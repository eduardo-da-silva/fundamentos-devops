{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Informa\u00e7\u00f5es iniciais","text":"<p>Essas s\u00e3o notas de aula para o uso nas disciplinas de Fundamentos de DevOps do curso de Bacharelado em Sistemas de Informa\u00e7\u00e3o do IFC - Campus Araquari. O conte\u00fado foi desenvolvido pelo Prof. Dr. Eduardo da Silva.</p> <p>Esse material ainda est\u00e1 em constru\u00e7\u00e3o e o seu conte\u00fado \u00e9 melhor absorvido durante as atividades realizadas em sala de aula.</p>"},{"location":"#ementa-do-curso","title":"Ementa do curso","text":"<p>Conceitos de versionamento de c\u00f3digo, reposit\u00f3rios de c\u00f3digo e suas ferramentas. Introdu\u00e7\u00e3o \u00e0 metodologia DevOps e ferramentas que auxiliam no processo de entrega, desenvolvimento e gerenciamento de sistemas computacionais ao longo do ciclo de vida de desenvolvimento de sistemas em organiza\u00e7\u00f5es. Introdu\u00e7\u00e3o \u00e0 abordagem integra\u00e7\u00e3o cont\u00ednua (CI) e entrega cont\u00ednua (CD). T\u00e9cnicas de automa\u00e7\u00e3o de pipeline e ferramentas. Introdu\u00e7\u00e3o \u00e0 containers e sua utiliza\u00e7\u00e3o em ambientes de desenvolvimento e produ\u00e7\u00e3o. Introdu\u00e7\u00e3o \u00e0 aspectos de seguran\u00e7a em DevOps.</p>"},{"location":"#objetivos-da-disciplina","title":"Objetivos da disciplina","text":"<p>Capacitar os alunos nos fundamentos e pr\u00e1ticas de DevOps, com \u00eanfase em versionamento de c\u00f3digo, metodologias \u00e1geis e ferramentas de gerenciamento de reposit\u00f3rios.</p> <p>Os alunos aprender\u00e3o a implementar pipelines de integra\u00e7\u00e3o cont\u00ednua (CI) e entrega cont\u00ednua (CD).</p> <p>Al\u00e9m disso, desenvolver\u00e3o habilidades em conteineriza\u00e7\u00e3o e pr\u00e1ticas de seguran\u00e7a.</p> <p>A disciplina fornece uma base s\u00f3lida para que os estudantes possam automatizar processos de desenvolvimento, gerenciar infraestrutura como c\u00f3digo e promover a colabora\u00e7\u00e3o efetiva entre equipes de desenvolvimento e opera\u00e7\u00f5es.</p>"},{"location":"#conteudo-programatico-e-cronograma","title":"Conte\u00fado program\u00e1tico e cronograma","text":"<p>Semana 1-2: Introdu\u00e7\u00e3o ao DevOps e Versionamento de C\u00f3digo</p> <ul> <li>Fundamentos de DevOps e sua import\u00e2ncia</li> <li>Pr\u00e1ticas de versionamento de c\u00f3digo</li> <li>Git b\u00e1sico: instala\u00e7\u00e3o, configura\u00e7\u00e3o e comandos essenciais</li> <li>Conventional commits</li> </ul> <p>Semana 3-4: Gest\u00e3o de Reposit\u00f3rios e Colabora\u00e7\u00e3o</p> <ul> <li>Plataformas de hospedagem de reposit\u00f3rios Git (GitHub, GitLab, Bitbucket)</li> <li>Estrat\u00e9gias de branching</li> <li>Pull requests e code review</li> <li>Projetos pr\u00e1ticos em equipe</li> </ul> <p>Semana 5-6: Integra\u00e7\u00e3o Cont\u00ednua</p> <ul> <li>Introdu\u00e7\u00e3o \u00e0 integra\u00e7\u00e3o cont\u00ednua</li> <li>Configura\u00e7\u00e3o de pipelines CI/CD</li> <li>GitHub Actions e GitLab CI</li> <li>Automa\u00e7\u00e3o de testes e builds</li> </ul> <p>Semana 7-8: Containers e Docker</p> <ul> <li>Fundamentos de containeriza\u00e7\u00e3o</li> <li>Docker: conceitos b\u00e1sicos e comandos</li> <li>Dockerfile e Docker Compose</li> <li>Pr\u00e1ticas com containers em desenvolvimento</li> </ul> <p>Semana 9-10: Orquestra\u00e7\u00e3o de Containers</p> <ul> <li>Introdu\u00e7\u00e3o ao Kubernetes</li> <li>Pods, services e deployments</li> <li>Gerenciamento de configura\u00e7\u00f5es</li> <li>Pr\u00e1ticas de orquestra\u00e7\u00e3o</li> </ul> <p>Semana 11-12: Infraestrutura como C\u00f3digo (IaC)</p> <ul> <li>Conceitos de IaC</li> <li>Terraform: fundamentos e pr\u00e1ticas</li> <li>Ansible: automa\u00e7\u00e3o de configura\u00e7\u00e3o</li> <li>Implementa\u00e7\u00e3o de infraestrutura automatizada</li> </ul> <p>Semana 13-14: Monitoramento e Observabilidade</p> <ul> <li>Fundamentos de monitoramento</li> <li>Prometheus e Grafana</li> <li>Logs e tracing distribu\u00eddo</li> <li>Pr\u00e1ticas de observabilidade</li> </ul> <p>Semana 15-16: DevSecOps</p> <ul> <li>Seguran\u00e7a em pipelines CI/CD</li> <li>An\u00e1lise est\u00e1tica de c\u00f3digo</li> <li>Scanning de vulnerabilidades</li> <li>Pr\u00e1ticas de seguran\u00e7a em containers</li> </ul> <p>Semana 17-18: Projeto Final e Revis\u00e3o</p> <ul> <li>Desenvolvimento de projeto completo em equipe</li> <li>Implementa\u00e7\u00e3o de pipeline completo</li> <li>Apresenta\u00e7\u00f5es dos projetos</li> <li>Revis\u00e3o geral e conclus\u00e3o do curso</li> </ul> <p>Carga Hor\u00e1ria:</p> <ul> <li>18 semanas x 2 encontros semanais</li> <li>Aulas de 50 minutos</li> <li>Total: 60 horas</li> </ul>"},{"location":"collaboration/","title":"Gest\u00e3o de Reposit\u00f3rios e Colabora\u00e7\u00e3o","text":"<p>Nesta etapa do curso, vamos explorar as pr\u00e1ticas de gest\u00e3o de reposit\u00f3rios e colabora\u00e7\u00e3o em equipe. Vamos abordar o uso de plataformas como GitHub e GitLab, as funcionalidades dispon\u00edveis, boas pr\u00e1ticas de colabora\u00e7\u00e3o, pull requests, code review e estrat\u00e9gias de branching.</p> <p>Num projeto Git, a colabora\u00e7\u00e3o eficiente \u00e9 essencial para o sucesso do desenvolvimento de software. Atrav\u00e9s de ferramentas e pr\u00e1ticas adequadas, \u00e9 poss\u00edvel organizar o trabalho em equipe, revisar e integrar as altera\u00e7\u00f5es de forma eficiente, garantindo a qualidade do c\u00f3digo e a produtividade da equipe.</p> <p>Inicialmente, \u00e9 importante resgatar alguns conceitos importantes, entre eles: reposit\u00f3rios remotos e locais, branches, pull requests e code review. Esses elementos s\u00e3o fundamentais para a colabora\u00e7\u00e3o em equipe e para a organiza\u00e7\u00e3o do desenvolvimento de software.</p>"},{"location":"collaboration/#repositorios-remotos-e-locais","title":"Reposit\u00f3rios Remotos e locais","text":"<p>Os reposit\u00f3rios remotos s\u00e3o vers\u00f5es do seu projeto que est\u00e3o hospedadas em servidores remotos, como GitHub, GitLab ou Bitbucket. Eles permitem que voc\u00ea compartilhe seu c\u00f3digo com outras pessoas e acesse-o de qualquer lugar. Al\u00e9m disso, os reposit\u00f3rios remotos s\u00e3o essenciais para a colabora\u00e7\u00e3o em equipe, pois permitem que v\u00e1rios desenvolvedores trabalhem no mesmo projeto simultaneamente.</p> <p>Eles diferem dos reposit\u00f3rios locais, que est\u00e3o armazenados em sua m\u00e1quina e s\u00e3o acess\u00edveis apenas localmente. Ao trabalhar em um projeto colaborativo, \u00e9 comum que cada desenvolvedor tenha uma c\u00f3pia do reposit\u00f3rio remoto em sua m\u00e1quina local, onde eles podem fazer altera\u00e7\u00f5es e contribui\u00e7\u00f5es.</p> <p>Em linhas gerais, a rela\u00e7\u00e3o entre reposit\u00f3rios remotos e locais \u00e9 bidirecional: voc\u00ea pode clonar um reposit\u00f3rio remoto para sua m\u00e1quina local, fazer altera\u00e7\u00f5es e envi\u00e1-las de volta para o reposit\u00f3rio remoto. Da mesma forma, voc\u00ea pode baixar as altera\u00e7\u00f5es feitas por outros desenvolvedores no reposit\u00f3rio remoto para sua m\u00e1quina local.</p>"},{"location":"collaboration/#plataformas-git","title":"Plataformas Git","text":"<p>O Git \u00e9 uma ferramenta poderosa para o controle de vers\u00e3o de c\u00f3digo-fonte, mas para colaborar efetivamente em projetos de software, \u00e9 necess\u00e1rio uma plataforma de hospedagem de reposit\u00f3rios Git. Ao usar uma plataforma Git, os desenvolvedores podem compartilhar, revisar e colaborar em projetos de forma eficiente, al\u00e9m de acessar recursos adicionais, como integra\u00e7\u00e3o cont\u00ednua, controle de acesso e gerenciamento de tarefas.</p> <p>Existem v\u00e1rias plataformas populares para hospedagem de reposit\u00f3rios Git, cada uma com suas pr\u00f3prias caracter\u00edsticas e funcionalidades. Algumas das plataformas mais conhecidas s\u00e3o:</p> <ul> <li>GitHub: Uma das plataformas mais populares para hospedagem de reposit\u00f3rios Git, o GitHub oferece uma ampla gama de recursos para colabora\u00e7\u00e3o em projetos de c\u00f3digo aberto e privados. Ele \u00e9 amplamente utilizado pela comunidade de desenvolvedores e empresas de tecnologia.</li> <li>GitLab: O GitLab \u00e9 uma plataforma de desenvolvimento de software completa, que inclui recursos de controle de vers\u00e3o, integra\u00e7\u00e3o cont\u00ednua, gerenciamento de tarefas e muito mais. Ele \u00e9 conhecido por sua flexibilidade e por oferecer uma vers\u00e3o de c\u00f3digo aberto que pode ser instalada em servidores locais.</li> <li>Bitbucket: O Bitbucket \u00e9 uma plataforma de hospedagem de reposit\u00f3rios Git da Atlassian, que oferece suporte para projetos de c\u00f3digo aberto e privados. Ele \u00e9 conhecido por sua integra\u00e7\u00e3o com outras ferramentas da Atlassian, como Jira e Confluence.</li> </ul> <p>Essas tr\u00eas plataformas apresentadas possuem diversos recursos gratuitos e pagos, sendo amplamente utilizadas pela comunidade de desenvolvedores para hospedar projetos de software e colaborar em equipe. Cada uma delas tem suas vantagens e caracter\u00edsticas espec\u00edficas, o que pode influenciar na escolha da plataforma mais adequada para um determinado projeto ou equipe de desenvolvimento.</p>"},{"location":"collaboration/#github","title":"GitHub","text":"<p>O GitHub foi criado em 2008 por Chris Wanstrath, PJ Hyett e Tom Preston-Werner e \u00e9 uma das plataformas mais populares para hospedagem de reposit\u00f3rios Git. Depois de sua cria\u00e7\u00e3o, o GitHub cresceu rapidamente e se tornou uma das maiores comunidades de desenvolvedores do mundo, com milh\u00f5es de reposit\u00f3rios p\u00fablicos e privados hospedados em sua plataforma. Em 2018, o GitHub foi adquirido pela Microsoft, que al\u00e9m de manter a plataforma, tem investido em melhorias e integra\u00e7\u00f5es com outros produtos da empresa.</p> <p>Alguns dos principais recursos do GitHub incluem:</p> <ul> <li>Reposit\u00f3rios p\u00fablicos e privados: O GitHub permite hospedar reposit\u00f3rios p\u00fablicos gratuitamente, que podem ser acessados por qualquer pessoa. Al\u00e9m disso, ele oferece planos pagos para reposit\u00f3rios privados, que s\u00e3o ideais para projetos comerciais ou propriet\u00e1rios.</li> <li>Issues e projetos: O GitHub oferece recursos avan\u00e7ados para gerenciamento de tarefas, como issues e projetos, que permitem que as equipes organizem e priorizem o trabalho de forma eficiente.</li> <li>Pull requests e code review: Os pull requests s\u00e3o uma forma estruturada de colabora\u00e7\u00e3o em projetos Git, permitindo que os desenvolvedores revisem, discutam e integrem as altera\u00e7\u00f5es de forma coordenada.</li> <li>Integra\u00e7\u00e3o cont\u00ednua: O GitHub Actions \u00e9 uma ferramenta de integra\u00e7\u00e3o cont\u00ednua integrada ao GitHub, que permite automatizar tarefas de build, testes e implanta\u00e7\u00e3o diretamente nos reposit\u00f3rios.</li> <li>Comunidade e colabora\u00e7\u00e3o: O GitHub \u00e9 conhecido por sua ampla comunidade de desenvolvedores, que compartilham projetos de c\u00f3digo aberto, contribuem com projetos existentes e colaboram em equipe de forma eficiente.</li> </ul>"},{"location":"collaboration/#gitlab","title":"GitLab","text":"<p>O GitLab \u00e9 uma plataforma de desenvolvimento de software completa, que oferece recursos de controle de vers\u00e3o, integra\u00e7\u00e3o cont\u00ednua, gerenciamento de tarefas e muito mais. Ele foi criado em 2011 por Dmitriy Zaporozhets e Valery Sizov e se tornou uma alternativa popular ao GitHub, especialmente para equipes que buscam uma solu\u00e7\u00e3o completa para o ciclo de vida do desenvolvimento de software.</p> <p>Alguns dos principais recursos do GitLab incluem:</p> <ul> <li>Reposit\u00f3rios p\u00fablicos e privados: O GitLab oferece suporte para reposit\u00f3rios p\u00fablicos e privados, com recursos avan\u00e7ados de controle de acesso e seguran\u00e7a.</li> <li>Integra\u00e7\u00e3o cont\u00ednua: O GitLab CI/CD \u00e9 uma ferramenta de integra\u00e7\u00e3o cont\u00ednua integrada ao GitLab, que permite automatizar tarefas de build, testes e implanta\u00e7\u00e3o diretamente nos reposit\u00f3rios.</li> <li>Gerenciamento de tarefas: O GitLab oferece recursos avan\u00e7ados para gerenciamento de tarefas, como issues, epics e roadmaps, que permitem que as equipes organizem e priorizem o trabalho de forma eficiente.</li> <li>Code review e merge requests: O GitLab oferece recursos avan\u00e7ados para code review e merge requests, que permitem que as equipes revisem, discutam e integrem as altera\u00e7\u00f5es de forma coordenada.</li> <li>Automa\u00e7\u00e3o e personaliza\u00e7\u00e3o: O GitLab \u00e9 conhecido por sua flexibilidade e capacidade de automa\u00e7\u00e3o, permitindo que as equipes personalizem seus processos de desenvolvimento de acordo com suas necessidades.</li> </ul> <p>Outra caracter\u00edstica do GitLab \u00e9 que ele permite a instala\u00e7\u00e3o em servidores locais, o que \u00e9 ideal para empresas que desejam manter o controle sobre seus dados e processos de desenvolvimento. Al\u00e9m disso, o GitLab oferece uma vers\u00e3o de c\u00f3digo aberto, o GitLab Community Edition, que pode ser usada gratuitamente por equipes de desenvolvimento.</p>"},{"location":"collaboration/#bitbucket","title":"Bitbucket","text":"<p>O Bitbucket \u00e9 uma plataforma de hospedagem de reposit\u00f3rios Git da Atlassian, que oferece suporte para projetos de c\u00f3digo aberto e privados. Ele foi criado em 2008 e adquirido pela Atlassian em 2010, tornando-se parte do portf\u00f3lio de ferramentas de desenvolvimento da empresa, que inclui o Jira, Confluence e Trello.</p> <p>Alguns dos principais recursos do Bitbucket incluem:</p> <ul> <li>Reposit\u00f3rios p\u00fablicos e privados: O Bitbucket oferece suporte para reposit\u00f3rios p\u00fablicos e privados, com recursos avan\u00e7ados de controle de acesso e seguran\u00e7a.</li> <li>Integra\u00e7\u00e3o com outras ferramentas da Atlassian: O Bitbucket \u00e9 integrado com outras ferramentas da Atlassian, como Jira e Confluence, permitindo uma integra\u00e7\u00e3o cont\u00ednua entre o controle de vers\u00e3o, gerenciamento de tarefas e documenta\u00e7\u00e3o.</li> <li>Code review e pull requests: O Bitbucket oferece recursos avan\u00e7ados para code review e pull requests, que permitem que as equipes revisem, discutam e integrem as altera\u00e7\u00f5es de forma coordenada.</li> <li>Integra\u00e7\u00e3o cont\u00ednua: O Bitbucket Pipelines \u00e9 uma ferramenta de integra\u00e7\u00e3o cont\u00ednua integrada ao Bitbucket, que permite automatizar tarefas de build, testes e implanta\u00e7\u00e3o diretamente nos reposit\u00f3rios.</li> </ul> <p>O Bitbucket \u00e9 uma op\u00e7\u00e3o popular para equipes que j\u00e1 utilizam outras ferramentas da Atlassian, como o Jira e Confluence, pois oferece uma integra\u00e7\u00e3o nativa entre essas ferramentas. Al\u00e9m disso, o Bitbucket oferece planos gratuitos e pagos, com recursos avan\u00e7ados para equipes de desenvolvimento de todos os tamanhos.</p>"},{"location":"collaboration/#revisao-das-plataformas-git","title":"Revis\u00e3o das plataformas Git","text":"<p>As plataformas Git, como GitHub, GitLab e Bitbucket, desempenham um papel fundamental na colabora\u00e7\u00e3o eficiente em projetos de software. Elas oferecem recursos avan\u00e7ados para gerenciamento de reposit\u00f3rios, controle de vers\u00e3o, integra\u00e7\u00e3o cont\u00ednua e colabora\u00e7\u00e3o em equipe, permitindo que os desenvolvedores trabalhem de forma coordenada e produtiva.</p> <p>Existem ainda outras plataformas de hospedagem de reposit\u00f3rios Git dispon\u00edveis no mercado, cada uma com suas pr\u00f3prias caracter\u00edsticas e funcionalidades. A escolha da plataforma mais adequada para um projeto ou equipe de desenvolvimento depende de v\u00e1rios fatores, como o tamanho da equipe, o tipo de projeto, os recursos necess\u00e1rios e as prefer\u00eancias dos desenvolvedores.</p> <p>Independentemente da plataforma escolhida, \u00e9 importante que as equipes adotem boas pr\u00e1ticas de colabora\u00e7\u00e3o, como o uso de pull requests, code review e integra\u00e7\u00e3o cont\u00ednua, para garantir a qualidade do c\u00f3digo, a efici\u00eancia do desenvolvimento e a produtividade da equipe.</p>"},{"location":"collaboration/#estrategias-de-branching","title":"Estrate\u0301gias de Branching","text":"<p>O uso de branches (ramificac\u0327o\u0303es) e\u0301 uma pra\u0301tica comum no versionamento de co\u0301digo que permite que os desenvolvedores trabalhem em funcionalidades ou correc\u0327o\u0303es de bugs isoladamente, sem interferir no co\u0301digo principal. Cada branch representa uma linha de desenvolvimento separada, que pode ser integrada ao branch principal (geralmente <code>main</code> ou <code>master</code>) por meio de merges.</p> <p>Os branches s\u00e3o \u00fateis para organizar o trabalho em equipe, facilitar a revis\u00e3o de c\u00f3digo e manter um hist\u00f3rico claro das altera\u00e7\u00f5es realizadas. Por exemplo, uma equipe de desenvolvimento pode criar branches espec\u00edficos para cada funcionalidade ou tarefa, como <code>feature/nova-funcionalidade</code> ou <code>bugfix/correcao-bug</code>.</p> <p>Ap\u00f3s concluir o desenvolvimento em um branch, \u00e9 comum realizar um merge para integrar as mudan\u00e7as no branch principal. O merge \u00e9 o processo de combinar as altera\u00e7\u00f5es de um branch em outro, garantindo que o c\u00f3digo seja atualizado e os conflitos sejam resolvidos corretamente.</p>"},{"location":"collaboration/#resolucao-de-conflitos","title":"Resolu\u00e7\u00e3o de Conflitos","text":"<p>Durante o merge, podem ocorrer conflitos quando duas ou mais altera\u00e7\u00f5es entram em conflito, ou seja, modificam a mesma parte do c\u00f3digo. Nesses casos, \u00e9 necess\u00e1rio resolver os conflitos manualmente, escolhendo qual vers\u00e3o do c\u00f3digo deve ser mantida.</p> <p>As ferramentas de versionamento, como Git, oferecem suporte para resolver conflitos de forma eficiente, permitindo que os desenvolvedores comparem as vers\u00f5es do c\u00f3digo, escolham as altera\u00e7\u00f5es desejadas e finalizem o merge com sucesso.</p> <p>A resolu\u00e7\u00e3o de conflitos \u00e9 uma etapa importante no processo de desenvolvimento colaborativo, pois garante que as mudan\u00e7as sejam integradas corretamente e que o c\u00f3digo seja mantido consistente ao longo do tempo.</p>"},{"location":"collaboration/#gitflow","title":"GitFlow","text":"<p>O GitFlow \u00e9 um modelo de branching amplamente utilizado que define um fluxo de trabalho com branches espec\u00edficos para features, releases, hotfixes e vers\u00f5es. Ele prop\u00f5e a utiliza\u00e7\u00e3o de branches como <code>feature/</code>, <code>release/</code>, <code>hotfix/</code> e <code>develop</code> para organizar o desenvolvimento de forma estruturada e facilitar a colabora\u00e7\u00e3o em equipe.</p> <p>O GitFlow \u00e9 baseado em algumas premissas fundamentais:</p> <ul> <li><code>master</code>: Branch principal que cont\u00e9m o c\u00f3digo em produ\u00e7\u00e3o.</li> <li><code>develop</code>: Branch de desenvolvimento cont\u00ednuo, onde as features s\u00e3o integradas.</li> <li><code>feature/</code>: Branches para o desenvolvimento de novas funcionalidades.</li> <li><code>release/</code>: Branches para preparar novas vers\u00f5es para produ\u00e7\u00e3o.</li> <li><code>hotfix/</code>: Branches para corrigir bugs cr\u00edticos em produ\u00e7\u00e3o.</li> </ul> <p>O GitFlow \u00e9 uma estrat\u00e9gia eficaz para organizar o desenvolvimento de software, facilitar a colabora\u00e7\u00e3o em equipe e manter um hist\u00f3rico claro das altera\u00e7\u00f5es realizadas.</p> <p>Para implementar o GitFlow existe um aplicativo, chamado git-flow, que facilita a utiliza\u00e7\u00e3o dessa estrat\u00e9gia.</p> <p>Por exemplo, usando o git-flow, voc\u00ea pode criar um novo branch de feature com o comando:</p> <pre><code>git flow feature start nova-funcionalidade\n</code></pre> <p>E finalizar a feature com o comando:</p> <pre><code>git flow feature finish nova-funcionalidade\n</code></pre> <p>O git-flow automatiza o processo de cria\u00e7\u00e3o e finaliza\u00e7\u00e3o de branches, facilitando o uso do GitFlow em projetos de desenvolvimento de software.</p> <p>Contudo, nem sempre \u00e9 necess\u00e1rio usar essa ferramenta, pois o GitFlow pode ser implementado manualmente, sem a necessidade de uma ferramenta espec\u00edfica. O que importa \u00e9 seguir o fluxo de trabalho proposto pelo GitFlow para organizar o desenvolvimento de forma eficiente.</p> <p>Existem outras estrat\u00e9gias de branching, como o trunk-based development, que prop\u00f5em abordagens diferentes para organizar o desenvolvimento de software. Cada equipe pode escolher a estrat\u00e9gia que melhor se adapta \u00e0s suas necessidades e ao seu fluxo de trabalho.</p>"},{"location":"collaboration/#pull-requests","title":"Pull Requests","text":"<p>Os pull requests (ou solicita\u00e7\u00f5es de pull) s\u00e3o uma forma de colabora\u00e7\u00e3o em projetos Git, em que um desenvolvedor prop\u00f5e as altera\u00e7\u00f5es feitas em um branch para serem mescladas no branch principal (ou outra branch). Eles s\u00e3o comumente usados em projetos colaborativos para revisar, discutir e integrar as altera\u00e7\u00f5es de forma estruturada.</p> <p>Ao abrir um pull request, o desenvolvedor pode descrever as altera\u00e7\u00f5es feitas, mencionar outros colaboradores, solicitar revis\u00f5es e discutir os detalhes das mudan\u00e7as. Isso permite que a equipe revise o c\u00f3digo, fa\u00e7a coment\u00e1rios, sugira melhorias e aprove as altera\u00e7\u00f5es antes de serem mescladas no c\u00f3digo principal.</p>"},{"location":"collaboration/#por-que-usar-pull-requests","title":"Por que usar pull requests?","text":"<p>Os pull requests s\u00e3o uma pr\u00e1tica recomendada para colabora\u00e7\u00e3o em projetos Git por v\u00e1rios motivos:</p> <ul> <li>Revis\u00e3o de c\u00f3digo: Os pull requests permitem que os desenvolvedores revisem o c\u00f3digo de seus colegas, fa\u00e7am coment\u00e1rios, sugiram melhorias e identifiquem poss\u00edveis problemas antes de mesclar as altera\u00e7\u00f5es no c\u00f3digo principal. Isso ajuda a garantir a qualidade do c\u00f3digo e a identificar bugs precocemente.</li> <li>Colabora\u00e7\u00e3o estruturada: Ao abrir um pull request, os desenvolvedores podem descrever as altera\u00e7\u00f5es feitas, mencionar outros colaboradores, solicitar revis\u00f5es e discutir os detalhes das mudan\u00e7as. Isso promove uma colabora\u00e7\u00e3o mais estruturada e eficiente entre os membros da equipe.</li> <li>Hist\u00f3rico de altera\u00e7\u00f5es: Os pull requests mant\u00eam um registro detalhado das altera\u00e7\u00f5es feitas no c\u00f3digo, incluindo quem fez as altera\u00e7\u00f5es, quando foram feitas e quais foram as discuss\u00f5es realizadas. Isso \u00e9 \u00fatil para auditorias, para entender o contexto das mudan\u00e7as e para rastrear a evolu\u00e7\u00e3o do c\u00f3digo ao longo do tempo.</li> <li>Integra\u00e7\u00e3o cont\u00ednua: Os pull requests s\u00e3o uma parte fundamental da integra\u00e7\u00e3o cont\u00ednua (CI), onde o c\u00f3digo \u00e9 frequentemente integrado e testado automaticamente. Ferramentas como GitHub Actions e GitLab CI/CD permitem configurar pipelines de CI que automatizam a verifica\u00e7\u00e3o das altera\u00e7\u00f5es propostas antes de serem mescladas no c\u00f3digo principal.</li> </ul>"},{"location":"collaboration/#como-criar-um-pull-request","title":"Como criar um pull request","text":"<p>Para criar um pull request, siga os seguintes passos:</p> <ol> <li>Crie um branch: Antes de abrir um pull request, crie um branch a partir do branch principal (geralmente <code>main</code> ou <code>master) para desenvolver suas altera\u00e7\u00f5es. Por exemplo, voc\u00ea pode criar um branch</code>feature/nova-funcionalidade` para implementar uma nova funcionalidade.</li> <li>Fa\u00e7a as altera\u00e7\u00f5es: Fa\u00e7a as altera\u00e7\u00f5es desejadas no seu branch, adicione, modifique ou remova arquivos conforme necess\u00e1rio.</li> <li>Commit e push: Ap\u00f3s fazer as altera\u00e7\u00f5es, fa\u00e7a commits locais e envie as altera\u00e7\u00f5es para o reposit\u00f3rio remoto usando <code>git push</code>.</li> <li>Abra o pull request: No GitHub ou GitLab, v\u00e1 at\u00e9 a p\u00e1gina do reposit\u00f3rio, clique no bot\u00e3o \"New pull request\" e selecione o branch que cont\u00e9m as altera\u00e7\u00f5es que voc\u00ea deseja mesclar.</li> <li>Descreva as altera\u00e7\u00f5es: Escreva uma descri\u00e7\u00e3o detalhada das altera\u00e7\u00f5es feitas, mencione outros colaboradores, solicite revis\u00f5es e discuta os detalhes das mudan\u00e7as.</li> <li>Solicite revis\u00f5es: Se desejar, solicite revis\u00f5es de outros colaboradores para revisar o c\u00f3digo, fazer coment\u00e1rios e sugerir melhorias.</li> <li>Aguarde a aprova\u00e7\u00e3o: Aguarde a revis\u00e3o e a aprova\u00e7\u00e3o dos colaboradores antes de mesclar as altera\u00e7\u00f5es no c\u00f3digo principal.</li> <li>Resolva os coment\u00e1rios: Caso haja coment\u00e1rios ou sugest\u00f5es de melhorias, fa\u00e7a as altera\u00e7\u00f5es necess\u00e1rias e atualize o pull request.</li> <li>Mescle as altera\u00e7\u00f5es: Ap\u00f3s a aprova\u00e7\u00e3o e resolu\u00e7\u00e3o dos coment\u00e1rios, mescle as altera\u00e7\u00f5es no branch principal clicando no bot\u00e3o \"Merge pull request\".</li> </ol> <p>Alguns times de desenvolvimento podem ter regras espec\u00edficas para a abertura e aprova\u00e7\u00e3o de pull requests, como a obrigatoriedade de revis\u00e3o por pares, a execu\u00e7\u00e3o de testes automatizados ou a integra\u00e7\u00e3o com ferramentas de CI/CD. Certifique-se de seguir as pr\u00e1ticas adotadas pela sua equipe ao criar e revisar pull requests.</p> <p>Um estrat\u00e9gia muito comum \u00e9 delimitar qual usu\u00e1rio pode fazer o merge do pull request, evitando que o pr\u00f3prio autor do pull request fa\u00e7a o merge, garantindo assim uma revis\u00e3o por pares.</p>"},{"location":"collaboration/#code-review","title":"Code Review","text":"<p>O code review (ou revis\u00e3o de c\u00f3digo) \u00e9 uma pr\u00e1tica essencial para garantir a qualidade do c\u00f3digo, identificar poss\u00edveis problemas e promover a colabora\u00e7\u00e3o em equipe. Durante o code review, os desenvolvedores revisam o c\u00f3digo de seus colegas, fazem coment\u00e1rios, sugerem melhorias e verificam se as boas pr\u00e1ticas de desenvolvimento foram seguidas.</p> <p>Em geral, o code review \u00e9 realizado por meio de ferramentas de controle de vers\u00e3o, como GitHub e GitLab, que permitem que os desenvolvedores visualizem as altera\u00e7\u00f5es, fa\u00e7am coment\u00e1rios linha a linha e discutam as mudan\u00e7as propostas. Essa pr\u00e1tica ajuda a identificar bugs, melhorar a legibilidade do c\u00f3digo e promover a troca de conhecimento entre os membros da equipe.</p> <p>Na pr\u00e1tica, em equipes bem organizadas, o code review \u00e9 uma etapa obrigat\u00f3ria antes de mesclar as altera\u00e7\u00f5es em um projeto. Ele garante que o c\u00f3digo seja revisado por pares, que poss\u00edveis problemas sejam identificados e que a qualidade do c\u00f3digo seja mantida ao longo do tempo.</p>"},{"location":"collaboration/#beneficios-do-code-review","title":"Benef\u00edcios do code review","text":"<p>O code review traz diversos benef\u00edcios para equipes de desenvolvimento, incluindo:</p> <ul> <li>Identifica\u00e7\u00e3o de bugs: Durante o code review, os desenvolvedores podem identificar bugs, problemas de l\u00f3gica e falhas de seguran\u00e7a no c\u00f3digo antes que ele seja mesclado no projeto principal. Isso ajuda a garantir a qualidade do software e a reduzir o n\u00famero de bugs em produ\u00e7\u00e3o.</li> <li>Melhoria da qualidade do c\u00f3digo: O code review promove a troca de conhecimento entre os membros da equipe, permitindo que os desenvolvedores aprendam uns com os outros, compartilhem boas pr\u00e1ticas e melhorem a qualidade do c\u00f3digo. Coment\u00e1rios construtivos e sugest\u00f5es de melhorias ajudam a elevar o n\u00edvel t\u00e9cnico da equipe.</li> <li>Conformidade com padr\u00f5es e boas pr\u00e1ticas: Durante o code review, os desenvolvedores podem verificar se o c\u00f3digo segue os padr\u00f5es de codifica\u00e7\u00e3o, as boas pr\u00e1ticas de desenvolvimento e as diretrizes do projeto. Isso ajuda a manter a consist\u00eancia do c\u00f3digo, facilita a manuten\u00e7\u00e3o e evita problemas futuros.</li> <li>Aprendizado cont\u00ednuo: O code review \u00e9 uma oportunidade para os desenvolvedores aprenderem novas t\u00e9cnicas, ferramentas e abordagens de desenvolvimento. Ao revisar o c\u00f3digo de seus colegas, os desenvolvedores podem expandir seu conhecimento e aprimorar suas habilidades t\u00e9cnicas.</li> <li>Promo\u00e7\u00e3o da colabora\u00e7\u00e3o: O code review promove a colabora\u00e7\u00e3o e a comunica\u00e7\u00e3o entre os membros da equipe, criando um ambiente de trabalho mais colaborativo e produtivo. Coment\u00e1rios construtivos, sugest\u00f5es de melhorias e discuss\u00f5es t\u00e9cnicas ajudam a fortalecer o trabalho em equipe.</li> </ul>"},{"location":"collaboration/#boas-praticas-de-code-review","title":"Boas pr\u00e1ticas de code review","text":"<p>Para obter os melhores resultados com o code review, \u00e9 importante seguir algumas boas pr\u00e1ticas:</p> <ul> <li>Seja construtivo: Ao fazer coment\u00e1rios no c\u00f3digo de seus colegas, seja construtivo e respeitoso. Evite cr\u00edticas negativas ou ataques pessoais e concentre-se em fornecer feedback \u00fatil e construtivo.</li> <li>Seja espec\u00edfico: Ao identificar problemas ou sugerir melhorias, seja espec\u00edfico e forne\u00e7a exemplos claros. Explique o motivo por tr\u00e1s das sugest\u00f5es e forne\u00e7a orienta\u00e7\u00f5es sobre como corrigir os problemas.</li> <li>Mantenha o foco: Durante o code review, mantenha o foco nos objetivos da revis\u00e3o. Evite discutir quest\u00f5es n\u00e3o relacionadas ao c\u00f3digo ou aprofundar-se em detalhes irrelevantes.</li> <li>Respeite o tempo: Respeite o tempo dos seus colegas e evite sobrecarreg\u00e1-los com revis\u00f5es extensas ou desnecess\u00e1rias. Priorize os coment\u00e1rios mais relevantes e \u00fateis para melhorar o c\u00f3digo.</li> <li>Aprenda com o feedback: Encare o code review como uma oportunidade de aprendizado e crescimento. Esteja aberto a receber feedback, aprender com os coment\u00e1rios dos seus colegas e aprimorar suas habilidades t\u00e9cnicas.</li> </ul>"},{"location":"collaboration/#projeto-em-grupo","title":"Projeto em grupo","text":"<p>A proposta \u00e9 um projeto em grupo para desenvolver um Gerenciador de Tarefas Web simples, onde os usu\u00e1rios podem adicionar, editar e remover tarefas. O projeto deve ser feito em equipe no GitHub, seguindo boas pr\u00e1ticas de versionamento e colabora\u00e7\u00e3o.</p> <p>O tema sugerido n\u00e3o \u00e9 obrigat\u00f3rio, mas serve como ponto de partida para a pr\u00e1tica de colabora\u00e7\u00e3o em equipe. Os alunos podem adaptar o projeto conforme desejarem, desde que sigam as diretrizes de versionamento e colabora\u00e7\u00e3o propostas.</p> <p>Tecnologias sugeridas</p> <ul> <li>Backend: FastAPI, Django ou Node.js</li> <li>Frontend: HTML, CSS, JavaScript (ou Vue.js, se quiserem algo mais avan\u00e7ado)</li> <li>Banco de dados: SQLite ou PostgreSQL (opcional)</li> <li>Ferramentas: GitHub para versionamento e colabora\u00e7\u00e3o</li> </ul> <p>Organiza\u00e7\u00e3o da Equipe (4 pessoas)</p> <p>No desenvolvimento do projeto n\u00e3o devem ser criados papeis fixos (documentador, testador, desenvolvedor backend ou frontend), mas sim que todos os membros participem de todas as etapas do desenvolvimento. A ideia \u00e9 que todos aprendam e pratiquem as habilidades de versionamento e colabora\u00e7\u00e3o.</p> <p>Tarefas que devem ser consideradas</p> <ul> <li> <p>Versionamento e Reposit\u00f3rio</p> </li> <li> <p>Configurar o reposit\u00f3rio no GitHub.</p> </li> <li>Criar o README.md com a documenta\u00e7\u00e3o inicial.</li> <li> <p>Definir a estrutura de pastas do projeto.</p> </li> <li> <p>Backend</p> </li> <li> <p>Criar uma API para gerenciar as tarefas (CRUD).</p> </li> <li>Criar os endpoints REST.</li> <li> <p>Documentar a API (Swagger ou Postman).</p> </li> <li> <p>Frontend</p> </li> <li> <p>Criar a interface web para intera\u00e7\u00e3o com a API.</p> </li> <li> <p>Usar HTML/CSS e JavaScript para consumir os dados.</p> </li> <li> <p>Integra\u00e7\u00e3o e Revis\u00e3o de C\u00f3digo</p> </li> <li>Definir e aplicar Conventional Commits.</li> <li>Gerenciar pull requests e code reviews.</li> <li>Definir e aplicar estrat\u00e9gias de branching.</li> </ul> <p>Requisitos do Projeto</p> <ul> <li>Criar um reposit\u00f3rio p\u00fablico no GitHub.</li> <li>Definir branches (main, develop, feature/*).</li> <li>Aplicar commits sem\u00e2nticos (Conventional Commits).</li> <li>Criar pull requests para cada nova funcionalidade.</li> <li>Implementar code review antes de mergear c\u00f3digo.</li> <li>Criar um README.md explicando o projeto.</li> </ul> <p>Como o trabalho ser\u00e1 avaliado</p> <ul> <li>Uso correto do Git e GitHub (branching, commits, PRs, code review).</li> <li>Organiza\u00e7\u00e3o do reposit\u00f3rio (documenta\u00e7\u00e3o, estrutura do projeto).</li> <li>Colabora\u00e7\u00e3o (todos os membros devem contribuir).</li> <li>Qualidade do c\u00f3digo (boas pr\u00e1ticas e estrutura\u00e7\u00e3o).</li> </ul>"},{"location":"git-basico/","title":"Git b\u00e1sico","text":"<p>O Git \u00e9 um sistema de controle de vers\u00e3o distribu\u00eddo amplamente utilizado no desenvolvimento de software. Ele permite que os desenvolvedores rastreiem e gerenciem as altera\u00e7\u00f5es feitas no c\u00f3digo-fonte ao longo do tempo, facilitando a colabora\u00e7\u00e3o em equipe e a integra\u00e7\u00e3o cont\u00ednua.</p> <p>Ele foi criado por Linus Torvalds em 2005 para gerenciar o desenvolvimento do kernel do Linux e se tornou uma ferramenta essencial para desenvolvedores em todo o mundo. O Git \u00e9 conhecido por sua velocidade, escalabilidade e flexibilidade, tornando-o a escolha ideal para projetos de todos os tamanhos.</p>"},{"location":"git-basico/#instalacao","title":"Instala\u00e7\u00e3o","text":"<p>Para instalar o Git em seu sistema, siga as instru\u00e7\u00f5es espec\u00edficas para o seu sistema operacional:</p> Linux (Arch | Manjaro)Linux (Ubuntu | Debian)macOSWindows <pre><code>sudo pacman -S git\n</code></pre> <pre><code>sudo apt update\nsudo apt install git\n</code></pre> <pre><code>brew install git\n</code></pre> <p>Baixe o instalador do Git no site oficial e siga as instru\u00e7\u00f5es de instala\u00e7\u00e3o</p> <p>Ap\u00f3s a instala\u00e7\u00e3o, voc\u00ea pode verificar se o Git foi instalado corretamente executando o comando:</p> <pre><code>git --version\n</code></pre> <p>Isso exibir\u00e1 a vers\u00e3o do Git instalada em seu sistema.</p>"},{"location":"git-basico/#configuracao","title":"Configura\u00e7\u00e3o","text":"<p>Antes de come\u00e7ar a usar o Git, \u00e9 importante configurar seu nome de usu\u00e1rio e endere\u00e7o de e-mail. Isso \u00e9 necess\u00e1rio para identificar as altera\u00e7\u00f5es feitas no c\u00f3digo e atribu\u00ed-las corretamente a voc\u00ea. Voc\u00ea pode configurar essas informa\u00e7\u00f5es usando os comandos:</p> <pre><code>git config --global user.name \"Seu Nome\"\ngit config --global user.email \"seuemail@dominio.com\"\n</code></pre> <p>Substitua <code>Seu Nome</code> pelo seu nome de usu\u00e1rio e <code>seuemail@dominio.com</code> pelo seu endere\u00e7o de e-mail. Essas informa\u00e7\u00f5es ser\u00e3o usadas nos commits que voc\u00ea fizer no Git.</p> <p>Note que foi usada a op\u00e7\u00e3o <code>--global</code> para configurar essas informa\u00e7\u00f5es globalmente, ou seja, elas ser\u00e3o aplicadas a todos os reposit\u00f3rios Git em seu sistema. Se voc\u00ea deseja configurar essas informa\u00e7\u00f5es apenas para um reposit\u00f3rio espec\u00edfico, remova a op\u00e7\u00e3o <code>--global</code>. As poss\u00edveis op\u00e7\u00f5es de abrang\u00eancia s\u00e3o:</p> <ul> <li><code>--global</code>: Aplica a configura\u00e7\u00e3o a todos os reposit\u00f3rios do usu\u00e1rio.</li> <li><code>--local</code>: Aplica a configura\u00e7\u00e3o apenas ao reposit\u00f3rio atual.</li> <li><code>--system</code>: Aplica a configura\u00e7\u00e3o a todos os reposit\u00f3rios do sistema.</li> </ul> <p>A configura\u00e7\u00e3o do Git \u00e9 um passo importante para garantir que suas altera\u00e7\u00f5es sejam atribu\u00eddas corretamente e que voc\u00ea possa colaborar efetivamente com outros desenvolvedores.</p>"},{"location":"git-basico/#comandos-essenciais","title":"Comandos essenciais","text":"<p>O Git possui uma s\u00e9rie de comandos essenciais que permitem rastrear, gerenciar e colaborar em projetos de software. Alguns dos comandos mais comuns incluem:</p> <ul> <li><code>git init</code>: Inicializa um reposit\u00f3rio Git em um diret\u00f3rio existente.</li> <li><code>git clone</code>: Clona um reposit\u00f3rio Git existente para o seu sistema.</li> <li><code>git add</code>: Adiciona arquivos ao \u00edndice (staging area) para serem inclu\u00eddos no pr\u00f3ximo commit.</li> <li><code>git commit</code>: Registra as altera\u00e7\u00f5es feitas nos arquivos no reposit\u00f3rio.</li> <li><code>git push</code>: Envia os commits locais para um reposit\u00f3rio remoto.</li> <li><code>git pull</code>: Atualiza o reposit\u00f3rio local com as altera\u00e7\u00f5es do reposit\u00f3rio remoto.</li> <li><code>git branch</code>: Lista, cria ou exclui branches no reposit\u00f3rio.</li> <li><code>git merge</code>: Combina as altera\u00e7\u00f5es de um branch em outro.</li> <li><code>git checkout</code>: Altera o branch atual ou restaura arquivos do reposit\u00f3rio.</li> <li><code>git log</code>: Exibe o hist\u00f3rico de commits do reposit\u00f3rio.</li> </ul> <p>Esses comandos s\u00e3o essenciais para trabalhar com o Git e colaborar em projetos de software. Ao dominar esses comandos, voc\u00ea poder\u00e1 rastrear e gerenciar as altera\u00e7\u00f5es no c\u00f3digo de forma eficiente e colaborar com outros desenvolvedores de forma eficaz.</p>"},{"location":"intro/","title":"Introdu\u00e7\u00e3o","text":"<p>DevOps \u00e9 uma cultura e conjunto de pr\u00e1ticas que visa unificar o desenvolvimento de software (Dev) com a opera\u00e7\u00e3o de sistemas (Ops). Esta abordagem enfatiza a colabora\u00e7\u00e3o, automa\u00e7\u00e3o e integra\u00e7\u00e3o cont\u00ednua, permitindo entregas mais r\u00e1pidas e confi\u00e1veis de software.</p> <p>O termo \"DevOps\" surgiu em 2009 durante a confer\u00eancia Agile Conference em Toronto, quando Patrick Debois e Andrew Shafer discutiram os problemas entre as equipes de desenvolvimento e opera\u00e7\u00f5es. O movimento ganhou for\u00e7a ap\u00f3s a primeira DevOpsDays, realizada na B\u00e9lgica no mesmo ano.</p> <p>A frustra\u00e7\u00e3o com o modelo tradicional de desenvolvimento, onde existia uma clara separa\u00e7\u00e3o (e frequentemente conflito) entre as equipes de desenvolvimento e opera\u00e7\u00f5es, levou \u00e0 busca por uma abordagem mais integrada. As equipes de desenvolvimento queriam implementar mudan\u00e7as rapidamente, enquanto as equipes de opera\u00e7\u00f5es priorizavam a estabilidade do sistema.</p> <p>Esta divis\u00e3o resultava em:</p> <ul> <li>Longos ciclos de desenvolvimento</li> <li>Problemas frequentes em produ\u00e7\u00e3o</li> <li>Comunica\u00e7\u00e3o deficiente entre equipes</li> <li>Resist\u00eancia \u00e0 mudan\u00e7a</li> </ul> <p>O DevOps surgiu como resposta a esses desafios, propondo uma cultura de colabora\u00e7\u00e3o e integra\u00e7\u00e3o entre as equipes.</p>"},{"location":"intro/#fundamentos-de-devops","title":"Fundamentos de DevOps","text":"<p>Dentro de uma organiza\u00e7\u00e3o que adota DevOps, as equipes de desenvolvimento e opera\u00e7\u00f5es trabalham juntas para alcan\u00e7ar os objetivos comuns de entrega r\u00e1pida e confi\u00e1vel de software. Isso envolve a implementa\u00e7\u00e3o de pr\u00e1ticas \u00e1geis, automa\u00e7\u00e3o de processos e monitoramento cont\u00ednuo do desempenho do software.</p> <p>De forma resumida, os princ\u00edpios fundamentais do DevOps incluem:</p> <ul> <li> <p>Cultura de colabora\u00e7\u00e3o entre equipes: A colabora\u00e7\u00e3o entre as equipes de desenvolvimento e opera\u00e7\u00f5es \u00e9 essencial. Por exemplo, em um projeto de desenvolvimento de uma aplica\u00e7\u00e3o web, as equipes podem realizar reuni\u00f5es di\u00e1rias para discutir o progresso, identificar obst\u00e1culos e planejar as pr\u00f3ximas etapas juntos.</p> </li> <li> <p>Automa\u00e7\u00e3o de processos: A automa\u00e7\u00e3o reduz erros humanos e acelera o ciclo de desenvolvimento. Um exemplo pr\u00e1tico \u00e9 a utiliza\u00e7\u00e3o de pipelines de integra\u00e7\u00e3o cont\u00ednua (CI) e entrega cont\u00ednua (CD) para automatizar testes e implanta\u00e7\u00f5es. Ferramentas como Jenkins, GitLab CI/CD e GitHub Actions s\u00e3o amplamente utilizadas para esse fim.</p> </li> <li> <p>Medi\u00e7\u00e3o cont\u00ednua de resultados: Medir e monitorar o desempenho do software e dos processos \u00e9 crucial para identificar \u00e1reas de melhoria. Por exemplo, a equipe pode usar ferramentas como Prometheus e Grafana para monitorar a performance da aplica\u00e7\u00e3o em produ\u00e7\u00e3o e gerar alertas em caso de problemas.</p> </li> <li> <p>Compartilhamento de conhecimento: Promover uma cultura de aprendizado cont\u00ednuo e compartilhamento de conhecimento entre as equipes. Isso pode ser feito atrav\u00e9s de sess\u00f5es de retrospectiva, onde as equipes discutem o que funcionou bem e o que pode ser melhorado, ou atrav\u00e9s de documenta\u00e7\u00f5es que detalham as melhores pr\u00e1ticas e li\u00e7\u00f5es aprendidas.</p> </li> <li> <p>Seguran\u00e7a integrada: Incorporar pr\u00e1ticas de seguran\u00e7a desde o in\u00edcio do ciclo de desenvolvimento. Isso \u00e9 conhecido como DevSecOps. Por exemplo, realizar an\u00e1lises de vulnerabilidades e testes de seguran\u00e7a automatizados durante o processo de CI/CD para garantir que o c\u00f3digo esteja seguro antes de ser implantado em produ\u00e7\u00e3o.</p> </li> </ul> <p>Esses princ\u00edpios ajudam a criar um ambiente onde as mudan\u00e7as podem ser implementadas de forma r\u00e1pida e segura, resultando em entregas mais frequentes e de maior qualidade. Nos dias atuais, a ado\u00e7\u00e3o de DevOps \u00e9 essencial para as empresas que buscam se manter competitivas em um mercado cada vez mais din\u00e2mico e exigente.</p> <p>Isso porque a capacidade de responder rapidamente \u00e0s demandas dos clientes e \u00e0s mudan\u00e7as no mercado \u00e9 um diferencial competitivo importante. Ao adotar os conceitos e t\u00e9cnicas de DevOps, as empresas t\u00eam maior flexibilidade para lan\u00e7ar novas funcionalidades, corrigir bugs e ajustar o software de acordo com as necessidades do neg\u00f3cio.</p> <p>Dessa forma, se bem empregada, a implementa\u00e7\u00e3o bem-sucedida do DevOps resulta em:</p> <ul> <li> <p>Entregas mais r\u00e1pidas: Com a automa\u00e7\u00e3o de processos e a integra\u00e7\u00e3o cont\u00ednua, as equipes podem lan\u00e7ar novas funcionalidades e corre\u00e7\u00f5es de bugs com maior frequ\u00eancia. Por exemplo, uma equipe de desenvolvimento pode usar pipelines de CI/CD para automatizar a constru\u00e7\u00e3o, teste e implanta\u00e7\u00e3o de uma aplica\u00e7\u00e3o, reduzindo o tempo entre a escrita do c\u00f3digo e sua disponibiliza\u00e7\u00e3o em produ\u00e7\u00e3o.</p> </li> <li> <p>Maior qualidade de software: Atrav\u00e9s de testes automatizados e monitoramento cont\u00ednuo, \u00e9 poss\u00edvel identificar e corrigir problemas antes que eles afetem os usu\u00e1rios finais. Por exemplo, a utiliza\u00e7\u00e3o de testes unit\u00e1rios, testes de integra\u00e7\u00e3o e testes de aceita\u00e7\u00e3o automatizados garante que o c\u00f3digo esteja funcionando conforme o esperado em diferentes cen\u00e1rios.</p> </li> <li> <p>Melhor resposta a problemas: Com a implementa\u00e7\u00e3o de pr\u00e1ticas de monitoramento e logging, as equipes podem detectar e responder a incidentes mais rapidamente. Por exemplo, ao usar ferramentas como ELK Stack (Elasticsearch, Logstash e Kibana) para centralizar e analisar logs, a equipe pode identificar a causa raiz de um problema e aplicar corre\u00e7\u00f5es de forma \u00e1gil.</p> </li> <li> <p>Maior satisfa\u00e7\u00e3o do cliente: A capacidade de entregar novas funcionalidades e melhorias de forma cont\u00ednua e confi\u00e1vel aumenta a satisfa\u00e7\u00e3o do cliente. Por exemplo, uma empresa de e-commerce que adota DevOps pode lan\u00e7ar novas funcionalidades de forma incremental, respondendo rapidamente ao feedback dos usu\u00e1rios e melhorando a experi\u00eancia de compra.</p> </li> </ul> <p>Esses benef\u00edcios demonstram como a ado\u00e7\u00e3o de pr\u00e1ticas DevOps pode transformar a forma como as equipes de desenvolvimento e opera\u00e7\u00f5es trabalham, resultando em um ciclo de desenvolvimento mais eficiente e produtos de maior qualidade.</p>"},{"location":"intro/#versionamento-de-codigo","title":"Versionamento de C\u00f3digo","text":"<p>O versionamento de c\u00f3digo \u00e9 uma pr\u00e1tica essencial no desenvolvimento de software que consiste em controlar e gerenciar as altera\u00e7\u00f5es feitas no c\u00f3digo-fonte ao longo do tempo. Isso permite que as equipes de desenvolvimento trabalhem de forma colaborativa, rastreiem as mudan\u00e7as realizadas e revertam para vers\u00f5es anteriores se necess\u00e1rio.</p> <p>No contexto do DevOps, o versionamento de c\u00f3digo \u00e9 fundamental por v\u00e1rias raz\u00f5es:</p> <ul> <li> <p>Colabora\u00e7\u00e3o eficiente: Ferramentas de versionamento, como Git, permitem que m\u00faltiplos desenvolvedores trabalhem simultaneamente no mesmo projeto sem conflitos. Por exemplo, em um projeto de desenvolvimento de uma aplica\u00e7\u00e3o web, diferentes desenvolvedores podem trabalhar em funcionalidades distintas e integrar suas mudan\u00e7as de forma coordenada.</p> </li> <li> <p>Hist\u00f3rico de mudan\u00e7as: Manter um hist\u00f3rico detalhado das altera\u00e7\u00f5es facilita a identifica\u00e7\u00e3o de quando e por quem uma mudan\u00e7a foi feita. Isso \u00e9 crucial para auditorias e para entender a evolu\u00e7\u00e3o do projeto. Por exemplo, se um bug for introduzido, a equipe pode revisar o hist\u00f3rico de commits para encontrar a origem do problema.</p> </li> <li> <p>Revers\u00e3o de altera\u00e7\u00f5es: Caso uma mudan\u00e7a cause problemas, \u00e9 poss\u00edvel reverter para uma vers\u00e3o anterior do c\u00f3digo de forma r\u00e1pida e segura. Isso minimiza o impacto de erros em produ\u00e7\u00e3o. Por exemplo, se uma nova funcionalidade causar falhas, a equipe pode reverter para a vers\u00e3o est\u00e1vel anterior enquanto trabalha na corre\u00e7\u00e3o.</p> </li> <li> <p>Integra\u00e7\u00e3o cont\u00ednua: O versionamento de c\u00f3digo \u00e9 a base para a integra\u00e7\u00e3o cont\u00ednua (CI), onde o c\u00f3digo \u00e9 frequentemente integrado e testado automaticamente. Isso garante que as mudan\u00e7as sejam verificadas continuamente, reduzindo o risco de problemas em produ\u00e7\u00e3o. Ferramentas como Jenkins e GitHub Actions s\u00e3o usadas para configurar pipelines de CI que automatizam esses processos.</p> </li> <li> <p>Entrega cont\u00ednua: Com o versionamento de c\u00f3digo, \u00e9 poss\u00edvel automatizar a entrega cont\u00ednua (CD), onde as mudan\u00e7as s\u00e3o automaticamente implantadas em ambientes de produ\u00e7\u00e3o ap\u00f3s passarem por testes rigorosos. Isso acelera o ciclo de desenvolvimento e entrega de software. Por exemplo, uma equipe pode configurar um pipeline de CD que implanta automaticamente novas vers\u00f5es da aplica\u00e7\u00e3o em um ambiente de produ\u00e7\u00e3o ap\u00f3s a aprova\u00e7\u00e3o dos testes.</p> </li> </ul> <p>Esses benef\u00edcios mostram como o versionamento de c\u00f3digo \u00e9 uma pr\u00e1tica indispens\u00e1vel para a implementa\u00e7\u00e3o bem-sucedida do DevOps, promovendo um desenvolvimento mais \u00e1gil, colaborativo e seguro.</p>"},{"location":"intro/#praticas-de-versionamento","title":"Pr\u00e1ticas de versionamento","text":"Nota importante sobre Git <p>Aqui, estou considerando que voc\u00ea j\u00e1 conhe\u00e7a o Git. Caso ainda n\u00e3o tenha familiaridade com a ferramenta, sugiro buscar algum material para estudo.</p> <p>Para mais detalhes, veja esse material , com algumas dicas iniciais de Git.</p> <p>Existem v\u00e1rias pr\u00e1ticas e conven\u00e7\u00f5es que podem ser adotadas para facilitar o versionamento de c\u00f3digo e a colabora\u00e7\u00e3o entre desenvolvedores. Alguns dos conceitos mais comuns incluem:</p> <ul> <li> <p>Branches: Dividir o c\u00f3digo em branches (ramifica\u00e7\u00f5es) separadas para desenvolver funcionalidades ou corre\u00e7\u00f5es de bugs isoladamente. Por exemplo, uma equipe pode criar um branch <code>feature/nova-funcionalidade</code> para implementar uma nova funcionalidade sem interferir no c\u00f3digo principal.</p> </li> <li> <p>Merges: Integrar as mudan\u00e7as de um branch para outro, geralmente usando pull requests. Por exemplo, ap\u00f3s concluir o desenvolvimento de uma funcionalidade em um branch de feature, a equipe pode abrir um pull request para mesclar as mudan\u00e7as no branch principal.</p> </li> <li> <p>Conventional Commits: Adotar uma conven\u00e7\u00e3o de mensagens de commit padronizada para facilitar a compreens\u00e3o do hist\u00f3rico de mudan\u00e7as. Por exemplo, prefixar as mensagens de commit com palavras-chave como <code>feat</code>, <code>fix</code>, <code>chore</code>, <code>docs</code>, <code>style</code>, <code>refactor</code>, <code>test</code> ou <code>ci</code> para indicar o tipo de altera\u00e7\u00e3o realizada.</p> </li> <li> <p>GitFlow: Seguir um modelo de branching como o GitFlow, que define um fluxo de trabalho com branches espec\u00edficos para features, releases, hotfixes e vers\u00f5es. Por exemplo, o GitFlow prop\u00f5e o uso de branches <code>feature/</code>, <code>release/</code>, <code>hotfix/</code> e <code>develop</code> para organizar o desenvolvimento de forma estruturada.</p> </li> </ul> <p>Essas pr\u00e1ticas ajudam a manter o c\u00f3digo organizado, facilitam a colabora\u00e7\u00e3o entre desenvolvedores e garantem a consist\u00eancia do hist\u00f3rico de mudan\u00e7as ao longo do tempo.</p>"},{"location":"intro/#praticas-de-semver","title":"Pr\u00e1ticas de SemVer","text":"<p>O SemVer (Semantic Versioning) \u00e9 uma conven\u00e7\u00e3o de versionamento que define um padr\u00e3o para atribuir vers\u00f5es a um software com base nas mudan\u00e7as realizadas. O SemVer \u00e9 composto por tr\u00eas n\u00fameros separados por pontos: <code>MAJOR.MINOR.PATCH</code>.</p> <ul> <li><code>MAJOR</code>: incrementado quando s\u00e3o feitas altera\u00e7\u00f5es incompat\u00edveis com vers\u00f5es anteriores.</li> <li><code>MINOR</code>: incrementado quando s\u00e3o adicionadas funcionalidades de forma retrocompat\u00edvel.</li> <li><code>PATCH</code>: incrementado quando s\u00e3o feitas corre\u00e7\u00f5es de bugs de forma retrocompat\u00edvel.</li> </ul> <p>Um exemplo de uso do SemVer seria:</p> <ul> <li><code>1.2.3</code>: vers\u00e3o <code>1</code> (major), <code>2</code> (minor) e <code>3</code> (patch).</li> </ul> <p>Essa conven\u00e7\u00e3o facilita a comunica\u00e7\u00e3o entre desenvolvedores, usu\u00e1rios e ferramentas, permitindo que todos entendam o impacto das mudan\u00e7as em uma nova vers\u00e3o do software. Por exemplo, ao seguir o SemVer, os usu\u00e1rios podem saber se uma atualiza\u00e7\u00e3o cont\u00e9m apenas corre\u00e7\u00f5es de bugs (<code>PATCH</code>), novas funcionalidades (<code>MINOR</code>) ou mudan\u00e7as incompat\u00edveis (<code>MAJOR</code>). No caso de uma API p\u00fablica, por exemplo, sabe-se que houver uma altera\u00e7\u00e3o no <code>MAJOR</code>, a API foi modificada de forma incompat\u00edvel com a vers\u00e3o anterior.</p>"},{"location":"intro/#conventional-commits","title":"Conventional Commits","text":"<p>O Conventional Commits \u00e9 uma conven\u00e7\u00e3o de mensagens de commit padronizada que facilita a compreens\u00e3o do hist\u00f3rico de mudan\u00e7as em um reposit\u00f3rio de c\u00f3digo. Essa conven\u00e7\u00e3o define um formato consistente para as mensagens de commit, permitindo que desenvolvedores e ferramentas identifiquem rapidamente o tipo de altera\u00e7\u00e3o realizada.</p> <p>Um bom local de consulta \u00e9 o site oficial do Conventional Commits, que fornece informa\u00e7\u00f5es detalhadas sobre a conven\u00e7\u00e3o, exemplos de mensagens de commit e recomenda\u00e7\u00f5es de uso. Ele \u00e9 mantido pela comunidade e \u00e9 uma refer\u00eancia \u00fatil para quem deseja adotar a conven\u00e7\u00e3o em seus projetos. O projeto foi inspirado em outras conven\u00e7\u00f5es de mensagens de commit, em especial o Angular Commit Message Guidelines.</p> <p>Em linhas gerais, as mensagens de commit seguem um padr\u00e3o predefinido, que inclui um prefixo indicando o tipo de altera\u00e7\u00e3o realizada, seguido de um t\u00edtulo descritivo. Alguns dos prefixos mais comuns incluem:</p> <ul> <li><code>feat</code>: Para novas funcionalidades ou melhorias</li> <li><code>fix</code>: Para corre\u00e7\u00f5es de bugs</li> <li><code>chore</code>: Para tarefas de manuten\u00e7\u00e3o ou refatora\u00e7\u00e3o</li> <li><code>docs</code>: Para altera\u00e7\u00f5es na documenta\u00e7\u00e3o</li> <li><code>style</code>: Para altera\u00e7\u00f5es de estilo ou formata\u00e7\u00e3o</li> <li><code>refactor</code>: Para refatora\u00e7\u00f5es de c\u00f3digo</li> <li><code>test</code>: Para adi\u00e7\u00f5es ou altera\u00e7\u00f5es em testes</li> <li><code>ci</code>: Para altera\u00e7\u00f5es em configura\u00e7\u00f5es de CI/CD</li> </ul> <p>Por exemplo, uma mensagem de commit seguindo a conven\u00e7\u00e3o Conventional Commits pode ser:</p> <pre><code>feat: adiciona funcionalidade de login\n</code></pre> <p>Essa mensagem indica que o commit adiciona uma nova funcionalidade de login ao projeto. Ao seguir essa conven\u00e7\u00e3o, os desenvolvedores podem facilmente identificar o prop\u00f3sito de cada commit e entender as mudan\u00e7as realizadas ao longo do tempo.</p> <p>Al\u00e9m disso, ferramentas de automa\u00e7\u00e3o, como linters e geradores de changelog, podem ser configuradas para analisar as mensagens de commit e gerar informa\u00e7\u00f5es \u00fateis, como logs de altera\u00e7\u00f5es e notas de vers\u00e3o automaticamente.</p> <p>A ado\u00e7\u00e3o do Conventional Commits \u00e9 uma pr\u00e1tica recomendada para equipes que buscam manter um hist\u00f3rico de mudan\u00e7as claro e organizado, facilitando a colabora\u00e7\u00e3o e a revis\u00e3o de c\u00f3digo.</p>"},{"location":"intro/#ferramentas-para-auxiliar-no-cumprimento-da-convencao","title":"Ferramentas para auxiliar no cumprimento da conven\u00e7\u00e3o","text":"<p>Para facilitar o uso do Conventional Commits, voc\u00ea pode instalar extens\u00f5es no Visual Studio Code que fornecem suporte para a conven\u00e7\u00e3o. Essas extens\u00f5es ajudam a formatar as mensagens de commit de acordo com a conven\u00e7\u00e3o, garantindo consist\u00eancia e facilitando a leitura do hist\u00f3rico de mudan\u00e7as.</p> <p>Uma extens\u00e3o popular para o Visual Studio Code \u00e9 o Conventional Commits, que fornece recursos como autocompletar, valida\u00e7\u00e3o e formata\u00e7\u00e3o das mensagens de commit de acordo com a conven\u00e7\u00e3o.</p> <p>Caso voc\u00ea n\u00e3o tenha interesse em fazer os commits dentro do VS Code, voc\u00ea pode utilizar ferramentas como o Commitizen para auxiliar na cria\u00e7\u00e3o de mensagens de commit seguindo a conven\u00e7\u00e3o. O Commitizen \u00e9 uma ferramenta de linha de comando que fornece um assistente interativo para criar mensagens de commit padronizadas.</p> <p>Ainda, \u00e9 poss\u00edvel utilizar ferramentas como o Commitlint e o Husky para validar as mensagens de commit automaticamente durante o processo de commit, garantindo que todas as mensagens sigam a conven\u00e7\u00e3o corretamente.</p>"},{"location":"renamedci/","title":"Integra\u00e7\u00e3o Cont\u00ednua","text":"<p>A integrac\u0327a\u0303o conti\u0301nua (CI) e\u0301 uma pra\u0301tica de desenvolvimento de software que consiste em integrar o co\u0301digo dos desenvolvedores em um reposito\u0301rio compartilhado com freque\u0302ncia, de prefere\u0302ncia va\u0301rias vezes ao dia. O objetivo da integrac\u0327a\u0303o conti\u0301nua e\u0301 detectar e corrigir problemas de integrac\u0327a\u0303o o mais ra\u0301pido possi\u0301vel, garantindo que o co\u0301digo seja sempre funcional e esteja em conformidade com as expectativas do projeto.</p> <p>Na pr\u00e1tica, a integrac\u0327a\u0303o conti\u0301nua envolve a automac\u0327a\u0303o de tarefas como compilac\u0327a\u0303o, testes e ana\u0301lise esta\u0301tica de co\u0301digo, que sa\u0303o executadas automaticamente sempre que um novo co\u0301digo e\u0301 integrado no reposito\u0301rio. Isso permite que a equipe de desenvolvimento identifique e corrija problemas rapidamente, evitando que bugs e erros se acumulem no co\u0301digo.</p> <p>Entre as principais funcionalidades da integrac\u0327a\u0303o conti\u0301nua, destacam-se:</p> <ul> <li>Automac\u0327a\u0303o de testes: a integrac\u0327a\u0303o conti\u0301nua permite a execuc\u0327a\u0303o automa\u0301tica de testes unita\u0301rios, testes de integrac\u0327a\u0303o e testes de aceitac\u0327a\u0303o sempre que o co\u0301digo e\u0301 integrado. Isso garante que o co\u0301digo seja testado continuamente e que novos bugs sejam identificados rapidamente.</li> <li>Compilac\u0327a\u0303o automa\u0301tica: a integrac\u0327a\u0303o conti\u0301nua tambe\u0301m inclui a compilac\u0327a\u0303o automa\u0301tica do co\u0301digo fonte sempre que uma alterac\u0327a\u0303o e\u0301 integrada. Isso permite que a equipe verifique se o co\u0301digo compila corretamente e se na\u0303o ha\u0301 erros de compilac\u0327a\u0303o.</li> <li>Linter e ana\u0301lise esta\u0301tica de co\u0301digo: a integrac\u0327a\u0303o conti\u0301nua tambe\u0301m pode incluir a execuc\u0327a\u0303o de ferramentas de ana\u0301lise esta\u0301tica de co\u0301digo e linters para identificar possi\u0301veis problemas de co\u0301digo, como ma\u0301s pra\u0301ticas, co\u0301digo duplicado e vulnerabilidades de seguranc\u0327a.</li> <li>Verifica\u00e7\u00e3o da qualidade do co\u0301digo: a integrac\u0327a\u0303o conti\u0301nua tambe\u0301m pode incluir a verificac\u0327a\u0303o da qualidade do co\u0301digo atrave\u0301s de me\u0301tricas de complexidade, cobertura de testes e outras me\u0301tricas de qualidade de co\u0301digo.</li> <li>Verifica\u00e7\u00e3o de seguran\u00e7a: a integrac\u0327a\u0303o conti\u0301nua tambe\u0301m pode incluir a verificac\u0327a\u0303o de vulnerabilidades de seguranc\u0327a no co\u0301digo fonte, garantindo que o co\u0301digo seja seguro e livre de vulnerabilidades conhecidas.</li> <li>Gera\u00e7\u00e3o de artefatos: a integrac\u0327a\u0303o conti\u0301nua tambe\u0301m pode incluir a gerac\u0327a\u0303o de artefatos, como builds compiladas, pacotes de instalac\u0327a\u0303o e documentac\u0327a\u0303o, que sa\u0303o usados para implantac\u0327a\u0303o e distribuic\u0327a\u0303o do software.</li> <li>Identifica\u00e7\u00e3o de pr\u00f3ximas vers\u00f5es: a integrac\u0327a\u0303o cont\u00ednua pode ser usada para identificar pr\u00f3ximas vers\u00f5es do software, gerando tags, vers\u00f5es e changelogs automaticamente.</li> <li>Gera\u00e7\u00e3o de tags e releases: a integrac\u0327a\u0303o cont\u00ednua pode gerar tags e releases automaticamente, facilitando o versionamento e a distribui\u00e7\u00e3o do software.</li> </ul> <p>Entre as principais ferramentas de integrac\u0327a\u0303o conti\u0301nua dispon\u00edveis no mercado, destacam-se o GitHub Actions, GitLab CI, Jenkins, Travis CI, CircleCI e Azure DevOps. Cada uma dessas ferramentas oferece recursos avan\u00e7ados de automa\u00e7\u00e3o, integra\u00e7\u00e3o com reposit\u00f3rios Git e suporte para diversas linguagens de programa\u00e7\u00e3o e tecnologias.</p> <p>Aqui, abordaremos apenas o GitHub Actions, que \u00e9 uma ferramenta de automa\u00e7\u00e3o de fluxos de trabalho integrada ao GitHub. O GitHub Actions permite a cria\u00e7\u00e3o de pipelines de CI/CD diretamente no reposit\u00f3rio, facilitando a automa\u00e7\u00e3o de tarefas como testes, compila\u00e7\u00e3o, an\u00e1lise de c\u00f3digo e implanta\u00e7\u00e3o. Al\u00e9m disso, possui uma comunidade ativa que disponibiliza diversos workflows prontos para uso em diferentes cen\u00e1rios.</p>"},{"location":"renamedci/#criando-um-projeto","title":"Criando um projeto","text":"<p>Neste guia, vamos criar um projeto simples em Python para demonstrar a integra\u00e7\u00e3o cont\u00ednua com o GitHub Actions. O projeto consistir\u00e1 em um script Python que realiza a soma de dois n\u00fameros e exibe o resultado.</p>"},{"location":"renamedci/#passo-a-passo","title":"Passo a passo","text":"<ul> <li> Crie um diret\u00f3rio para o projeto.</li> </ul> <p>Crie um diret\u00f3rio para o projeto em sua m\u00e1quina local e abra-o com o Visual Studio Code ou outro editor de sua prefer\u00eancia.</p> <ul> <li> Inicialize um reposit\u00f3rio Git</li> </ul> <p>Dentro do diret\u00f3rio do projeto, inicialize um reposit\u00f3rio Git com o comando:</p> <pre><code>git init\n</code></pre> <ul> <li> Crie um ambiente virtual</li> </ul> <p>Crie um ambiente virtual para o projeto com o comando:</p> <pre><code>python -m venv .venv\n</code></pre> <p>Em seguida, ative o ambiente virtual:</p> Linux e macOSWindows <pre><code>source .venv/bin/activate\n</code></pre> <pre><code>.venv\\Scripts\\activate\n</code></pre> <ul> <li> Configure o .gitignore</li> </ul> <p>Crie um arquivo <code>.gitignore</code> na raiz do projeto e adicione o seguinte conte\u00fado para ignorar o ambiente virtual e os arquivos <code>.pyc</code>:</p> .gitignore<pre><code>.venv\n*.pyc\n__pycache__/\n.pytest_cache/\n</code></pre> <ul> <li> Instale o <code>pytest</code></li> </ul> <p>Instale o <code>pytest</code> para realizar os testes unit\u00e1rios do projeto:</p> <pre><code>pip install pytest\n</code></pre> <ul> <li> Crie um arquivo de testes</li> </ul> <p>Crie um arquivo Python chamado <code>test_app.py</code> com o seguinte conte\u00fado:</p> test_app.py<pre><code>from app import sumF\n\n\ndef test_sum():\n    assert sumF(1, 2) == 3\n    assert sumF(2, 2) == 4\n    assert sumF(3, 2) == 5\n</code></pre> <p>Se rodarmos os testes agora, eles devem falhar, pois ainda n\u00e3o implementamos a fun\u00e7\u00e3o <code>sumF</code>. Para testar, execute o comando:</p> <pre><code>pytest\n</code></pre> <ul> <li> Crie um arquivo Python</li> </ul> <p>Crie um arquivo Python chamado <code>app.py</code> com o seguinte conte\u00fado:</p> app.py<pre><code>def sumF(a, b):\n    return a + b\n\n\nif __name__ == \"__main__\":\n    print(sumF(10, 10))\n</code></pre> <ul> <li> Execute os testes</li> </ul> <p>Execute os testes novamente com o comando <code>pytest</code>. Eles devem passar agora, pois a fun\u00e7\u00e3o <code>sumF</code> foi implementada e est\u00e1 correta.</p> <ul> <li> Crie um arquivo <code>requirements.txt</code></li> </ul> <p>Crie um arquivo <code>requirements.txt</code> com as depend\u00eancias do projeto:</p> <pre><code>pip freeze &gt; requirements.txt\n</code></pre>"},{"location":"renamedci/#fazendo-o-commit-inicial","title":"Fazendo o commit inicial","text":"<p>Neste momento, voc\u00ea j\u00e1 pode publicar a branch principal do projeto no GitHub. Para isso, voc\u00ea pode usar a pr\u00f3pria extens\u00e3o do Visual Studio Code ou os comandos do Git.</p> <p>Na pr\u00f3xima sess\u00e3o, vamos configurar o GitHub Actions para realizar a integra\u00e7\u00e3o cont\u00ednua do projeto.</p>"},{"location":"renamedci/#criacao-de-uma-imagem-docker","title":"Cria\u00e7\u00e3o de uma imagem Docker","text":"<p>Para criar uma imagem Docker, \u00e9 necess\u00e1rio criar um arquivo chamado <code>Dockerfile</code> na raiz do projeto. O <code>Dockerfile</code> \u00e9 um arquivo de configura\u00e7\u00e3o que define como a imagem Docker ser\u00e1 constru\u00edda, incluindo as depend\u00eancias, comandos e configura\u00e7\u00f5es necess\u00e1rias para executar a aplica\u00e7\u00e3o.</p> <p>Aqui est\u00e1 um exemplo de <code>Dockerfile</code> para um projeto Python simples:</p> Dockerfile<pre><code>FROM python:3.13-slim\nWORKDIR /app\nCOPY requirements.txt requirements.txt\nRUN pip install -r requirements.txt\nCOPY app.py app.py\nCMD [\"python\", \"app.py\"]\n</code></pre> <p>No arquivo criado, temos as seguintes instru\u00e7\u00f5es:</p> <ul> <li><code>FROM python:3.13-slim</code>: Define a imagem base a ser utilizada, neste caso, uma imagem Python 3.13 slim.</li> <li><code>WORKDIR /app</code>: Define o diret\u00f3rio de trabalho dentro da imagem.</li> <li><code>COPY requirements.txt requirements.txt</code>: Copia o arquivo <code>requirements.txt</code> para o diret\u00f3rio de trabalho.</li> <li><code>RUN pip install -r requirements.txt</code>: Instala as depend\u00eancias do projeto.</li> <li><code>COPY app.py app.py</code>: Copia o arquivo <code>app.py</code> para o diret\u00f3rio de trabalho.</li> <li><code>CMD [\"python\", \"app.py\"]</code>: Define o comando a ser executado quando o cont\u00eainer for iniciado.</li> </ul> <p>Note que n\u00e3o rodamos o comando <code>pytest</code> dentro do cont\u00eainer, pois os testes unit\u00e1rios devem ser executados antes de construir a imagem Docker. Para isso, podemos configurar um job no GitHub Actions para executar os testes antes de construir a imagem.</p>"},{"location":"renamedci/#testando-a-imagem-docker-localmente","title":"Testando a imagem Docker localmente","text":"<p>Para testar a imagem Docker localmente, voc\u00ea pode executar os seguintes comandos:</p> <ul> <li> Construir a imagem:</li> </ul> <pre><code>docker build -t ci-sum-python .\n</code></pre> <ul> <li> Executar o cont\u00eainer:</li> </ul> <pre><code>docker run --rm ci-sum-python\n</code></pre> <p>O comando <code>docker build</code> cria uma imagem Docker com o nome <code>ci-sum-python</code> a partir do <code>Dockerfile</code> presente no diret\u00f3rio atual. Em seguida, o comando <code>docker run</code> inicia um cont\u00eainer a partir da imagem criada, executando o arquivo <code>app.py</code> e exibindo a sa\u00edda no terminal.</p> <p>No caso do nosso exemplo, o arquivo <code>app.py</code> simplesmente soma dois n\u00fameros e imprime o resultado. Ao executar o cont\u00eainer, voc\u00ea deve ver a sa\u00edda correspondente \u00e0 soma dos n\u00fameros.</p>"},{"location":"renamedci/#configuracao-do-github-actions","title":"Configura\u00e7\u00e3o do GitHub Actions","text":"<p>O GitHub Actions permite a cria\u00e7\u00e3o de pipelines de CI/CD diretamente no reposit\u00f3rio, facilitando a automa\u00e7\u00e3o de tarefas como testes, compila\u00e7\u00e3o, an\u00e1lise de c\u00f3digo e implanta\u00e7\u00e3o. Para configurar o GitHub Actions, crie um arquivo chamado <code>.github/workflows/ci.yml</code> na raiz do projeto com o seguinte conte\u00fado:</p> <pre><code>name: ci-python\non: [push]\njobs:\n  check-application:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.13'\n          cache: 'pip'\n      - run: pip install -r requirements.txt\n      - run: pytest\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v1\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v1\n\n      - name: Build\n        id: docker_build\n        uses: docker/build-push-action@v2\n        with:\n          push: false\n</code></pre> <p>Neste arquivo de configura\u00e7\u00e3o, definimos um job chamado <code>check-application</code> que executa as seguintes etapas:</p> <ol> <li><code>actions/checkout@v4</code>: Faz o checkout do c\u00f3digo fonte do reposit\u00f3rio.</li> <li><code>actions/setup-python@v5</code>: Configura o ambiente Python com a vers\u00e3o 3.13 e o cache do <code>pip</code>.</li> <li><code>pip install -r requirements.txt</code>: Instala as depend\u00eancias do projeto.</li> <li><code>pytest</code>: Executa os testes unit\u00e1rios do projeto.</li> <li><code>docker/setup-qemu-action@v1</code>: Configura o QEMU para execu\u00e7\u00e3o de imagens multiplataforma.</li> <li><code>docker/setup-buildx-action@v1</code>: Configura o Buildx para constru\u00e7\u00e3o de imagens Docker.</li> <li><code>docker/build-push-action@v2</code>: Constr\u00f3i a imagem Docker a partir do <code>Dockerfile</code>.</li> </ol> <p>Note que o job <code>check-application</code> \u00e9 acionado sempre que ocorre um push no reposit\u00f3rio. Voc\u00ea pode personalizar as etapas de acordo com as necessidades do seu projeto, adicionando mais comandos, testes e a\u00e7\u00f5es espec\u00edficas.</p> <p>Tamb\u00e9m, na \u00faltima etapa, foi configurada a op\u00e7\u00e3o <code>push</code> como <code>false</code>, o que significa que a imagem Docker ser\u00e1 constru\u00edda, mas n\u00e3o ser\u00e1 enviada para um registro de cont\u00eainer. Voc\u00ea pode alterar essa op\u00e7\u00e3o para <code>true</code> e adicionar as credenciais necess\u00e1rias para fazer o push da imagem para um registro de cont\u00eainer. Nesta etapa, estamos apenas construindo a imagem para fins de demonstra\u00e7\u00e3o.</p>"},{"location":"renamedci/#executando-o-github-actions","title":"Executando o GitHub Actions","text":"<p>Para executar o GitHub Actions, fa\u00e7a um push das altera\u00e7\u00f5es no arquivo <code>.github/workflows/ci.yml</code> para o reposit\u00f3rio remoto. Ap\u00f3s o push, o GitHub Actions ser\u00e1 acionado automaticamente e voc\u00ea poder\u00e1 visualizar o status da execu\u00e7\u00e3o na aba \"Actions\" do reposit\u00f3rio.</p> <pre><code>\n</code></pre>"},{"location":"cd/","title":"Entrega Cont\u00ednua","text":"<p>J\u00e1 estudamos um pouco sobre a integra\u00e7\u00e3o cont\u00ednua, onde o c\u00f3digo \u00e9 integrado e testado automaticamente. Agora, vamos falar sobre a entrega cont\u00ednua.</p> <p>A entrega cont\u00ednua \u00e9 uma pr\u00e1tica de desenvolvimento de software onde as altera\u00e7\u00f5es no c\u00f3digo s\u00e3o automaticamente preparadas para um lan\u00e7amento em produ\u00e7\u00e3o. Isso significa que, ap\u00f3s cada altera\u00e7\u00e3o no c\u00f3digo, o software \u00e9 automaticamente testado e preparado para ser lan\u00e7ado, permitindo que novas funcionalidades sejam disponibilizadas rapidamente e com menos riscos.</p> <p>Uma t\u00e9cnica muito comum na aplica\u00e7\u00e3o da entrega cont\u00ednua \u00e9 o GitOps, que \u00e9 uma combina\u00e7\u00e3o de pr\u00e1ticas de desenvolvimento \u00e1gil e opera\u00e7\u00f5es de TI. O GitOps utiliza o Git como a \u00fanica fonte de verdade para a infraestrutura e as aplica\u00e7\u00f5es, permitindo que as equipes de desenvolvimento e opera\u00e7\u00f5es trabalhem juntas de forma mais eficiente.</p> <p>Ainda, podemos utilizar o GitOps para automatizar o processo de entrega cont\u00ednua, permitindo que as altera\u00e7\u00f5es no c\u00f3digo sejam automaticamente implantadas em ambientes de produ\u00e7\u00e3o. Isso reduz o tempo e o esfor\u00e7o necess\u00e1rios para implantar novas funcionalidades e corre\u00e7\u00f5es de bugs, al\u00e9m de aumentar a confiabilidade e a seguran\u00e7a do processo de entrega.</p> <p>Integrado ao ambiente de k8s que estamos utilizando, o GitOps pode ser utilizado para gerenciar a infraestrutura e as aplica\u00e7\u00f5es em cont\u00eaineres. Isso permite que as equipes de desenvolvimento e opera\u00e7\u00f5es trabalhem juntas de forma mais eficiente, utilizando pr\u00e1ticas \u00e1geis e automa\u00e7\u00e3o para implantar novas funcionalidades e corre\u00e7\u00f5es de bugs rapidamente.</p> <p>V\u00e1rias ferramentas podem ser utilizadas para implementar o GitOps, como o ArgoCD e o Flux. Essas ferramentas permitem que as equipes de desenvolvimento e opera\u00e7\u00f5es trabalhem juntas de forma mais eficiente, utilizando pr\u00e1ticas \u00e1geis e automa\u00e7\u00e3o para implantar novas funcionalidades e corre\u00e7\u00f5es de bugs rapidamente. Nas nossas aulas faremos uso do ArgoCD, que \u00e9 uma ferramenta de entrega cont\u00ednua para Kubernetes que permite implantar aplica\u00e7\u00f5es de forma automatizada e segura, e utiliza o Git como a \u00fanica fonte de verdade para a infraestrutura e as aplica\u00e7\u00f5es.</p>"},{"location":"cd/#instalacao-do-argocd","title":"Instala\u00e7\u00e3o do ArgoCD","text":"<p>Para instalar o ArgoCD, voc\u00ea pode usar o seguinte comando:</p> <pre><code>kubectl create namespace argocd\nkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n</code></pre> <p>Isso criar\u00e1 um namespace chamado <code>argocd</code> e instalar\u00e1 o ArgoCD nesse namespace. Ap\u00f3s a instala\u00e7\u00e3o, voc\u00ea pode acessar o ArgoCD atrav\u00e9s do seguinte comando:</p> <pre><code>kubectl port-forward svc/argocd-server -n argocd --address 0.0.0.0 8080:443\n</code></pre> <p>Isso far\u00e1 o encaminhamento da porta 8080 do seu computador local para a porta 443 do servi\u00e7o <code>argocd-server</code> no namespace <code>argocd</code>. Voc\u00ea pode acessar o ArgoCD em <code>https://localhost:8080</code>. O nome de usu\u00e1rio padr\u00e3o \u00e9 <code>admin</code> e a senha pode ser obtida com o seguinte comando:</p> <pre><code>kubectl get secret argocd-initial-admin-secret -n argocd -o jsonpath=\"{.data.password}\" | base64 -d; echo\n</code></pre> <p>Isso exibir\u00e1 a senha inicial do usu\u00e1rio <code>admin</code>.</p> <p>Agora j\u00e1 estamos preparados para utilizar o ArgoCD e implementar a entrega cont\u00ednua em nossos projetos. Vamos ver como fazer isso na pr\u00e1tica.</p> <p>Mas, antes, vamos preparar o reposit\u00f3rio do nosso projeto para que possamos utilizar o ArgoCD. Para isso, vamos criar um reposit\u00f3rio no GitHub e adicionar os arquivos de configura\u00e7\u00e3o do ArgoCD.</p>"},{"location":"cd/#preparacao-do-repositorio","title":"Prepara\u00e7\u00e3o do reposit\u00f3rio","text":"<p>Vamos continuar usando o projeto que criamos na aula anterior (orquestra\u00e7\u00e3o de cont\u00eaineres). Para isso, vamos criar um reposit\u00f3rio no GitHub e adicionar os arquivos de configura\u00e7\u00e3o do ArgoCD.</p> <p>Para tal suba o seu projeto para o GitHub, e crie um reposit\u00f3rio, por exemplo chamado <code>hello-fastapi-k8s</code> (esta \u00e9 apenas uma sugest\u00e3o). Ap\u00f3s subir a primeira vers\u00e3o para o repost\u00f3rio do GitHub, j\u00e1 sugiro que voc\u00ea crie os dois segredos no GitHub para fazer o upload da imagem do Docker para o Docker Hub e do arquivo de configura\u00e7\u00e3o do ArgoCD para o reposit\u00f3rio do GitHub.</p> <p>Para compatibilidade com o que mostraremos nos arquivos de configura\u00e7\u00e3o do workflow do GitHub, sugiro que voc\u00ea crie esses dois segredos com os seguintes nomes:</p> <ul> <li><code>DOCKERHUB_USERNAME</code>: seu nome de usu\u00e1rio do Docker Hub</li> <li><code>DOCKERHUB_TOKEN</code>: seu token de acesso do Docker Hub</li> </ul> <p>O <code>DOCKERHUB_TOKEN</code> pode ser gerado na sua conta do Docker Hub, na se\u00e7\u00e3o de configura\u00e7\u00f5es de seguran\u00e7a.</p> <p>Tamb\u00e9m \u00e9 necess\u00e1rio permitir que o GitHub Actions fa\u00e7a push no reposit\u00f3rio. Para isso, voc\u00ea deve acessar as configura\u00e7\u00f5es do seu reposit\u00f3rio no GitHub, clicar em <code>Actions</code> e depois em <code>General</code>. Na se\u00e7\u00e3o <code>Workflow permissions</code>, selecione a op\u00e7\u00e3o <code>Read and write permissions</code>. Isso permitir\u00e1 que o GitHub Actions fa\u00e7a push no reposit\u00f3rio.</p> <p>Agora, vamos criar o arquivo de configura\u00e7\u00e3o do fluxo de CI/CD do GitHub. Para isso, crie uma pasta chamada <code>.github</code> na raiz do seu reposit\u00f3rio e dentro dela crie outra pasta chamada <code>workflows</code>. Dentro da pasta <code>workflows</code>, crie um arquivo chamado <code>ci-cd.yml</code>. O caminho completo do arquivo deve ser <code>.github/workflows/ci-cd.yml</code>. Esse arquivo ser\u00e1 respons\u00e1vel por configurar o fluxo de CI/CD do GitHub. O conte\u00fado do arquivo deve ser o seguinte:</p> ./.github/workflows/ci-cd.yml<pre><code>name: CICD\n\non:\n  push:\n    branches: [main]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Login to DockerHub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Build and push Docker image\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          push: true\n          tags: |\n            eduardosilvasc/hello-fastapi-k8s:latest\n            eduardosilvasc/hello-fastapi-k8s:${{ github.sha }}\n\n      - name: Setup Kustomize\n        uses: imranismail/setup-kustomize@v2\n\n      - name: Update kustomization.yaml\n        run: |\n          cd k8s\n          kustomize edit set image hello-fastapi=eduardosilvasc/hello-fastapi-k8s:$GITHUB_SHA\n\n      - name: Commit changes\n        run: |\n          git config --local user.name \"GitHub Actions\"\n          git config --local user.email \"actions@github.com\"\n          git commit -am \"Update kustomization.yaml with new image\"\n\n      - name: Push changes\n        uses: ad-m/github-push-action@master\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          branch: ${{ github.ref }}\n</code></pre> <p>Note que eu fixei em alguns locais o nome da imagem como <code>eduardosilvasc/hello-fastapi-k8s</code>, que \u00e9 o nome do reposit\u00f3rio que eu criei no Docker Hub. Voc\u00ea deve alterar esse nome para o nome do reposit\u00f3rio que voc\u00ea criou no Docker Hub, e tamb\u00e9m o nome da imagem que voc\u00ea utilizar\u00e1. Esses nomes devem ser os mesmos que voc\u00ea utilizar\u00e1 no arquivo de configura\u00e7\u00e3o do ArgoCD, que veremos a seguir.</p>"},{"location":"cd/#configuracao-do-kustomize","title":"Configura\u00e7\u00e3o do Kustomize","text":"<p>Agora, vamos criar o arquivo de configura\u00e7\u00e3o do Kustomize. Para isso, crie uma pasta chamada <code>k8s</code> na raiz do seu reposit\u00f3rio e dentro dela crie um arquivo chamado <code>kustomization.yaml</code>. O caminho completo do arquivo deve ser <code>k8s/kustomization.yaml</code>. Esse arquivo ser\u00e1 respons\u00e1vel por configurar o Kustomize. O conte\u00fado do arquivo deve ser o seguinte:</p> ./k8s/kustomization.yaml<pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nresources:\n  - deployment.yaml\n  - service.yaml\nimages:\n  - name: hello-fastapi\n    newName: eduardosilvasc/hello-fastapi-k8s\n    newTag: c58b625834eb8b45c0d3d3b45ba4cbc288fc5146\n</code></pre> <p>No que, embora na pasta tamb\u00e9m tenhamos o arquivo <code>pod.yaml</code>, n\u00e3o o colocamos no <code>kustomization.yaml</code> porque ele n\u00e3o \u00e9 necess\u00e1rio para o ArgoCD. O ArgoCD ir\u00e1 criar o pod automaticamente a partir do deployment.</p> <p>Al\u00e9m disso, perceba que na declara\u00e7\u00e3o de <code>images</code> temos o par\u00e2metro <code>name</code> com nome que est\u00e1 no nome do template do <code>deployment.yaml</code>, e o par\u00e2metro <code>newName</code> com o nome da imagem que voc\u00ea subiu para o Docker Hub. O par\u00e2metro <code>newTag</code> deve ser o mesmo que voc\u00ea utilizar\u00e1 no arquivo de configura\u00e7\u00e3o do ArgoCD, que veremos a seguir.</p> <p>Com essa configura\u00e7\u00e3o feita, voc\u00ea j\u00e1 pode subir a sua atualiza\u00e7\u00e3o para o reposit\u00f3rio do GitHub. O fluxo de CI/CD do GitHub ir\u00e1 executar automaticamente o processo de build e push da imagem para o Docker Hub, e atualizar o arquivo <code>kustomization.yaml</code> com a nova tag da imagem. Isso significa que, sempre que voc\u00ea fizer uma altera\u00e7\u00e3o no c\u00f3digo e subir para o reposit\u00f3rio do GitHub, a imagem ser\u00e1 atualizada automaticamente no Docker Hub.</p>"},{"location":"cd/#configuracao-do-argocd","title":"Configura\u00e7\u00e3o do ArgoCD","text":"<p>Agora, vamos acessar o ArgoCD e criar um novo aplicativo. Para isso, acesse o ArgoCD em <code>https://localhost:8080</code> e fa\u00e7a login com o usu\u00e1rio <code>admin</code> e a senha que voc\u00ea obteve anteriormente.</p> <p>Ap\u00f3s fazer login, voc\u00ea ver\u00e1 a tela inicial do ArgoCD. Clique no bot\u00e3o <code>New App</code> para criar um novo aplicativo.</p> <p>Na tela de cria\u00e7\u00e3o do aplicativo, preencha os campos da seguinte forma:</p> <ul> <li>Application Name: hello-fastapi-k8s</li> <li>Project: default</li> <li>Sync Policy: Manual</li> <li>Repository URL: https://github.com/eduardo-da-silva/hello-fastapi-k8s.git</li> <li>Revision: HEAD</li> <li>Path: k8s</li> <li>Cluster: https://kubernetes.default.svc</li> <li>Namespace: default</li> </ul> <p>Com esses dados preenchidos, clique no bot\u00e3o <code>Create</code> para criar o aplicativo.</p> <p>Agora, voc\u00ea ver\u00e1 o aplicativo criado na tela inicial do ArgoCD. Clique no nome do aplicativo para acessar a tela de detalhes do aplicativo. Na tela de detalhes do aplicativo, voc\u00ea ver\u00e1 a \u00e1rvore de recursos do aplicativo. Clique no bot\u00e3o <code>Sync</code> para sincronizar o aplicativo com o reposit\u00f3rio do GitHub. Isso ir\u00e1 criar os recursos no Kubernetes a partir do arquivo <code>kustomization.yaml</code>.</p> <p>Ap\u00f3s a sincroniza\u00e7\u00e3o, voc\u00ea ver\u00e1 os recursos criados na \u00e1rvore de recursos do aplicativo. Voc\u00ea pode clicar em cada recurso para ver os detalhes do recurso.</p> <p>Como estamos executando o ArgoCD dentro de um cluster com o kind, n\u00e3o temos acesso ao servi\u00e7o que foi implantado com o Kustomize e o ArgoCD. Para acessar o servi\u00e7o, voc\u00ea pode usar o seguinte comando:</p> <pre><code>kubectl port-forward svc/hello-fastapi-service --address 0.0.0.0 8000:8000\n</code></pre> <p>Note que o nome do servi\u00e7o pode variar de acordo com o que voc\u00ea definiu no arquivo <code>service.yaml</code>. O comando acima far\u00e1 o encaminhamento da porta 8000 do seu computador local para a porta 8000 do servi\u00e7o. Esse n\u00famero de porta tamb\u00e9m pode variar de acordo com o que voc\u00ea definiu no arquivo <code>service.yaml</code>, <code>deployment.yaml</code> e na pr\u00f3pria aplica\u00e7\u00e3o FastAPI. Voc\u00ea pode acessar o servi\u00e7o em <code>http://localhost:8000</code>. Isso far\u00e1 com que voc\u00ea consiga acessar a aplica\u00e7\u00e3o FastAPI que foi implantada no Kubernetes.</p>"},{"location":"ci/","title":"Integra\u00e7\u00e3o Cont\u00ednua","text":"<p>A integrac\u0327a\u0303o conti\u0301nua (CI) e\u0301 uma pra\u0301tica de desenvolvimento de software que consiste em integrar o co\u0301digo dos desenvolvedores em um reposito\u0301rio compartilhado com freque\u0302ncia, de prefere\u0302ncia va\u0301rias vezes ao dia. O objetivo da integrac\u0327a\u0303o conti\u0301nua e\u0301 detectar e corrigir problemas de integrac\u0327a\u0303o o mais ra\u0301pido possi\u0301vel, garantindo que o co\u0301digo seja sempre funcional e esteja em conformidade com as expectativas do projeto.</p> <p>Na pr\u00e1tica, a integrac\u0327a\u0303o conti\u0301nua envolve a automac\u0327a\u0303o de tarefas como compilac\u0327a\u0303o, testes e ana\u0301lise esta\u0301tica de co\u0301digo, que sa\u0303o executadas automaticamente sempre que um novo co\u0301digo e\u0301 integrado no reposito\u0301rio. Isso permite que a equipe de desenvolvimento identifique e corrija problemas rapidamente, evitando que bugs e erros se acumulem no co\u0301digo.</p> <p>Entre as principais funcionalidades da integrac\u0327a\u0303o conti\u0301nua, destacam-se:</p> <ul> <li>Automac\u0327a\u0303o de testes: a integrac\u0327a\u0303o conti\u0301nua permite a execuc\u0327a\u0303o automa\u0301tica de testes unita\u0301rios, testes de integrac\u0327a\u0303o e testes de aceitac\u0327a\u0303o sempre que o co\u0301digo e\u0301 integrado. Isso garante que o co\u0301digo seja testado continuamente e que novos bugs sejam identificados rapidamente.</li> <li>Compilac\u0327a\u0303o automa\u0301tica: a integrac\u0327a\u0303o conti\u0301nua tambe\u0301m inclui a compilac\u0327a\u0303o automa\u0301tica do co\u0301digo fonte sempre que uma alterac\u0327a\u0303o e\u0301 integrada. Isso permite que a equipe verifique se o co\u0301digo compila corretamente e se na\u0303o ha\u0301 erros de compilac\u0327a\u0303o.</li> <li>Linter e ana\u0301lise esta\u0301tica de co\u0301digo: a integrac\u0327a\u0303o conti\u0301nua tambe\u0301m pode incluir a execuc\u0327a\u0303o de ferramentas de ana\u0301lise esta\u0301tica de co\u0301digo e linters para identificar possi\u0301veis problemas de co\u0301digo, como ma\u0301s pra\u0301ticas, co\u0301digo duplicado e vulnerabilidades de seguranc\u0327a.</li> <li>Verifica\u00e7\u00e3o da qualidade do co\u0301digo: a integrac\u0327a\u0303o conti\u0301nua tambe\u0301m pode incluir a verificac\u0327a\u0303o da qualidade do co\u0301digo atrave\u0301s de me\u0301tricas de complexidade, cobertura de testes e outras me\u0301tricas de qualidade de co\u0301digo.</li> <li>Verifica\u00e7\u00e3o de seguran\u00e7a: a integrac\u0327a\u0303o conti\u0301nua tambe\u0301m pode incluir a verificac\u0327a\u0303o de vulnerabilidades de seguranc\u0327a no co\u0301digo fonte, garantindo que o co\u0301digo seja seguro e livre de vulnerabilidades conhecidas.</li> <li>Gera\u00e7\u00e3o de artefatos: a integrac\u0327a\u0303o conti\u0301nua tambe\u0301m pode incluir a gerac\u0327a\u0303o de artefatos, como builds compiladas, pacotes de instalac\u0327a\u0303o e documentac\u0327a\u0303o, que sa\u0303o usados para implantac\u0327a\u0303o e distribuic\u0327a\u0303o do software.</li> <li>Identifica\u00e7\u00e3o de pr\u00f3ximas vers\u00f5es: a integrac\u0327a\u0303o cont\u00ednua pode ser usada para identificar pr\u00f3ximas vers\u00f5es do software, gerando tags, vers\u00f5es e changelogs automaticamente.</li> <li>Gera\u00e7\u00e3o de tags e releases: a integrac\u0327a\u0303o cont\u00ednua pode gerar tags e releases automaticamente, facilitando o versionamento e a distribui\u00e7\u00e3o do software.</li> </ul> <p>Entre as principais ferramentas de integrac\u0327a\u0303o conti\u0301nua dispon\u00edveis no mercado, destacam-se o GitHub Actions, GitLab CI, Jenkins, Travis CI, CircleCI e Azure DevOps. Cada uma dessas ferramentas oferece recursos avan\u00e7ados de automa\u00e7\u00e3o, integra\u00e7\u00e3o com reposit\u00f3rios Git e suporte para diversas linguagens de programa\u00e7\u00e3o e tecnologias.</p> <p>Aqui, abordaremos apenas o GitHub Actions, que \u00e9 uma ferramenta de automa\u00e7\u00e3o de fluxos de trabalho integrada ao GitHub. O GitHub Actions permite a cria\u00e7\u00e3o de pipelines de CI/CD diretamente no reposit\u00f3rio, facilitando a automa\u00e7\u00e3o de tarefas como testes, compila\u00e7\u00e3o, an\u00e1lise de c\u00f3digo e implanta\u00e7\u00e3o. Al\u00e9m disso, possui uma comunidade ativa que disponibiliza diversos workflows prontos para uso em diferentes cen\u00e1rios.</p>"},{"location":"ci/#criando-um-projeto","title":"Criando um projeto","text":"<p>Neste guia, vamos criar um projeto simples em Python para demonstrar a integra\u00e7\u00e3o cont\u00ednua com o GitHub Actions. O projeto consistir\u00e1 em um script Python que realiza a soma de dois n\u00fameros e exibe o resultado.</p>"},{"location":"ci/#passo-a-passo","title":"Passo a passo","text":"<ul> <li> Crie um diret\u00f3rio para o projeto.</li> </ul> <p>Crie um diret\u00f3rio para o projeto em sua m\u00e1quina local e abra-o com o Visual Studio Code ou outro editor de sua prefer\u00eancia.</p> <ul> <li> Inicialize um reposit\u00f3rio Git</li> </ul> <p>Dentro do diret\u00f3rio do projeto, inicialize um reposit\u00f3rio Git com o comando:</p> <pre><code>git init\n</code></pre> <ul> <li> Crie um ambiente virtual</li> </ul> <p>Crie um ambiente virtual para o projeto com o comando:</p> <pre><code>python -m venv .venv\n</code></pre> <p>Em seguida, ative o ambiente virtual:</p> Linux e macOSWindows <pre><code>source .venv/bin/activate\n</code></pre> <pre><code>.venv\\Scripts\\activate\n</code></pre> <ul> <li> Configure o .gitignore</li> </ul> <p>Crie um arquivo <code>.gitignore</code> na raiz do projeto e adicione o seguinte conte\u00fado para ignorar o ambiente virtual e os arquivos <code>.pyc</code>:</p> .gitignore<pre><code>.venv\n*.pyc\n__pycache__/\n.pytest_cache/\n</code></pre> <ul> <li> Instale o <code>pytest</code></li> </ul> <p>Instale o <code>pytest</code> para realizar os testes unit\u00e1rios do projeto:</p> <pre><code>pip install pytest\n</code></pre> <ul> <li> Crie um arquivo de testes</li> </ul> <p>Crie um arquivo Python chamado <code>test_app.py</code> com o seguinte conte\u00fado:</p> test_app.py<pre><code>from app import sumF\n\n\ndef test_sum():\n    assert sumF(1, 2) == 3\n    assert sumF(2, 2) == 4\n    assert sumF(3, 2) == 5\n</code></pre> <p>Se rodarmos os testes agora, eles devem falhar, pois ainda n\u00e3o implementamos a fun\u00e7\u00e3o <code>sumF</code>. Para testar, execute o comando:</p> <pre><code>pytest\n</code></pre> <ul> <li> Crie um arquivo Python</li> </ul> <p>Crie um arquivo Python chamado <code>app.py</code> com o seguinte conte\u00fado:</p> app.py<pre><code>def sumF(a, b):\n    return a + b\n\n\nif __name__ == \"__main__\":\n    print(sumF(10, 10))\n</code></pre> <ul> <li> Execute os testes</li> </ul> <p>Execute os testes novamente com o comando <code>pytest</code>. Eles devem passar agora, pois a fun\u00e7\u00e3o <code>sumF</code> foi implementada e est\u00e1 correta.</p> <ul> <li> Crie um arquivo <code>requirements.txt</code></li> </ul> <p>Crie um arquivo <code>requirements.txt</code> com as depend\u00eancias do projeto:</p> <pre><code>pip freeze &gt; requirements.txt\n</code></pre>"},{"location":"ci/#fazendo-o-commit-inicial","title":"Fazendo o commit inicial","text":"<p>Neste momento, voc\u00ea j\u00e1 pode publicar a branch principal do projeto no GitHub. Para isso, voc\u00ea pode usar a pr\u00f3pria extens\u00e3o do Visual Studio Code ou os comandos do Git.</p> <p>Na pr\u00f3xima sess\u00e3o, vamos configurar o GitHub Actions para realizar a integra\u00e7\u00e3o cont\u00ednua do projeto.</p>"},{"location":"ci/#criacao-de-uma-imagem-docker","title":"Cria\u00e7\u00e3o de uma imagem Docker","text":"<p>Para criar uma imagem Docker, \u00e9 necess\u00e1rio criar um arquivo chamado <code>Dockerfile</code> na raiz do projeto. O <code>Dockerfile</code> \u00e9 um arquivo de configura\u00e7\u00e3o que define como a imagem Docker ser\u00e1 constru\u00edda, incluindo as depend\u00eancias, comandos e configura\u00e7\u00f5es necess\u00e1rias para executar a aplica\u00e7\u00e3o.</p> <p>Aqui est\u00e1 um exemplo de <code>Dockerfile</code> para um projeto Python simples:</p> Dockerfile<pre><code>FROM python:3.13-slim\nWORKDIR /app\nCOPY requirements.txt requirements.txt\nRUN pip install -r requirements.txt\nCOPY app.py app.py\nCMD [\"python\", \"app.py\"]\n</code></pre> <p>No arquivo criado, temos as seguintes instru\u00e7\u00f5es:</p> <ul> <li><code>FROM python:3.13-slim</code>: Define a imagem base a ser utilizada, neste caso, uma imagem Python 3.13 slim.</li> <li><code>WORKDIR /app</code>: Define o diret\u00f3rio de trabalho dentro da imagem.</li> <li><code>COPY requirements.txt requirements.txt</code>: Copia o arquivo <code>requirements.txt</code> para o diret\u00f3rio de trabalho.</li> <li><code>RUN pip install -r requirements.txt</code>: Instala as depend\u00eancias do projeto.</li> <li><code>COPY app.py app.py</code>: Copia o arquivo <code>app.py</code> para o diret\u00f3rio de trabalho.</li> <li><code>CMD [\"python\", \"app.py\"]</code>: Define o comando a ser executado quando o cont\u00eainer for iniciado.</li> </ul> <p>Note que n\u00e3o rodamos o comando <code>pytest</code> dentro do cont\u00eainer, pois os testes unit\u00e1rios devem ser executados antes de construir a imagem Docker. Para isso, podemos configurar um job no GitHub Actions para executar os testes antes de construir a imagem.</p>"},{"location":"ci/#testando-a-imagem-docker-localmente","title":"Testando a imagem Docker localmente","text":"<p>Para testar a imagem Docker localmente, voc\u00ea pode executar os seguintes comandos:</p> <ul> <li> Construir a imagem:</li> </ul> <pre><code>docker build -t ci-sum-python .\n</code></pre> <ul> <li> Executar o cont\u00eainer:</li> </ul> <pre><code>docker run --rm ci-sum-python\n</code></pre> <p>O comando <code>docker build</code> cria uma imagem Docker com o nome <code>ci-sum-python</code> a partir do <code>Dockerfile</code> presente no diret\u00f3rio atual. Em seguida, o comando <code>docker run</code> inicia um cont\u00eainer a partir da imagem criada, executando o arquivo <code>app.py</code> e exibindo a sa\u00edda no terminal.</p> <p>No caso do nosso exemplo, o arquivo <code>app.py</code> simplesmente soma dois n\u00fameros e imprime o resultado. Ao executar o cont\u00eainer, voc\u00ea deve ver a sa\u00edda correspondente \u00e0 soma dos n\u00fameros.</p>"},{"location":"ci/#configuracao-do-github-actions","title":"Configura\u00e7\u00e3o do GitHub Actions","text":"<p>O GitHub Actions permite a cria\u00e7\u00e3o de pipelines de CI/CD diretamente no reposit\u00f3rio, facilitando a automa\u00e7\u00e3o de tarefas como testes, compila\u00e7\u00e3o, an\u00e1lise de c\u00f3digo e implanta\u00e7\u00e3o. Para configurar o GitHub Actions, crie um arquivo chamado <code>.github/workflows/ci.yml</code> na raiz do projeto com o seguinte conte\u00fado:</p> <pre><code>name: ci-python\non: [push]\njobs:\n  check-application:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.13'\n          cache: 'pip'\n      - run: pip install -r requirements.txt\n      - run: pytest\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v1\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v1\n\n      - name: Build\n        id: docker_build\n        uses: docker/build-push-action@v2\n        with:\n          push: false\n</code></pre> <p>Neste arquivo de configura\u00e7\u00e3o, definimos um job chamado <code>check-application</code> que executa as seguintes etapas:</p> <ol> <li><code>actions/checkout@v4</code>: Faz o checkout do c\u00f3digo fonte do reposit\u00f3rio.</li> <li><code>actions/setup-python@v5</code>: Configura o ambiente Python com a vers\u00e3o 3.13 e o cache do <code>pip</code>.</li> <li><code>pip install -r requirements.txt</code>: Instala as depend\u00eancias do projeto.</li> <li><code>pytest</code>: Executa os testes unit\u00e1rios do projeto.</li> <li><code>docker/setup-qemu-action@v1</code>: Configura o QEMU para execu\u00e7\u00e3o de imagens multiplataforma.</li> <li><code>docker/setup-buildx-action@v1</code>: Configura o Buildx para constru\u00e7\u00e3o de imagens Docker.</li> <li><code>docker/build-push-action@v2</code>: Constr\u00f3i a imagem Docker a partir do <code>Dockerfile</code>.</li> </ol> <p>Note que o job <code>check-application</code> \u00e9 acionado sempre que ocorre um push no reposit\u00f3rio. Voc\u00ea pode personalizar as etapas de acordo com as necessidades do seu projeto, adicionando mais comandos, testes e a\u00e7\u00f5es espec\u00edficas.</p> <p>Tamb\u00e9m, na \u00faltima etapa, foi configurada a op\u00e7\u00e3o <code>push</code> como <code>false</code>, o que significa que a imagem Docker ser\u00e1 constru\u00edda, mas n\u00e3o ser\u00e1 enviada para um registro de cont\u00eainer. Voc\u00ea pode alterar essa op\u00e7\u00e3o para <code>true</code> e adicionar as credenciais necess\u00e1rias para fazer o push da imagem para um registro de cont\u00eainer. Nesta etapa, estamos apenas construindo a imagem para fins de demonstra\u00e7\u00e3o.</p>"},{"location":"ci/#executando-o-github-actions","title":"Executando o GitHub Actions","text":"<p>Para executar o GitHub Actions, fa\u00e7a um push das altera\u00e7\u00f5es no arquivo <code>.github/workflows/ci.yml</code> para o reposit\u00f3rio remoto. Ap\u00f3s o push, o GitHub Actions ser\u00e1 acionado automaticamente e voc\u00ea poder\u00e1 visualizar o status da execu\u00e7\u00e3o na aba \"Actions\" do reposit\u00f3rio.</p>"},{"location":"ci/#automatizando-o-upload-da-imagem-docker-para-o-dockerhub","title":"Automatizando o upload da imagem Docker para o DockerHub","text":"<p>Nesta etapa, vamos automatizar o upload da imagem Docker para o DockerHub sempre que houver um push no reposit\u00f3rio. Isso \u00e9 \u00fatil para garantir que a imagem mais recente esteja sempre dispon\u00edvel em um registro de cont\u00eainer, facilitando a implanta\u00e7\u00e3o em diferentes ambientes.</p> <p>Para isso, vamos usar o GitHub Actions para criar um pipeline de CI/CD que constr\u00f3i a imagem Docker e faz o upload para o DockerHub. O pipeline ser\u00e1 acionado sempre que houver um push no reposit\u00f3rio, garantindo que a imagem mais recente esteja sempre dispon\u00edvel.</p>"},{"location":"ci/#configurando-o-dockerhub","title":"Configurando o DockerHub","text":"<p>O DockerHub \u00e9 um servi\u00e7o de registro de cont\u00eaineres que permite armazenar e compartilhar imagens Docker. Depois que temos um container gerado, no processo de DevOps, \u00e9 comum fazer o upload da imagem para um registro de cont\u00eaineres, como o DockerHub, para facilitar a distribui\u00e7\u00e3o e implanta\u00e7\u00e3o da aplica\u00e7\u00e3o em diferentes ambientes.</p> <p>Para isso, \u00e9 necess\u00e1rio que tenhamos uma conta no DockerHub. Caso n\u00e3o tenha, voc\u00ea pode criar uma conta gratuita em DockerHub. Como a conta criada, voc\u00ea poderia fazer o upload da imagem usando o comando <code>docker push</code>, mas como o objetivo \u00e9 fazer isso de forma automatizada, vamos configurar o GitHub Actions para fazer o upload da imagem Docker para o DockerHub sempre que houver um push no reposit\u00f3rio.</p> <p>Ent\u00e3o, precisamos gerar um token de acesso no DockerHub para permitir que o GitHub Actions fa\u00e7a o upload da imagem. Para isso, siga os passos abaixo:</p> <ol> <li>Acesse sua conta no DockerHub.</li> <li>Clique na sua foto de perfil no canto superior direito e selecione \"Account Settings\".</li> <li>Na se\u00e7\u00e3o \"Personal Access Tokens\", clique em \"Generate New Token\".</li> <li>D\u00ea um nome para o token, defina um prazo de expira\u00e7\u00e3o e as permiss\u00f5es de acesso (recomendado \"Read, Write, and Delete\").</li> <li>Clique em \"Generate\" e copie o token gerado. Guarde-o em um local seguro, pois voc\u00ea n\u00e3o poder\u00e1 v\u00ea-lo novamente.</li> </ol> <p>Nas pr\u00f3ximas etapas, vamos configurar o GitHub Actions para fazer o upload da imagem Docker para o DockerHub usando esse token de acesso.</p>"},{"location":"ci/#guardando-o-token-no-github","title":"Guardando o token no GitHub","text":"<p>Agora que temos o token de acesso do DockerHub, precisamos armazen\u00e1-lo como um segredo no reposit\u00f3rio do GitHub. Isso permitir\u00e1 que o GitHub Actions acesse o token de forma segura durante a execu\u00e7\u00e3o do pipeline.</p> <p>Para armazenar o token como um segredo no GitHub, siga os passos abaixo:</p> <ol> <li>Acesse o reposit\u00f3rio do GitHub onde voc\u00ea configurou o GitHub Actions.</li> <li>Clique na aba \"Settings\" (Configura\u00e7\u00f5es) do reposit\u00f3rio.</li> <li>No menu lateral, clique em \"Secrets and variables\" e depois em \"Actions\".</li> <li>Clique no bot\u00e3o \"New repository secret\" (Novo segredo do reposit\u00f3rio).</li> <li>D\u00ea um nome para o segredo, como <code>DOCKERHUB_TOKEN</code>, e cole o token de acesso que voc\u00ea gerou no DockerHub.</li> <li>Clique em \"Add secret\" (Adicionar segredo) para salvar o token.</li> <li>Agora, o token estar\u00e1 dispon\u00edvel como um segredo no GitHub Actions e poder\u00e1 ser usado no pipeline de CI/CD.</li> </ol> <p>Sugiro tamb\u00e9m que voc\u00ea crie um segredo para o seu usu\u00e1rio do DockerHub, que ser\u00e1 usado para fazer o login no DockerHub. Para isso, siga os passos abaixo:</p> <ol> <li>Acesse o reposit\u00f3rio do GitHub onde voc\u00ea configurou o GitHub Actions.</li> <li>Clique na aba \"Settings\" (Configura\u00e7\u00f5es) do reposit\u00f3rio.</li> <li>No menu lateral, clique em \"Secrets and variables\" e depois em \"Actions\".</li> <li>Clique no bot\u00e3o \"New repository secret\" (Novo segredo do reposit\u00f3rio).</li> <li>D\u00ea um nome para o segredo, como <code>DOCKERHUB_USERNAME</code>, e cole o seu nome de usu\u00e1rio do DockerHub.</li> <li>Clique em \"Add secret\" (Adicionar segredo) para salvar o token.</li> <li>Agora, o token estar\u00e1 dispon\u00edvel como um segredo no GitHub Actions e poder\u00e1 ser usado no pipeline de CI/CD.</li> </ol> <p>Com isso, voc\u00ea j\u00e1 tem os segredos necess\u00e1rios para fazer o upload da imagem Docker para o DockerHub. Agora, vamos configurar o GitHub Actions para fazer isso automaticamente sempre que houver um push no reposit\u00f3rio.</p>"},{"location":"ci/#configurando-o-github-actions-para-fazer-o-upload-da-imagem-docker","title":"Configurando o GitHub Actions para fazer o upload da imagem Docker","text":"<p>Agora que temos os segredos armazenados no GitHub, precisamos configurar o GitHub Actions para fazer o upload da imagem Docker para o DockerHub. Para isso, vamos editar o arquivo <code>.github/workflows/ci.yml</code> que criamos anteriormente e adicionar as etapas necess\u00e1rias para fazer o upload da imagem.</p> <p>Aqui est\u00e1 um exemplo de como o arquivo <code>.github/workflows/ci.yml</code> pode ficar ap\u00f3s as altera\u00e7\u00f5es:</p> .github/workflows/ci.yml<pre><code>name: ci-python\non: [push]\njobs:\n  check-application:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.13'\n          cache: 'pip'\n      - run: pip install -r requirements.txt\n      - run: pytest\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v1\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v1\n\n      - name: Login to DockerHub\n        uses: docker/login-action@v2\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }} # (1)\n          password: ${{ secrets.DOCKERHUB_TOKEN }} # (2)\n\n      - name: Build and Push to DockerHub\n        id: docker_build_push\n        uses: docker/build-push-action@v2\n        with:\n          push: true # (3)\n          tags: your-dockerhub-username/ci-sum-python:${{ github.sha }} # (4)\n</code></pre> <ol> <li>A express\u00e3o <code>${{ secrets.DOCKERHUB_USERNAME }}</code> indica o segredo que voc\u00ea criou para o seu nome de usu\u00e1rio do DockerHub.</li> <li>A express\u00e3o <code>${{ secrets.DOCKERHUB_TOKEN }}</code> indica o segredo que voc\u00ea criou para o token de acesso do DockerHub.</li> <li>A linha <code>push: true</code> indica que a imagem deve ser enviada para o DockerHub ap\u00f3s a constru\u00e7\u00e3o.</li> <li>Aqui voc\u00ea deve substituir <code>your-dockerhub-username</code> pelo seu nome de usu\u00e1rio do DockerHub, como configurado nos segredos, usando <code>${{ secrets.DOCKERHUB_USERNAME }}</code>. O <code>ci-sum-python</code> \u00e9 o nome da imagem que voc\u00ea deseja usar no DockerHub, e <code>${{ github.sha }}</code> \u00e9 a tag da imagem que ser\u00e1 gerada.</li> </ol> <p>Note que usamos a vari\u00e1vel <code>${{ github.sha }}</code> para gerar uma tag \u00fanica para cada commit, o que \u00e9 \u00fatil para identificar a vers\u00e3o da imagem correspondente ao commit. Voc\u00ea pode personalizar essa tag de acordo com suas necessidades, como usar um n\u00famero de vers\u00e3o espec\u00edfico ou uma tag mais amig\u00e1vel. Tamb\u00e9m pode ser usada a palavra <code>latest</code>, mas somente isso n\u00e3o \u00e9 recomendado, pois pode causar confus\u00e3o ao identificar qual vers\u00e3o da imagem est\u00e1 sendo usada.</p>"},{"location":"ci/#executando-o-github-actions_1","title":"Executando o GitHub Actions","text":"<p>Para executar o GitHub Actions, fa\u00e7a um push das altera\u00e7\u00f5es no arquivo <code>.github/workflows/ci.yml</code> para o reposit\u00f3rio remoto. Ap\u00f3s o push, o GitHub Actions ser\u00e1 acionado automaticamente e voc\u00ea poder\u00e1 visualizar o status da execu\u00e7\u00e3o na aba \"Actions\" do reposit\u00f3rio.</p> <p>Se tudo estiver configurado corretamente, o GitHub Actions ir\u00e1 construir a imagem Docker e fazer o upload para o DockerHub automaticamente. Voc\u00ea pode verificar se a imagem foi enviada com sucesso acessando sua conta no DockerHub e verificando se a imagem <code>ci-sum-python</code> est\u00e1 dispon\u00edvel no seu reposit\u00f3rio.</p> <p>Em seguida, voc\u00ea pode usar a imagem Docker em qualquer lugar, como em um servidor de produ\u00e7\u00e3o ou em um ambiente de desenvolvimento local, usando o comando <code>docker pull your-dockerhub-username/ci-sum-python:latest</code> ou <code>docker pull your-dockerhub-username/ci-sum-python:sha</code>, onde <code>sha</code> \u00e9 o hash do commit que voc\u00ea deseja usar. Note que voc\u00ea deve estar atento ao nome que voc\u00ea deu para a imagem, na op\u00e7\u00e3o <code>tags</code>, e usar o mesmo nome para fazer o pull da imagem.</p>"},{"location":"ci/configurando-deploy-dockerhub/","title":"Configurando deploy dockerhub","text":""},{"location":"ci/configurando-deploy-dockerhub/#automatizando-o-upload-da-imagem-docker-para-o-dockerhub","title":"Automatizando o upload da imagem Docker para o DockerHub","text":"<p>Nesta etapa, vamos automatizar o upload da imagem Docker para o DockerHub sempre que houver um push no reposit\u00f3rio. Isso \u00e9 \u00fatil para garantir que a imagem mais recente esteja sempre dispon\u00edvel em um registro de cont\u00eainer, facilitando a implanta\u00e7\u00e3o em diferentes ambientes.</p> <p>Para isso, vamos usar o GitHub Actions para criar um pipeline de CI/CD que constr\u00f3i a imagem Docker e faz o upload para o DockerHub. O pipeline ser\u00e1 acionado sempre que houver um push no reposit\u00f3rio, garantindo que a imagem mais recente esteja sempre dispon\u00edvel.</p>"},{"location":"ci/configurando-deploy-dockerhub/#configurando-o-dockerhub","title":"Configurando o DockerHub","text":"<p>O DockerHub \u00e9 um servi\u00e7o de registro de cont\u00eaineres que permite armazenar e compartilhar imagens Docker. Depois que temos um container gerado, no processo de DevOps, \u00e9 comum fazer o upload da imagem para um registro de cont\u00eaineres, como o DockerHub, para facilitar a distribui\u00e7\u00e3o e implanta\u00e7\u00e3o da aplica\u00e7\u00e3o em diferentes ambientes.</p> <p>Para isso, \u00e9 necess\u00e1rio que tenhamos uma conta no DockerHub. Caso n\u00e3o tenha, voc\u00ea pode criar uma conta gratuita em DockerHub. Como a conta criada, voc\u00ea poderia fazer o upload da imagem usando o comando <code>docker push</code>, mas como o objetivo \u00e9 fazer isso de forma automatizada, vamos configurar o GitHub Actions para fazer o upload da imagem Docker para o DockerHub sempre que houver um push no reposit\u00f3rio.</p> <p>Ent\u00e3o, precisamos gerar um token de acesso no DockerHub para permitir que o GitHub Actions fa\u00e7a o upload da imagem. Para isso, siga os passos abaixo:</p> <ol> <li>Acesse sua conta no DockerHub.</li> <li>Clique na sua foto de perfil no canto superior direito e selecione \"Account Settings\".</li> <li>Na se\u00e7\u00e3o \"Personal Access Tokens\", clique em \"Generate New Token\".</li> <li>D\u00ea um nome para o token, defina um prazo de expira\u00e7\u00e3o e as permiss\u00f5es de acesso (recomendado \"Read, Write, and Delete\").</li> <li>Clique em \"Generate\" e copie o token gerado. Guarde-o em um local seguro, pois voc\u00ea n\u00e3o poder\u00e1 v\u00ea-lo novamente.</li> </ol> <p>Nas pr\u00f3ximas etapas, vamos configurar o GitHub Actions para fazer o upload da imagem Docker para o DockerHub usando esse token de acesso.</p>"},{"location":"ci/configurando-deploy-dockerhub/#guardando-o-token-no-github","title":"Guardando o token no GitHub","text":"<p>Agora que temos o token de acesso do DockerHub, precisamos armazen\u00e1-lo como um segredo no reposit\u00f3rio do GitHub. Isso permitir\u00e1 que o GitHub Actions acesse o token de forma segura durante a execu\u00e7\u00e3o do pipeline.</p> <p>Para armazenar o token como um segredo no GitHub, siga os passos abaixo:</p> <ol> <li>Acesse o reposit\u00f3rio do GitHub onde voc\u00ea configurou o GitHub Actions.</li> <li>Clique na aba \"Settings\" (Configura\u00e7\u00f5es) do reposit\u00f3rio.</li> <li>No menu lateral, clique em \"Secrets and variables\" e depois em \"Actions\".</li> <li>Clique no bot\u00e3o \"New repository secret\" (Novo segredo do reposit\u00f3rio).</li> <li>D\u00ea um nome para o segredo, como <code>DOCKERHUB_TOKEN</code>, e cole o token de acesso que voc\u00ea gerou no DockerHub.</li> <li>Clique em \"Add secret\" (Adicionar segredo) para salvar o token.</li> <li>Agora, o token estar\u00e1 dispon\u00edvel como um segredo no GitHub Actions e poder\u00e1 ser usado no pipeline de CI/CD.</li> </ol> <p>Sugiro tamb\u00e9m que voc\u00ea crie um segredo para o seu usu\u00e1rio do DockerHub, que ser\u00e1 usado para fazer o login no DockerHub. Para isso, siga os passos abaixo:</p> <ol> <li>Acesse o reposit\u00f3rio do GitHub onde voc\u00ea configurou o GitHub Actions.</li> <li>Clique na aba \"Settings\" (Configura\u00e7\u00f5es) do reposit\u00f3rio.</li> <li>No menu lateral, clique em \"Secrets and variables\" e depois em \"Actions\".</li> <li>Clique no bot\u00e3o \"New repository secret\" (Novo segredo do reposit\u00f3rio).</li> <li>D\u00ea um nome para o segredo, como <code>DOCKERHUB_USERNAME</code>, e cole o seu nome de usu\u00e1rio do DockerHub.</li> <li>Clique em \"Add secret\" (Adicionar segredo) para salvar o token.</li> <li>Agora, o token estar\u00e1 dispon\u00edvel como um segredo no GitHub Actions e poder\u00e1 ser usado no pipeline de CI/CD.</li> </ol> <p>Com isso, voc\u00ea j\u00e1 tem os segredos necess\u00e1rios para fazer o upload da imagem Docker para o DockerHub. Agora, vamos configurar o GitHub Actions para fazer isso automaticamente sempre que houver um push no reposit\u00f3rio.</p>"},{"location":"ci/configurando-deploy-dockerhub/#configurando-o-github-actions-para-fazer-o-upload-da-imagem-docker","title":"Configurando o GitHub Actions para fazer o upload da imagem Docker","text":"<p>Agora que temos os segredos armazenados no GitHub, precisamos configurar o GitHub Actions para fazer o upload da imagem Docker para o DockerHub. Para isso, vamos editar o arquivo <code>.github/workflows/ci.yml</code> que criamos anteriormente e adicionar as etapas necess\u00e1rias para fazer o upload da imagem.</p> <p>Aqui est\u00e1 um exemplo de como o arquivo <code>.github/workflows/ci.yml</code> pode ficar ap\u00f3s as altera\u00e7\u00f5es:</p> .github/workflows/ci.yml<pre><code>name: ci-python\non: [push]\njobs:\n  check-application:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.13'\n          cache: 'pip'\n      - run: pip install -r requirements.txt\n      - run: pytest\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v1\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v1\n\n      - name: Login to DockerHub\n        uses: docker/login-action@v2\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }} # (1)\n          password: ${{ secrets.DOCKERHUB_TOKEN }} # (2)\n\n      - name: Build and Push to DockerHub\n        id: docker_build_push\n        uses: docker/build-push-action@v2\n        with:\n          push: true # (3)\n          tags: your-dockerhub-username/ci-sum-python:${{ github.sha }} # (4)\n</code></pre> <ol> <li>A express\u00e3o <code>${{ secrets.DOCKERHUB_USERNAME }}</code> indica o segredo que voc\u00ea criou para o seu nome de usu\u00e1rio do DockerHub.</li> <li>A express\u00e3o <code>${{ secrets.DOCKERHUB_TOKEN }}</code> indica o segredo que voc\u00ea criou para o token de acesso do DockerHub.</li> <li>A linha <code>push: true</code> indica que a imagem deve ser enviada para o DockerHub ap\u00f3s a constru\u00e7\u00e3o.</li> <li>Aqui voc\u00ea deve substituir <code>your-dockerhub-username</code> pelo seu nome de usu\u00e1rio do DockerHub, como configurado nos segredos, usando <code>${{ secrets.DOCKERHUB_USERNAME }}</code>. O <code>ci-sum-python</code> \u00e9 o nome da imagem que voc\u00ea deseja usar no DockerHub, e <code>${{ github.sha }}</code> \u00e9 a tag da imagem que ser\u00e1 gerada.</li> </ol> <p>Note que usamos a vari\u00e1vel <code>${{ github.sha }}</code> para gerar uma tag \u00fanica para cada commit, o que \u00e9 \u00fatil para identificar a vers\u00e3o da imagem correspondente ao commit. Voc\u00ea pode personalizar essa tag de acordo com suas necessidades, como usar um n\u00famero de vers\u00e3o espec\u00edfico ou uma tag mais amig\u00e1vel. Tamb\u00e9m pode ser usada a palavra <code>latest</code>, mas somente isso n\u00e3o \u00e9 recomendado, pois pode causar confus\u00e3o ao identificar qual vers\u00e3o da imagem est\u00e1 sendo usada.</p>"},{"location":"ci/configurando-deploy-dockerhub/#executando-o-github-actions","title":"Executando o GitHub Actions","text":"<p>Para executar o GitHub Actions, fa\u00e7a um push das altera\u00e7\u00f5es no arquivo <code>.github/workflows/ci.yml</code> para o reposit\u00f3rio remoto. Ap\u00f3s o push, o GitHub Actions ser\u00e1 acionado automaticamente e voc\u00ea poder\u00e1 visualizar o status da execu\u00e7\u00e3o na aba \"Actions\" do reposit\u00f3rio.</p> <p>Se tudo estiver configurado corretamente, o GitHub Actions ir\u00e1 construir a imagem Docker e fazer o upload para o DockerHub automaticamente. Voc\u00ea pode verificar se a imagem foi enviada com sucesso acessando sua conta no DockerHub e verificando se a imagem <code>ci-sum-python</code> est\u00e1 dispon\u00edvel no seu reposit\u00f3rio.</p> <p>Em seguida, voc\u00ea pode usar a imagem Docker em qualquer lugar, como em um servidor de produ\u00e7\u00e3o ou em um ambiente de desenvolvimento local, usando o comando <code>docker pull your-dockerhub-username/ci-sum-python:latest</code> ou <code>docker pull your-dockerhub-username/ci-sum-python:sha</code>, onde <code>sha</code> \u00e9 o hash do commit que voc\u00ea deseja usar. Note que voc\u00ea deve estar atento ao nome que voc\u00ea deu para a imagem, na op\u00e7\u00e3o <code>tags</code>, e usar o mesmo nome para fazer o pull da imagem.</p>"},{"location":"ci/configurando-github-actions/","title":"Configurando github actions","text":""},{"location":"ci/configurando-github-actions/#configuracao-do-github-actions","title":"Configura\u00e7\u00e3o do GitHub Actions","text":"<p>O GitHub Actions permite a cria\u00e7\u00e3o de pipelines de CI/CD diretamente no reposit\u00f3rio, facilitando a automa\u00e7\u00e3o de tarefas como testes, compila\u00e7\u00e3o, an\u00e1lise de c\u00f3digo e implanta\u00e7\u00e3o. Para configurar o GitHub Actions, crie um arquivo chamado <code>.github/workflows/ci.yml</code> na raiz do projeto com o seguinte conte\u00fado:</p> <pre><code>name: ci-python\non: [push]\njobs:\n  check-application:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.13'\n          cache: 'pip'\n      - run: pip install -r requirements.txt\n      - run: pytest\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v1\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v1\n\n      - name: Build\n        id: docker_build\n        uses: docker/build-push-action@v2\n        with:\n          push: false\n</code></pre> <p>Neste arquivo de configura\u00e7\u00e3o, definimos um job chamado <code>check-application</code> que executa as seguintes etapas:</p> <ol> <li><code>actions/checkout@v4</code>: Faz o checkout do c\u00f3digo fonte do reposit\u00f3rio.</li> <li><code>actions/setup-python@v5</code>: Configura o ambiente Python com a vers\u00e3o 3.13 e o cache do <code>pip</code>.</li> <li><code>pip install -r requirements.txt</code>: Instala as depend\u00eancias do projeto.</li> <li><code>pytest</code>: Executa os testes unit\u00e1rios do projeto.</li> <li><code>docker/setup-qemu-action@v1</code>: Configura o QEMU para execu\u00e7\u00e3o de imagens multiplataforma.</li> <li><code>docker/setup-buildx-action@v1</code>: Configura o Buildx para constru\u00e7\u00e3o de imagens Docker.</li> <li><code>docker/build-push-action@v2</code>: Constr\u00f3i a imagem Docker a partir do <code>Dockerfile</code>.</li> </ol> <p>Note que o job <code>check-application</code> \u00e9 acionado sempre que ocorre um push no reposit\u00f3rio. Voc\u00ea pode personalizar as etapas de acordo com as necessidades do seu projeto, adicionando mais comandos, testes e a\u00e7\u00f5es espec\u00edficas.</p> <p>Tamb\u00e9m, na \u00faltima etapa, foi configurada a op\u00e7\u00e3o <code>push</code> como <code>false</code>, o que significa que a imagem Docker ser\u00e1 constru\u00edda, mas n\u00e3o ser\u00e1 enviada para um registro de cont\u00eainer. Voc\u00ea pode alterar essa op\u00e7\u00e3o para <code>true</code> e adicionar as credenciais necess\u00e1rias para fazer o push da imagem para um registro de cont\u00eainer. Nesta etapa, estamos apenas construindo a imagem para fins de demonstra\u00e7\u00e3o.</p>"},{"location":"ci/configurando-github-actions/#executando-o-github-actions","title":"Executando o GitHub Actions","text":"<p>Para executar o GitHub Actions, fa\u00e7a um push das altera\u00e7\u00f5es no arquivo <code>.github/workflows/ci.yml</code> para o reposit\u00f3rio remoto. Ap\u00f3s o push, o GitHub Actions ser\u00e1 acionado automaticamente e voc\u00ea poder\u00e1 visualizar o status da execu\u00e7\u00e3o na aba \"Actions\" do reposit\u00f3rio.</p>"},{"location":"ci/criando-docker/","title":"Criando docker","text":""},{"location":"ci/criando-docker/#criacao-de-uma-imagem-docker","title":"Cria\u00e7\u00e3o de uma imagem Docker","text":"<p>Para criar uma imagem Docker, \u00e9 necess\u00e1rio criar um arquivo chamado <code>Dockerfile</code> na raiz do projeto. O <code>Dockerfile</code> \u00e9 um arquivo de configura\u00e7\u00e3o que define como a imagem Docker ser\u00e1 constru\u00edda, incluindo as depend\u00eancias, comandos e configura\u00e7\u00f5es necess\u00e1rias para executar a aplica\u00e7\u00e3o.</p> <p>Aqui est\u00e1 um exemplo de <code>Dockerfile</code> para um projeto Python simples:</p> Dockerfile<pre><code>FROM python:3.13-slim\nWORKDIR /app\nCOPY requirements.txt requirements.txt\nRUN pip install -r requirements.txt\nCOPY app.py app.py\nCMD [\"python\", \"app.py\"]\n</code></pre> <p>No arquivo criado, temos as seguintes instru\u00e7\u00f5es:</p> <ul> <li><code>FROM python:3.13-slim</code>: Define a imagem base a ser utilizada, neste caso, uma imagem Python 3.13 slim.</li> <li><code>WORKDIR /app</code>: Define o diret\u00f3rio de trabalho dentro da imagem.</li> <li><code>COPY requirements.txt requirements.txt</code>: Copia o arquivo <code>requirements.txt</code> para o diret\u00f3rio de trabalho.</li> <li><code>RUN pip install -r requirements.txt</code>: Instala as depend\u00eancias do projeto.</li> <li><code>COPY app.py app.py</code>: Copia o arquivo <code>app.py</code> para o diret\u00f3rio de trabalho.</li> <li><code>CMD [\"python\", \"app.py\"]</code>: Define o comando a ser executado quando o cont\u00eainer for iniciado.</li> </ul> <p>Note que n\u00e3o rodamos o comando <code>pytest</code> dentro do cont\u00eainer, pois os testes unit\u00e1rios devem ser executados antes de construir a imagem Docker. Para isso, podemos configurar um job no GitHub Actions para executar os testes antes de construir a imagem.</p>"},{"location":"ci/criando-docker/#testando-a-imagem-docker-localmente","title":"Testando a imagem Docker localmente","text":"<p>Para testar a imagem Docker localmente, voc\u00ea pode executar os seguintes comandos:</p> <ul> <li> Construir a imagem:</li> </ul> <pre><code>docker build -t ci-sum-python .\n</code></pre> <ul> <li> Executar o cont\u00eainer:</li> </ul> <pre><code>docker run --rm ci-sum-python\n</code></pre> <p>O comando <code>docker build</code> cria uma imagem Docker com o nome <code>ci-sum-python</code> a partir do <code>Dockerfile</code> presente no diret\u00f3rio atual. Em seguida, o comando <code>docker run</code> inicia um cont\u00eainer a partir da imagem criada, executando o arquivo <code>app.py</code> e exibindo a sa\u00edda no terminal.</p> <p>No caso do nosso exemplo, o arquivo <code>app.py</code> simplesmente soma dois n\u00fameros e imprime o resultado. Ao executar o cont\u00eainer, voc\u00ea deve ver a sa\u00edda correspondente \u00e0 soma dos n\u00fameros.</p>"},{"location":"ci/criando-projeto/","title":"Criando projeto","text":""},{"location":"ci/criando-projeto/#criando-um-projeto","title":"Criando um projeto","text":"<p>Neste guia, vamos criar um projeto simples em Python para demonstrar a integra\u00e7\u00e3o cont\u00ednua com o GitHub Actions. O projeto consistir\u00e1 em um script Python que realiza a soma de dois n\u00fameros e exibe o resultado.</p>"},{"location":"ci/criando-projeto/#passo-a-passo","title":"Passo a passo","text":"<ul> <li> Crie um diret\u00f3rio para o projeto.</li> </ul> <p>Crie um diret\u00f3rio para o projeto em sua m\u00e1quina local e abra-o com o Visual Studio Code ou outro editor de sua prefer\u00eancia.</p> <ul> <li> Inicialize um reposit\u00f3rio Git</li> </ul> <p>Dentro do diret\u00f3rio do projeto, inicialize um reposit\u00f3rio Git com o comando:</p> <pre><code>git init\n</code></pre> <ul> <li> Crie um ambiente virtual</li> </ul> <p>Crie um ambiente virtual para o projeto com o comando:</p> <pre><code>python -m venv .venv\n</code></pre> <p>Em seguida, ative o ambiente virtual:</p> Linux e macOSWindows <pre><code>source .venv/bin/activate\n</code></pre> <pre><code>.venv\\Scripts\\activate\n</code></pre> <ul> <li> Configure o .gitignore</li> </ul> <p>Crie um arquivo <code>.gitignore</code> na raiz do projeto e adicione o seguinte conte\u00fado para ignorar o ambiente virtual e os arquivos <code>.pyc</code>:</p> .gitignore<pre><code>.venv\n*.pyc\n__pycache__/\n.pytest_cache/\n</code></pre> <ul> <li> Instale o <code>pytest</code></li> </ul> <p>Instale o <code>pytest</code> para realizar os testes unit\u00e1rios do projeto:</p> <pre><code>pip install pytest\n</code></pre> <ul> <li> Crie um arquivo de testes</li> </ul> <p>Crie um arquivo Python chamado <code>test_app.py</code> com o seguinte conte\u00fado:</p> test_app.py<pre><code>from app import sumF\n\n\ndef test_sum():\n    assert sumF(1, 2) == 3\n    assert sumF(2, 2) == 4\n    assert sumF(3, 2) == 5\n</code></pre> <p>Se rodarmos os testes agora, eles devem falhar, pois ainda n\u00e3o implementamos a fun\u00e7\u00e3o <code>sumF</code>. Para testar, execute o comando:</p> <pre><code>pytest\n</code></pre> <ul> <li> Crie um arquivo Python</li> </ul> <p>Crie um arquivo Python chamado <code>app.py</code> com o seguinte conte\u00fado:</p> app.py<pre><code>def sumF(a, b):\n    return a + b\n\n\nif __name__ == \"__main__\":\n    print(sumF(10, 10))\n</code></pre> <ul> <li> Execute os testes</li> </ul> <p>Execute os testes novamente com o comando <code>pytest</code>. Eles devem passar agora, pois a fun\u00e7\u00e3o <code>sumF</code> foi implementada e est\u00e1 correta.</p> <ul> <li> Crie um arquivo <code>requirements.txt</code></li> </ul> <p>Crie um arquivo <code>requirements.txt</code> com as depend\u00eancias do projeto:</p> <pre><code>pip freeze &gt; requirements.txt\n</code></pre>"},{"location":"ci/criando-projeto/#fazendo-o-commit-inicial","title":"Fazendo o commit inicial","text":"<p>Neste momento, voc\u00ea j\u00e1 pode publicar a branch principal do projeto no GitHub. Para isso, voc\u00ea pode usar a pr\u00f3pria extens\u00e3o do Visual Studio Code ou os comandos do Git.</p> <p>Na pr\u00f3xima sess\u00e3o, vamos configurar o GitHub Actions para realizar a integra\u00e7\u00e3o cont\u00ednua do projeto.</p>"},{"location":"containers/","title":"Cont\u00eaineres","text":"<p>Nesta se\u00e7\u00e3o, abordaremos os conceitos b\u00e1sicos de containers, sem entrar nos detalhes de uso dos famosos Docker e Kubernetes. Vamos nos concentrar nos conceitos fundamentais e na import\u00e2ncia dos containers no desenvolvimento de software moderno.</p>"},{"location":"containers/#fundamentos-dos-conteineres","title":"Fundamentos dos cont\u00eaineres","text":"<p>O uso de <code>containers</code> (ou cont\u00eaineres) \u00e9 uma pr\u00e1tica comum no desenvolvimento de software moderno, permitindo que os desenvolvedores criem, testem e implantem aplicativos de forma consistente em diferentes ambientes. Os containers s\u00e3o unidades leves e port\u00e1teis que empacotam o c\u00f3digo-fonte, bibliotecas e depend\u00eancias necess\u00e1rias para executar um aplicativo, garantindo que ele funcione da mesma forma em qualquer lugar.</p> <p>De forma resumida, um cont\u00eainer \u00e9 um ambiente completo, composto por uma aplica\u00e7\u00e3o e todas suas depend\u00eancias, bibliotecas, bin\u00e1rios, arquivos de configura\u00e7\u00e3o, em um \u00fanico pacote. Os containers s\u00e3o baseados na tecnologia de virtualiza\u00e7\u00e3o, mas diferentemente das m\u00e1quinas virtuais, que virtualizam todo o sistema operacional, os containers compartilham o mesmo n\u00facleo do sistema operacional host. Isso torna os containers mais leves e r\u00e1pidos de iniciar, al\u00e9m de permitir que v\u00e1rios containers sejam executados simultaneamente em um \u00fanico host.</p> <p>Ao criar um cont\u00eainer para uma aplica\u00e7\u00e3o e suas depend\u00eancias, as diferen\u00e7as entre distribui\u00e7\u00f5es de sistemas operacionais e camadas inferiores da infraestrutura s\u00e3o abstra\u00eddas. Com isso, os desenvolvedores podem se concentrar em escrever c\u00f3digo e aplica\u00e7\u00f5es, sem se preocupar com as diferen\u00e7as entre os ambientes de desenvolvimento, teste e produ\u00e7\u00e3o.</p>"},{"location":"containers/#o-que-sao-conteineres","title":"O que s\u00e3o cont\u00eaineres?","text":"<p>Os cont\u00eaineres s\u00e3o unidades de software que empacotam o c\u00f3digo-fonte, bibliotecas e depend\u00eancias necess\u00e1rias para executar um aplicativo. Eles s\u00e3o isolados uns dos outros e do sistema operacional host, o que significa que cada cont\u00eainer pode ter suas pr\u00f3prias configura\u00e7\u00f5es e depend\u00eancias, sem interferir em outros cont\u00eaineres ou no sistema operacional subjacente.</p> <p>Os cont\u00eaineres s\u00e3o ambientes de leves, port\u00e1teis, consistentes e isolados que permitem aos desenvolvedores executar e empacotar aplicativos com suas depend\u00eancias de forma consistente em diferentes plataformas. Eles ajudam a simplificar os processos de desenvolvimento, implanta\u00e7\u00e3o e gerenciamento de aplicativos, garantindo que os aplicativos sejam executados de forma consistente, independentemente da infraestrutura subjacente.</p>"},{"location":"containers/#por-que-usar-conteineres","title":"Por que usar cont\u00eaineres?","text":"<p>Os cont\u00eaineres oferecem v\u00e1rias vantagens em rela\u00e7\u00e3o aos m\u00e9todos tradicionais de desenvolvimento e implanta\u00e7\u00e3o de aplicativos. Algumas das principais raz\u00f5es para usar cont\u00eaineres incluem:</p> <ul> <li>Consist\u00eancia: Os cont\u00eaineres garantem que o aplicativo funcione da mesma forma em diferentes ambientes, eliminando problemas de \"funciona na minha m\u00e1quina\". Isso \u00e9 especialmente \u00fatil quando se trabalha em equipes grandes ou em projetos complexos.</li> <li>Portabilidade: Os cont\u00eaineres podem ser executados em qualquer lugar, desde o laptop do desenvolvedor at\u00e9 servidores em nuvem ou ambientes de produ\u00e7\u00e3o. Isso facilita a migra\u00e7\u00e3o de aplicativos entre diferentes ambientes e plataformas.</li> <li>Isolamento: Os cont\u00eaineres s\u00e3o isolados uns dos outros, o que significa que as depend\u00eancias e configura\u00e7\u00f5es de um cont\u00eainer n\u00e3o afetam outros cont\u00eaineres ou o sistema operacional host. Isso ajuda a evitar conflitos de depend\u00eancia e facilita o gerenciamento de aplicativos complexos.</li> <li>Efici\u00eancia: Os cont\u00eaineres s\u00e3o mais leves e r\u00e1pidos de iniciar do que as m\u00e1quinas virtuais, permitindo que v\u00e1rios cont\u00eaineres sejam executados simultaneamente em um \u00fanico <code>host</code>. Isso reduz o uso de recursos e melhora a efici\u00eancia geral do sistema.</li> <li>Escalabilidade: Os cont\u00eaineres podem ser facilmente escalados para atender \u00e0 demanda, permitindo que os desenvolvedores aumentem ou diminuam rapidamente a capacidade de um aplicativo conforme necess\u00e1rio. Isso \u00e9 especialmente \u00fatil em ambientes de produ\u00e7\u00e3o, onde a carga de trabalho pode variar significativamente.</li> <li>Facilidade de gerenciamento: Os cont\u00eaineres podem ser facilmente gerenciados e orquestrados usando ferramentas como Docker e Kubernetes, permitindo que os desenvolvedores automatizem tarefas comuns, como implanta\u00e7\u00e3o, escalonamento e monitoramento de aplicativos.</li> </ul> <p>Os cont\u00eaineres resolvem o problema de ambientes inconsistentes ao trabalhar em grandes equipes. Antes dos cont\u00eaineres ou ambientes virtuais, muitos problemas e perda de tempo eram causados pela necessidade de instalar e configurar ambientes locais para construir projetos compartilhados por colegas de trabalho ou amigos.</p> <p>Dessa forma, os cont\u00eaineres ajudam a reduzir o tempo de desenvolvimento e a aumentar a efici\u00eancia, permitindo que os desenvolvedores se concentrem no que realmente importa: escrever c\u00f3digo e criar aplicativos incr\u00edveis. Ainda, de forma geral, o uso de cont\u00eaineres ajudar a reduzir os conflitos entre as equipes de desenvolvimento e opera\u00e7\u00f5es, separando as \u00e1reas de responsabilidade. Os desenvolvedores podem se concentrar em seus aplicativos e as equipes de opera\u00e7\u00f5es podem se concentrar na infraestrutura. E, como os cont\u00eaineres s\u00e3o baseados em tecnologia de c\u00f3digo aberto, voc\u00ea obt\u00e9m os mais recentes avan\u00e7os assim que est\u00e3o dispon\u00edveis.</p> <p>Embora o Docker possa ser a ferramenta de cont\u00eainer mais conhecida, existem outras op\u00e7\u00f5es dispon\u00edveis, como Podman, Skopeo, Buildah e CRI-O. Essas ferramentas oferecem funcionalidades semelhantes ao Docker, mas podem ter diferen\u00e7as em termos de arquitetura, desempenho e recursos espec\u00edficos.</p>"},{"location":"containers/#bare-metal-vs-virtualizacao-vs-conteineres","title":"Bare Metal vs Virtualiza\u00e7\u00e3o vs Cont\u00eaineres","text":"<p><code>Bare Metal</code> \u00e9 um termo usado para descrever um computador que est\u00e1 executando diretamente no hardware sem nenhuma virtualiza\u00e7\u00e3o. Esta \u00e9 a maneira com maior desempenho para executar um aplicativo, mas tamb\u00e9m \u00e9 a menos flex\u00edvel. Voc\u00ea s\u00f3 pode executar um aplicativo por servidor e n\u00e3o pode mover facilmente o aplicativo para outro servidor.</p> <p>Para resolver esse problema, a virtualiza\u00e7\u00e3o foi introduzida. A virtualiza\u00e7\u00e3o permite que voc\u00ea execute v\u00e1rios sistemas operacionais em um \u00fanico servidor. A cada uma dessas inst\u00e2ncias de sistema operacional \u00e9 chamada de m\u00e1quina virtual (VM). Cada VM \u00e9 executada em cima de um hipervisor, que \u00e9 um peda\u00e7o de software que emula o hardware de um computador. O hipervisor permite que voc\u00ea execute v\u00e1rios sistemas operacionais em um \u00fanico servidor e tamb\u00e9m fornece isolamento entre aplicativos executados em diferentes VMs.</p> <p>Isso \u00e9 poss\u00edvel porque o hipervisor emula o hardware de um computador, permitindo que cada VM tenha seu pr\u00f3prio sistema operacional e recursos. Em linhas gerais, o hipervisor <code>engana</code> o sistema operacional convidado (VM) para pensar que est\u00e1 executando em um hardware f\u00edsico, quando na verdade est\u00e1 sendo executado em cima de outro sistema operacional (o hipervisor). No entanto, isso pode levar a uma sobrecarga de desempenho, pois o hipervisor precisa gerenciar os recursos do hardware subjacente e alocar esses recursos para cada VM. Al\u00e9m disso, o hipervisor pode introduzir lat\u00eancia e reduzir o desempenho geral do sistema.</p> <p>J\u00e1 os cont\u00eaineres s\u00e3o uma maneira de executar v\u00e1rios aplicativos em um \u00fanico servidor sem a sobrecarga de um hipervisor. Cada cont\u00eainer \u00e9 executado em cima de um mecanismo de cont\u00eainer (software que gerencia o ciclo de vida dos cont\u00eaineres), que supervisiona e isola processos usando os recursos do n\u00facleo do sistema operacional host.</p> <p>Dessa forma, os cont\u00eaineres compartilham o mesmo n\u00facleo do sistema operacional host, mas cada cont\u00eainer tem seu pr\u00f3prio sistema de arquivos, rede e processos. Isso significa que os cont\u00eaineres s\u00e3o mais leves e r\u00e1pidos de iniciar do que as VMs, pois n\u00e3o precisam emular todo o hardware de um computador. Al\u00e9m disso, os cont\u00eaineres podem ser facilmente movidos entre diferentes servidores e ambientes, tornando-os mais port\u00e1teis e flex\u00edveis. Por outro lado, como todos os cont\u00eaineres usam o mesmo n\u00facleo do sistema operacionais, n\u00e3o \u00e9 poss\u00edvel que cada cont\u00eainer tenha seu pr\u00f3prio sistema operacional. Isso pode levar a problemas de compatibilidade entre aplicativos que exigem diferentes vers\u00f5es do n\u00facleo do sistema operacional.</p>"},{"location":"containers/#open-container-initiative-oci","title":"Open Container Initiative (OCI)","text":"<p>A Open Container Initiative (OCI) \u00e9 uma organiza\u00e7\u00e3o que visa criar padr\u00f5es abertos para cont\u00eaineres. A OCI foi criada em 2015 como parte da Linux Foundation e tem como objetivo promover a interoperabilidade entre diferentes ferramentas e plataformas de cont\u00eaineres.</p> <p>A OCI define dois padr\u00f5es principais:</p> <ul> <li>Runtime Specification: Define como os cont\u00eaineres devem ser executados em um ambiente de cont\u00eainer. Isso inclui detalhes sobre como os cont\u00eaineres devem ser iniciados, parados e gerenciados, bem como como os recursos do sistema devem ser alocados para os cont\u00eaineres.</li> <li>Image Specification: Define como as imagens de cont\u00eainer devem ser formatadas e armazenadas. Isso inclui detalhes sobre como as imagens devem ser empacotadas, versionadas e distribu\u00eddas.</li> </ul> <p>Esses padr\u00f5es ajudam a garantir que diferentes ferramentas e plataformas de cont\u00eaineres possam trabalhar juntas de forma interoper\u00e1vel. Isso significa que os desenvolvedores podem usar diferentes ferramentas para criar, executar e gerenciar cont\u00eaineres, sem se preocupar com problemas de compatibilidade.</p> <p>A Docker foi uma das primeiras empresas a adotar os padr\u00f5es da OCI e tem trabalhado em estreita colabora\u00e7\u00e3o com a OCI para promover a interoperabilidade entre diferentes ferramentas de cont\u00eaineres. Outras empresas, como Red Hat, Google e Microsoft, tamb\u00e9m est\u00e3o envolvidas na OCI e apoiam seus esfor\u00e7os para criar padr\u00f5es abertos para cont\u00eaineres.</p>"},{"location":"containers/#as-tecnologias-que-dao-vida-aos-conteineres","title":"As tecnologias que d\u00e3o vida aos cont\u00eaineres","text":"<p>O conceito de cont\u00eaineres \u00e9 suportado por v\u00e1rias tecnologias que permitem a cria\u00e7\u00e3o, execu\u00e7\u00e3o e gerenciamento de cont\u00eaineres. Entre essas tecnologias, podemos citar as duas principais, que s\u00e3o:</p> <ul> <li>Namespaces: Os namespaces s\u00e3o uma caracter\u00edstica do n\u00facleo do Linux que permite isolar processos e recursos em diferentes cont\u00eaineres. Cada cont\u00eainer tem seu pr\u00f3prio namespace, o que significa que os processos em um cont\u00eainer n\u00e3o podem ver ou interagir com os processos em outro cont\u00eainer.</li> <li>Cgroups: Os cgroups (control groups) s\u00e3o outra caracter\u00edstica do n\u00facleo do Linux que permite limitar e monitorar o uso de recursos (como CPU, mem\u00f3ria e disco) por processos em um cont\u00eainer. Isso ajuda a garantir que os cont\u00eaineres n\u00e3o consumam mais recursos do que o necess\u00e1rio e permite que os desenvolvedores definam limites para cada cont\u00eainer.</li> </ul> <p>Outras tecnologias tamb\u00e9m s\u00e3o importantes para o funcionamento dos cont\u00eaineres, como:</p> <ul> <li>UnionFS: O UnionFS \u00e9 um sistema de arquivos que permite empilhar v\u00e1rios sistemas de arquivos em um \u00fanico sistema de arquivos. Isso \u00e9 \u00fatil para criar imagens de cont\u00eainer, pois permite que os desenvolvedores empilhem diferentes camadas de arquivos e depend\u00eancias em uma \u00fanica imagem.</li> <li>Containerd: O Containerd \u00e9 um daemon de cont\u00eainer que fornece uma API para criar, executar e gerenciar cont\u00eaineres. Ele \u00e9 usado por v\u00e1rias ferramentas de cont\u00eainer, incluindo o Docker, e fornece uma interface comum para trabalhar com cont\u00eaineres.</li> <li>runc: O runc \u00e9 um runtime de cont\u00eainer que implementa os padr\u00f5es da OCI. Ele \u00e9 usado pelo Docker e outras ferramentas de cont\u00eainer para executar cont\u00eaineres. O runc \u00e9 respons\u00e1vel por criar e gerenciar os namespaces, cgroups e sistemas de arquivos necess\u00e1rios para executar um cont\u00eainer.</li> </ul>"},{"location":"containers/#namespaces","title":"Namespaces","text":"<p>Os namespaces s\u00e3o uma caracter\u00edstica do n\u00facleo do Linux que permite isolar processos e recursos em diferentes cont\u00eaineres. Cada cont\u00eainer tem seu pr\u00f3prio namespace, o que significa que os processos em um cont\u00eainer n\u00e3o podem ver ou interagir com os processos em outro cont\u00eainer. Isso \u00e9 fundamental para garantir o isolamento entre cont\u00eaineres e evitar conflitos de depend\u00eancia.</p> <p>Os namespaces s\u00e3o usados para isolar diferentes recursos do sistema, como:</p> <ul> <li>PID namespace: Isola os IDs de processo (PIDs) entre cont\u00eaineres, permitindo que cada cont\u00eainer tenha seu pr\u00f3prio conjunto de processos.</li> <li>Network namespace: Isola as interfaces de rede entre cont\u00eaineres, permitindo que cada cont\u00eainer tenha sua pr\u00f3pria pilha de rede e endere\u00e7os IP.</li> <li>Mount namespace: Isola os pontos de montagem entre cont\u00eaineres, permitindo que cada cont\u00eainer tenha seu pr\u00f3prio sistema de arquivos.</li> <li>User namespace: Isola os IDs de usu\u00e1rio e grupo entre cont\u00eaineres, permitindo que cada cont\u00eainer tenha seu pr\u00f3prio conjunto de usu\u00e1rios e permiss\u00f5es.</li> <li>IPC namespace: Isola os recursos de comunica\u00e7\u00e3o entre processos (IPC) entre cont\u00eaineres, permitindo que cada cont\u00eainer tenha seu pr\u00f3prio conjunto de recursos IPC.</li> <li>UTS namespace: Isola os nomes de host e dom\u00ednio entre cont\u00eaineres, permitindo que cada cont\u00eainer tenha seu pr\u00f3prio nome de host e dom\u00ednio.</li> <li>Cgroup namespace: Isola os grupos de controle (cgroups) entre cont\u00eaineres, permitindo que cada cont\u00eainer tenha seu pr\u00f3prio conjunto de cgroups.</li> <li>Time namespace: Isola o tempo entre cont\u00eaineres, permitindo que cada cont\u00eainer tenha seu pr\u00f3prio rel\u00f3gio e fuso hor\u00e1rio.</li> <li>Seccomp namespace: Isola os filtros de seguran\u00e7a entre cont\u00eaineres, permitindo que cada cont\u00eainer tenha seu pr\u00f3prio conjunto de regras de seguran\u00e7a.</li> </ul> <p>A imagem abaixo ilustra como esses recurso est\u00e3o isolados dentro de um namespace:</p> <pre><code>flowchart LR\n  subgraph Namespace\n    PID\n    NET\n    MNT\n    USER\n    IPC\n    UTS\n  end</code></pre>"},{"location":"containers/#criando-um-ambiente-isolado-com-namespace","title":"Criando um ambiente isolado com namespace","text":"<p>No Linux, voc\u00ea pode criar um ambiente isolado usando namespaces com o comando <code>unshare</code>. O comando <code>unshare</code> permite que voc\u00ea execute um comando em um novo namespace, isolando-o do restante do sistema. Isso \u00e9 \u00fatil para testar e desenvolver aplicativos em um ambiente isolado.</p> <p>Neste exemplo, criaremos um novo namespace de PID, rede e sistema de montagem, e iniciaremos um bash dentro desse ambiente isolado.</p> <pre><code>sudo unshare -p -m -n -f --mount-proc bash\n</code></pre> <p>Vamos analisar os par\u00e2metros usados:</p> <ul> <li><code>-p</code>: Cria um novo namespace de PID, onde os processos ter\u00e3o IDs independentes do sistema principal.</li> <li><code>-m</code>: Cria um novo namespace de montagem, isolando o sistema de arquivos.</li> <li><code>-n</code>: Cria um novo namespace de rede, isolando as interfaces de rede.</li> <li><code>-f</code>: For\u00e7a a cria\u00e7\u00e3o do novo processo no namespace.</li> <li><code>--mount-proc</code>: Monta o sistema de arquivos <code>/proc</code> dentro do namespace, permitindo visualizar apenas os processos do ambiente isolado.</li> <li><code>bash</code>: O comando a ser executado dentro do novo namespace.</li> </ul> <p>Ap\u00f3s executar o comando, voc\u00ea ter\u00e1 um shell bash dentro de um novo namespace de PID, rede e sistema de montagem. Isso significa que qualquer processo iniciado dentro desse shell n\u00e3o ter\u00e1 acesso aos processos ou recursos do sistema principal.</p> <p>Da parte externa do namespace, voc\u00ea pode verificar os processos em execu\u00e7\u00e3o usando o comando <code>ps</code>. Nesse caso, queremos identificar o PID do bash que foi iniciado dentro do namespace. Para isso, voc\u00ea pode usar o comando <code>ps</code> com a op\u00e7\u00e3o <code>-ef</code> para listar todos os processos em execu\u00e7\u00e3o:</p> <pre><code> ps -ef | grep unshare\n</code></pre> <p>Com esse comando, voc\u00ea ver\u00e1 uma lista de processos em execu\u00e7\u00e3o e poder\u00e1 identificar o PID do processo <code>unshare</code>. O PID do bash iniciado dentro do namespace ser\u00e1 um filho desse processo. Uma forma de visualizar isso \u00e9 usando o comando <code>pstree</code>, que exibe a \u00e1rvore de processos:</p> <pre><code>pstree -p &lt;PID_IDENTIFICADO_AO_COMANDO_UNSHARE&gt; # (1)\n</code></pre> <ol> <li>Substitua <code>&lt;PID_IDENTIFICADO_AO_COMANDO_UNSHARE&gt;</code> pelo PID do processo <code>unshare</code> que voc\u00ea encontrou na etapa anterior. O PID do bash ser\u00e1 listado como um filho do processo <code>unshare</code>.</li> </ol>"},{"location":"containers/#cgroups-ou-control-groups","title":"CGroups (ou Control Groups)","text":"<p>Os cgroups (control groups) s\u00e3o uma caracter\u00edstica do n\u00facleo do Linux que permite limitar e monitorar o uso de recursos (como CPU, mem\u00f3ria e disco) por processos em um cont\u00eainer. Isso ajuda a garantir que os cont\u00eaineres n\u00e3o consumam mais recursos do que o necess\u00e1rio e permite que os desenvolvedores definam limites para cada cont\u00eainer.</p> <p>Os cgroups s\u00e3o organizados em hierarquias, onde cada hierarquia pode conter v\u00e1rios grupos de controle. Cada grupo de controle pode ter suas pr\u00f3prias configura\u00e7\u00f5es de limite de recursos, permitindo que os desenvolvedores definam diferentes limites para diferentes grupos de processos.</p> <p>Os cgroups s\u00e3o usados para controlar o uso de recursos em v\u00e1rias \u00e1reas, incluindo:</p> <ul> <li>Limita\u00e7\u00e3o de CPU: Permite definir limites de uso de CPU para grupos de processos, garantindo que um cont\u00eainer n\u00e3o consuma mais CPU do que o necess\u00e1rio.</li> <li>Limita\u00e7\u00e3o de mem\u00f3ria: Permite definir limites de uso de mem\u00f3ria para grupos de processos, garantindo que um cont\u00eainer n\u00e3o consuma mais mem\u00f3ria do que o necess\u00e1rio.</li> <li>Limita\u00e7\u00e3o de disco: Permite definir limites de uso de disco para grupos de processos, garantindo que um cont\u00eainer n\u00e3o consuma mais espa\u00e7o em disco do que o necess\u00e1rio.</li> <li>Limita\u00e7\u00e3o de rede: Permite definir limites de uso de rede para grupos de processos, garantindo que um cont\u00eainer n\u00e3o consuma mais largura de banda do que o necess\u00e1rio.</li> <li>Limita\u00e7\u00e3o de I/O: Permite definir limites de uso de entrada/sa\u00edda (I/O) para grupos de processos, garantindo que um cont\u00eainer n\u00e3o consuma mais recursos de I/O do que o necess\u00e1rio.</li> </ul> <p><pre><code>flowchart LR\n  subgraph CGroup\n    CPU\n    cpuset\n    memory\n    device\n    I/O\n    network\n  end</code></pre> Os cgroups s\u00e3o uma parte fundamental da tecnologia de cont\u00eaineres, pois permitem que os desenvolvedores definam limites e monitorem o uso de recursos em cont\u00eaineres. Isso \u00e9 especialmente importante em ambientes de produ\u00e7\u00e3o, onde v\u00e1rios cont\u00eaineres podem estar sendo executados simultaneamente e o uso excessivo de recursos por um cont\u00eainer pode afetar o desempenho de outros cont\u00eaineres ou do sistema host. Por isso, junto com os namespaces, os cgroups s\u00e3o fundamentais para garantir o isolamento e o controle de recursos em cont\u00eaineres. Eles permitem que os desenvolvedores definam limites e monitorem o uso de recursos, garantindo que os cont\u00eaineres n\u00e3o afetem o desempenho do sistema host ou de outros cont\u00eaineres.</p>"},{"location":"containers/#criando-um-ambiente-isolado-com-cgroups","title":"Criando um ambiente isolado com cgroups","text":"<p>N\u00f3s vamos limitar os recursos do namespace criado anteriormente e, em seguida, rodar um teste de estresse para verificar se os limites est\u00e3o funcionando corretamente.</p> <p>Inicialmente, vamos criar alguns arquivos com as defini\u00e7\u00f5es do cgroup que iremos associar ao processo bash que criamos anteriormente. Para isso, vamos criar um diret\u00f3rio para o cgroup e configurar os limites de CPU e mem\u00f3ria.</p> <pre><code>sudo mkdir /sys/fs/cgroup/meu-namespace # (1)\n</code></pre> <ol> <li>O nome <code>meu-namespace</code> pode ser alterado para qualquer nome que voc\u00ea preferir. O importante \u00e9 que o diret\u00f3rio seja criado dentro de <code>/sys/fs/cgroup/</code>, que \u00e9 onde os cgroups s\u00e3o montados no sistema.</li> </ol> <p>Agora vamos limitar os recursos do cgroup. Para isso, vamos criar dois arquivos: <code>cpu.max</code> e <code>memory.max</code>. O arquivo <code>cpu.max</code> define o limite de uso de CPU, enquanto o arquivo <code>memory.max</code> define o limite de uso de mem\u00f3ria.</p> <pre><code>echo \"50000 100000\" | sudo tee /sys/fs/cgroup/meu-namespace/cpu.max # (1)\necho \"100M\" | sudo tee /sys/fs/cgroup/meu-namespace/memory.max # (2)\n</code></pre> <ol> <li>O valor <code>50000 100000</code> significa que o cgroup pode usar at\u00e9 50% de um n\u00facleo de CPU (50.000 microssegundos em 100.000 microssegundos).</li> <li>O valor <code>100M</code> significa que o cgroup pode usar at\u00e9 100 MB de mem\u00f3ria.</li> </ol> <p>No exemplo acima, foram criados os dois arquivos <code>cpu.max</code> e <code>memory.max</code> dentro do diret\u00f3rio <code>/sys/fs/cgroup/meu-namespace/</code>. Esses arquivos s\u00e3o usados para definir os limites de CPU e mem\u00f3ria do cgroup. Voc\u00ea pode confirmar o conte\u00fado dos arquivos usando o comando <code>cat</code>:</p> <pre><code>cat /sys/fs/cgroup/meu-namespace/cpu.max\ncat /sys/fs/cgroup/meu-namespace/memory.max\n</code></pre> <p>Agora que temos o <code>cgroup</code> criado e os limites definidos, precisamos associar o processo bash que criamos anteriormente a esse cgroup. Para isso, precisamos do PID do processo bash que est\u00e1 rodando no namespace. Vamos supor que o PID do bash seja <code>12345</code>. Para associar esse processo ao cgroup <code>meu-namespace</code>, precisamos adicionar o PID do processo ao arquivo <code>cgroup.procs</code> dentro do diret\u00f3rio do cgroup. Para isso, voc\u00ea pode usar o seguinte comando:</p> <pre><code>echo 12345 | sudo tee /sys/fs/cgroup/meu-namespace/cgroup.procs # (1)\n</code></pre> <ol> <li>Substitua <code>12345</code> pelo PID do processo bash que voc\u00ea encontrou anteriormente.</li> </ol> <p>Agora, o processo bash e todos os seus filhos estar\u00e3o associados ao cgroup <code>meu-namespace</code>, e estar\u00e3o limitados pelos recursos definidos nos arquivos <code>cpu.max</code> e <code>memory.max</code>.</p>"},{"location":"containers/#fazendo-um-teste-de-stress","title":"Fazendo um teste de stress","text":"<p>O Linux fornece uma ferramenta chamada <code>stress</code> que pode ser usada para gerar carga em CPU, mem\u00f3ria e disco. Essa ferramenta \u00e9 \u00fatil para testar os limites de recursos definidos em um cgroup.</p> <p>Vamos considerar o comando abaixo:</p> <pre><code>stress --cpu 2 --vm 1 --vm-bytes 80M --timeout 30\n</code></pre> <p>Esse comando faz o seguinte:</p> <ul> <li><code>--cpu 2</code>: Cria dois processos que consomem CPU.</li> <li><code>--vm 1</code>: Cria um processo que consome mem\u00f3ria.</li> <li><code>--vm-bytes 80M</code>: O processo de mem\u00f3ria consome 80 MB de mem\u00f3ria.</li> <li>'--timeout 30': O comando ser\u00e1 executado por 30 segundos.</li> </ul> <p>Como a gente pode ver, o comando <code>stress</code> vai tentar consumir 80 MB de mem\u00f3ria e 2 n\u00facleos de CPU. No entanto, como definimos um limite de 100 MB de mem\u00f3ria e 50% de CPU no cgroup, o comando <code>stress</code> deve ser limitado a esses valores. Por outro lado, se o comando for executado fora do cgroup, ele n\u00e3o ter\u00e1 esses limites e poder\u00e1 consumir mais recursos do que o esperado.</p> <p>Para que possamos verificar os limites que foram impostos pelo cgroup, \u00e9 poss\u00edvel analisar os registros do arquivo <code>cpu.stat</code> do cgroup. Esse arquivo cont\u00e9m informa\u00e7\u00f5es sobre o uso de CPU e o n\u00famero de vezes que o cgroup foi limitado (throttled).</p> <pre><code>cat /sys/fs/cgroup/meu-namespace/cpu.stat\n</code></pre> <p>O arquivo <code>cpu.stat</code> cont\u00e9m, entre outras, as seguintes informa\u00e7\u00f5es:</p> <ul> <li><code>usage_usec</code>: Tempo total de CPU usado pelo cgroup (em microssegundos).</li> <li><code>nr_throttled</code>: Quantas vezes o cgroup foi limitado (throttled).</li> <li><code>throttled_usec</code>: Tempo total durante o qual o cgroup foi limitado (em microssegundos).</li> </ul> <p>Agora, podemos executar o comando <code>stress</code> dentro do cgroup e monitorar o arquivo <code>cpu.stat</code> para verificar se os limites est\u00e3o funcionando corretamente.</p> <p>Importante</p> <ol> <li> <p>Crie um novo cgroup para cada teste, para garantir que n\u00e3o haja valores acumulados no <code>cpu.stat</code> de execu\u00e7\u00f5es anteriores</p> </li> <li> <p>Remova o cgroup ap\u00f3s o teste e o encerramento do namespace:</p> </li> </ol> <pre><code>sudo rmdir /sys/fs/cgroup/mycontainer\n</code></pre>"},{"location":"docker/","title":"Docker","text":"<p>Criado em 2013, o Docker introduziu o que se tornou o padr\u00e3o da ind\u00fastria para cont\u00eaineres. Ele foi desenvolvido por Solomon Hykes e sua equipe na dotCloud, uma plataforma de PaaS (Platform as a Service). Desde ent\u00e3o, o Docker evoluiu para se tornar uma das ferramentas mais populares para desenvolvimento e implanta\u00e7\u00e3o de aplicativos em cont\u00eaineres.</p> <p>Docker \u00e9 uma plataforma Open Source escrita em Go que ajuda a cria\u00e7\u00e3o e a administra\u00e7\u00e3o de ambientes isolados. Ele permite criar, testar e implantar aplicativos rapidamente. O Docker empacota o software em unidades padronizadas chamadas cont\u00eaineres, que incluem tudo o que o software precisa para funcionar, como bibliotecas, depend\u00eancias e arquivos de configura\u00e7\u00e3o. Isso garante que o aplicativo funcione de maneira consistente em qualquer ambiente.</p> <p>O Docker trabalha com uma virtualiza\u00e7\u00e3o a n\u00edvel do sistema operacional, onde o mesmo utiliza de recursos como o kernel do sistema hospedeiro para executar seus cont\u00eaineres. Diferente do modelo tradicional de M\u00e1quinas Virtuais, o Docker n\u00e3o necessita da instala\u00e7\u00e3o de um sistema operacional por completo, e sim apenas dos arquivos necess\u00e1rios para a aplica\u00e7\u00e3o ser executada.</p> <p>Em resumo, o Docker simplifica o processo de desenvolvimento, teste, empacotamento, homologa\u00e7\u00e3o e implanta\u00e7\u00e3o de aplicativos em cont\u00eaineres port\u00e1teis e leves. O Docker \u00e9 amplamente utilizado em ambientes de desenvolvimento e produ\u00e7\u00e3o, permitindo que os desenvolvedores criem aplicativos de forma mais r\u00e1pida e eficiente, minimizando impactos no processo de desenvolvimento e entrega de software.</p> <p>Como j\u00e1 discutido anteriormente, existem diversos runtimes de cont\u00eaineres e at\u00e9 \u00e9 poss\u00edvel utilizar cont\u00eaineres sem Docker. Contudo, atualmente o Docker \u00e9 o runtime de container mais utilizada no mercado, sendo uma tecnologia fundamental no mundo do DevOps.</p>"},{"location":"docker/#instalacao-do-docker","title":"Instala\u00e7\u00e3o do Docker","text":"<p>Em geral, uma ferramenta muito comum para administrar os cont\u00eaineres Docker \u00e9 o Docker Desktop. O Docker Desktop \u00e9 uma aplica\u00e7\u00e3o que fornece uma interface gr\u00e1fica para gerenciar cont\u00eaineres Docker, imagens e volumes. Ele \u00e9 f\u00e1cil de instalar e configurar, e \u00e9 uma \u00f3tima op\u00e7\u00e3o para desenvolvedores que desejam trabalhar com Docker em suas m\u00e1quinas locais. Ele est\u00e1 dispon\u00edvel para Windows, macOS e Linux.</p> <p>Por outro lado, existe uma confus\u00e3o comum entre \"Docker Desktop\" e \"Docker Engine\". O Docker Engine refere-se especificamente a um subconjunto dos componentes do Docker Desktop que s\u00e3o gratuitos e de c\u00f3digo aberto e podem ser instalados apenas no Linux. O Docker Engine pode criar imagens de cont\u00eainer, executar cont\u00eaineres a partir delas e, em geral, fazer a maioria das coisas que o Docker Desktop pode, mas \u00e9 apenas para Linux e n\u00e3o fornece todo o polimento da experi\u00eancia do desenvolvedor que o Docker Desktop fornece.</p> <p>Para instalar o Docker Desktop em sua m\u00e1quina, acesse o site do Docker Desktop e siga as instru\u00e7\u00f5es de instala\u00e7\u00e3o para o seu sistema operacional. O Docker Desktop \u00e9 gratuito para uso pessoal e educacional, mas pode ter custos associados para uso comercial em algumas circunst\u00e2ncias. Consulte a documenta\u00e7\u00e3o do Docker para obter mais informa\u00e7\u00f5es sobre pre\u00e7os e licenciamento.</p> <p>Em sistemas operacionais baseados em Linux, como Ubuntu, voc\u00ea pode instalar o Docker Engine diretamente usando o gerenciador de pacotes. Aqui est\u00e3o os passos b\u00e1sicos para instalar o Docker Engine no Ubuntu:</p> Arch LinuxUbuntuDebianFedora <pre><code>sudo pacman -Syu\nsudo pacman -S docker docker-compose\nsudo systemctl start docker\nsudo systemctl enable docker\n</code></pre> <pre><code>sudo apt-get update &amp;&amp; sudo apt upgrade\nsudo apt-get install \\\n    apt-transport-https \\\n    ca-certificates \\\n    curl \\\n    software-properties-common \\\n    gnupg \\\n    lsb-release\n\nsudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\necho \\\n\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n$(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n\nsudo systemctl start docker\nsudo systemctl enable docker\n</code></pre> <pre><code>sudo apt-get update &amp;&amp; sudo apt upgrade\nsudo apt-get install \\\n    apt-transport-https \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n\nsudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\necho \\\n\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian \\\n$(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n\nsudo systemctl start docker\nsudo systemctl enable docker\n</code></pre> <pre><code>sudo dnf update -y\nsudo dnf install dnf-plugins-core -y\n\nsudo dnf config-manager --add-repo https://download.docker.com/linux/fedora/docker-ce.repo\nsudo dnf install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n\nsudo systemctl start docker\nsudo systemctl enable docker\n</code></pre> <p>Tamb\u00e9m, pode ser \u00fatil adicionar o usu\u00e1rio atual ao grupo <code>docker</code> para evitar a necessidade de usar <code>sudo</code> ao executar comandos do Docker. Voc\u00ea pode fazer isso com o seguinte comando:</p> <pre><code>sudo usermod -aG docker $USER\n</code></pre> <p>Depois de adicionar o usu\u00e1rio ao grupo <code>docker</code>, voc\u00ea precisar\u00e1 sair e entrar novamente na sess\u00e3o para que as altera\u00e7\u00f5es tenham efeito. Voc\u00ea pode verificar se o usu\u00e1rio foi adicionado corretamente ao grupo <code>docker</code> executando o seguinte comando:</p> <pre><code>groups $USER\n</code></pre> <p>Ap\u00f3s a instala\u00e7\u00e3o, voc\u00ea pode verificar se o Docker est\u00e1 funcionando corretamente executando o seguinte comando:</p> <pre><code>docker --version\n</code></pre> <p>Isso deve exibir a vers\u00e3o do Docker instalada em seu sistema.</p> <p>Voc\u00ea tamb\u00e9m pode executar o <code>Hello World</code> do docker, com o seguinte comando:</p> <pre><code>docker run hello-world\n</code></pre> <p>Isso deve baixar uma imagem de teste do Docker Hub e executar um cont\u00eainer a partir dela. Se tudo estiver funcionando corretamente, voc\u00ea ver\u00e1 uma mensagem de boas-vindas do Docker.</p>"},{"location":"docker/#os-componentes-do-docker","title":"Os componentes do Docker","text":"<p>Existem tr\u00eas componentes principais no ecossistema Docker:</p> <ul> <li>Dockerfile: Um arquivo de texto contendo instru\u00e7\u00f5es (comandos) para construir uma imagem Docker.</li> <li>Imagem Docker: Um instant\u00e2neo de um cont\u00eainer, criado a partir de um Dockerfile. As imagens s\u00e3o armazenadas em um registro, como o Docker Hub, e podem ser puxadas ou enviadas para o registro.</li> <li>Cont\u00eainer Docker: Uma inst\u00e2ncia em execu\u00e7\u00e3o de uma imagem Docker.</li> </ul>"},{"location":"docker/#estrutura-do-dockerfile","title":"Estrutura do Dockerfile","text":"<p>Um Dockerfile \u00e9 um arquivo de texto que cont\u00e9m uma s\u00e9rie de instru\u00e7\u00f5es para criar uma imagem Docker. Cada instru\u00e7\u00e3o no Dockerfile cria uma camada na imagem, e essas camadas s\u00e3o empilhadas para formar a imagem final. Aqui est\u00e1 um exemplo b\u00e1sico de um Dockerfile:</p> <pre><code>FROM ubuntu:20.04 # (1)\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y nodejs npm\nWORKDIR /app\nCOPY . .\nRUN npm install\nEXPOSE 3000\nCMD [\"npm\", \"start\"]\n</code></pre> <ol> <li><code>FROM</code>: Especifica a imagem base a ser usada. Neste caso, estamos usando a imagem oficial do Ubuntu 20.04.</li> <li><code>RUN</code>: Executa comandos no cont\u00eainer durante a constru\u00e7\u00e3o da imagem. Aqui, estamos atualizando o sistema e instalando o Node.js e o npm.</li> <li><code>WORKDIR</code>: Define o diret\u00f3rio de trabalho dentro do cont\u00eainer. Todos os comandos subsequentes ser\u00e3o executados a partir desse diret\u00f3rio.</li> <li><code>COPY</code>: Copia arquivos do diret\u00f3rio atual (no host) para o cont\u00eainer.</li> <li><code>EXPOSE</code>: Informa ao Docker que o cont\u00eainer escutar\u00e1 na porta especificada em tempo de execu\u00e7\u00e3o. Isso n\u00e3o publica a porta, mas \u00e9 uma boa pr\u00e1tica documentar quais portas o cont\u00eainer usar\u00e1.</li> <li><code>CMD</code>: Especifica o comando a ser executado quando o cont\u00eainer \u00e9 iniciado. Neste caso, estamos iniciando o aplicativo Node.js com <code>npm start</code>.</li> </ol> <p>O quadro abaixo resume os principais comandos do Dockerfile:</p> Comando Descri\u00e7\u00e3o <code>FROM</code> Especifica a imagem base a ser usada. <code>RUN</code> Executa comandos no cont\u00eainer durante a constru\u00e7\u00e3o da imagem. <code>WORKDIR</code> Define o diret\u00f3rio de trabalho dentro do cont\u00eainer. <code>COPY</code> Copia arquivos do diret\u00f3rio atual (no host) para o cont\u00eainer. <code>EXPOSE</code> Informa ao Docker que o cont\u00eainer escutar\u00e1 na porta especificada. <code>CMD</code> Especifica o comando a ser executado quando o cont\u00eainer \u00e9 iniciado. <code>ENTRYPOINT</code> Define o ponto de entrada do cont\u00eainer, permitindo que o cont\u00eainer seja executado como um execut\u00e1vel. <code>ENV</code> Define vari\u00e1veis de ambiente dentro do cont\u00eainer. <code>VOLUME</code> Cria um ponto de montagem para persist\u00eancia de dados. <code>ARG</code> Define vari\u00e1veis de constru\u00e7\u00e3o que podem ser passadas durante a constru\u00e7\u00e3o da imagem. <code>LABEL</code> Adiciona metadados \u00e0 imagem, como autor, vers\u00e3o, etc. <code>ADD</code> Copia arquivos e diret\u00f3rios do host para o cont\u00eainer, com suporte a URLs e extra\u00e7\u00e3o de arquivos tar. <code>USER</code> Define o usu\u00e1rio a ser usado ao executar o cont\u00eainer. <code>HEALTHCHECK</code> Define um comando para verificar a sa\u00fade do cont\u00eainer. <code>ONBUILD</code> Adiciona instru\u00e7\u00f5es que ser\u00e3o executadas quando a imagem for usada como base para outra imagem. <p>A complexidade de um Dockerfile pode variar dependendo do aplicativo que voc\u00ea est\u00e1 criando. \u00c0 medida que voc\u00ea se familiariza com o Docker, voc\u00ea aprender\u00e1 a usar esses comandos de forma mais eficaz.</p> <p>A ordem dos comandos no Dockerfile \u00e9 importante, pois cada comando cria uma nova camada na imagem. O Docker tenta otimizar o processo de constru\u00e7\u00e3o, armazenando em cache as camadas que n\u00e3o mudaram. Portanto, \u00e9 uma boa pr\u00e1tica colocar os comandos que mudam com menos frequ\u00eancia (como a instala\u00e7\u00e3o de depend\u00eancias) antes dos que mudam com mais frequ\u00eancia (como a c\u00f3pia do c\u00f3digo-fonte).</p> <p>Note que, ao gerar uma imagem, o Docker executa cada comando do Dockerfile em uma nova camada. Isso significa que, se voc\u00ea modificar um comando no Dockerfile, todas as camadas subsequentes tamb\u00e9m ser\u00e3o reconstru\u00eddas, o que pode aumentar o tempo de constru\u00e7\u00e3o da imagem. Para otimizar isso, \u00e9 recomend\u00e1vel agrupar comandos relacionados e minimizar o n\u00famero de camadas criadas.</p>"},{"location":"docker/#a-imagem-docker","title":"A imagem Docker","text":"<p>Uma imagem Docker \u00e9 um arquivo leve, independente e execut\u00e1vel que cont\u00e9m tudo o que \u00e9 necess\u00e1rio para executar um aplicativo, incluindo o c\u00f3digo-fonte, bibliotecas, depend\u00eancias e arquivos de configura\u00e7\u00e3o. As imagens s\u00e3o criadas a partir de um Dockerfile fe podem ser armazenadas em um registro, como o Docker Hub.</p> <p>As imagens Docker s\u00e3o compostas por v\u00e1rias camadas, cada uma representando uma instru\u00e7\u00e3o no Dockerfile. Essas camadas s\u00e3o empilhadas para formar a imagem final. Quando voc\u00ea executa um cont\u00eainer a partir de uma imagem, o Docker cria uma camada de leitura e grava\u00e7\u00e3o em cima da imagem, permitindo que voc\u00ea fa\u00e7a altera\u00e7\u00f5es no cont\u00eainer sem afetar a imagem original.</p> <p>Por isso, as imagens Docker s\u00e3o imut\u00e1veis, o que significa que, uma vez criadas, n\u00e3o podem ser alteradas. Se voc\u00ea precisar fazer altera\u00e7\u00f5es em uma imagem, precisar\u00e1 criar uma nova imagem a partir do Dockerfile. As altera\u00e7\u00f5es que s\u00e3o feitas em um cont\u00eainer em execu\u00e7\u00e3o n\u00e3o afetam a imagem original, e s\u00e3o armazenadas numa camada sobreposta \u00e0 imagem original.</p> <p>As imagens Docker s\u00e3o identificadas por um nome e uma tag, que geralmente seguem o formato <code>nome:tag</code>. Por exemplo, <code>meuapp:1.0</code> refere-se \u00e0 imagem chamada <code>meuapp</code> com a tag <code>1.0</code>. Se voc\u00ea n\u00e3o especificar uma tag, o Docker usar\u00e1 a tag <code>latest</code> por padr\u00e3o.</p> <p>Voc\u00ea pode verificar a listagem de imagens dispon\u00edveis em sua m\u00e1quina local usando o seguinte comando:</p> <pre><code>docker image ls\n</code></pre> <p>Vamos supor que voc\u00ea n\u00e3o tenha ainda nenhuma imagem instalada. Voc\u00ea pode baixar uma imagem do Docker Hub usando o comando <code>docker pull</code>. Por exemplo, para baixar a imagem oficial do Nginx, voc\u00ea pode usar o seguinte comando:</p> <pre><code>docker pull nginx\n</code></pre> <p>Isso far\u00e1 o download da imagem do Nginx e a armazenar\u00e1 localmente. Voc\u00ea pode verificar se a imagem foi baixada com sucesso executando novamente o comando <code>docker image ls</code>. Voc\u00ea ver\u00e1 uma sa\u00edda semelhante a esta:</p> REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest 4cad75abc83d 2 weeks ago 192MB <p>A imagem <code>nginx</code> foi baixada e est\u00e1 dispon\u00edvel localmente. Voc\u00ea pode usar essa imagem para criar cont\u00eaineres Nginx em sua m\u00e1quina.</p>"},{"location":"docker/#o-conteiner-docker","title":"O cont\u00eainer Docker","text":"<p>Um cont\u00eainer Docker \u00e9 uma inst\u00e2ncia em execu\u00e7\u00e3o de uma imagem Docker. Como j\u00e1 estudamos, os cont\u00eaineres s\u00e3o isolados uns dos outros e do host, o que significa que eles t\u00eam seu pr\u00f3prio sistema de arquivos, rede e processos. Isso permite que voc\u00ea execute v\u00e1rios cont\u00eaineres em um \u00fanico host sem conflitos.</p> <p>Os cont\u00eaineres s\u00e3o criados a partir de imagens Docker e podem ser iniciados, parados e removidos conforme necess\u00e1rio. Quando voc\u00ea executa um cont\u00eainer, o Docker cria uma camada de leitura e grava\u00e7\u00e3o em cima da imagem, permitindo que voc\u00ea fa\u00e7a altera\u00e7\u00f5es no cont\u00eainer sem afetar a imagem original.</p> <p>Os cont\u00eaineres s\u00e3o ef\u00eameros por natureza, o que significa que eles podem ser iniciados e parados rapidamente. Quando um cont\u00eainer \u00e9 parado, ele pode ser removido ou reiniciado a partir da imagem original. Isso torna os cont\u00eaineres ideais para ambientes de desenvolvimento e produ\u00e7\u00e3o, onde voc\u00ea pode precisar criar e destruir inst\u00e2ncias rapidamente.</p> <p>Os cont\u00eaineres podem ser executados em segundo plano (modo \"detached\") ou em primeiro plano (modo \"foreground\"). Quando um cont\u00eainer \u00e9 executado em segundo plano, ele continua em execu\u00e7\u00e3o mesmo depois que o terminal \u00e9 fechado. Para executar um cont\u00eainer em segundo plano, voc\u00ea pode usar a op\u00e7\u00e3o <code>-d</code> com o comando <code>docker run</code>. Por exemplo:</p> <pre><code>docker run -d -p 8001:80 nginx\n</code></pre> <p>Isso executar\u00e1 um cont\u00eainer Nginx em segundo plano, mapeando a porta 80 do cont\u00eainer para a porta 8001 do host. Voc\u00ea pode acessar o Nginx no seu navegador em <code>http://localhost:8001</code>.</p> <p>Se voc\u00ea quiser ver uma lista dos cont\u00eaineres em execu\u00e7\u00e3o, pode usar o seguinte comando:</p> <pre><code>docker container ls\n</code></pre> <p>Isso exibir\u00e1 uma tabela com informa\u00e7\u00f5es sobre os cont\u00eaineres em execu\u00e7\u00e3o, incluindo o ID do cont\u00eainer, o nome da imagem, o status e as portas mapeadas.</p> <p>Se voc\u00ea quiser ver todos os cont\u00eaineres, incluindo os parados, pode usar o seguinte comando:</p> <pre><code>docker container ls -a\n</code></pre> <p>Isso exibir\u00e1 uma tabela com informa\u00e7\u00f5es sobre todos os cont\u00eaineres, incluindo os que est\u00e3o parados.</p> <p>Para parar um cont\u00eainer em execu\u00e7\u00e3o, voc\u00ea pode usar o seguinte comando:</p> <pre><code>docker container stop &lt;container_id&gt;\n</code></pre> <p>Substitua <code>&lt;container_id&gt;</code> pelo ID do cont\u00eainer que voc\u00ea deseja parar. Voc\u00ea pode encontrar o ID do cont\u00eainer na sa\u00edda do comando <code>docker container ls</code>.</p>"},{"location":"docker/#comandos-do-docker","title":"Comandos do Docker","text":"<p>Abaixo est\u00e3o alguns comandos essenciais do Docker que voc\u00ea usar\u00e1 com frequ\u00eancia:</p> <ul> <li><code>docker pull &lt;image&gt;</code>: Baixar uma imagem de um registro, como o Docker Hub.</li> <li><code>docker build -t &lt;image_name&gt; &lt;path&gt;</code>: Criar uma imagem a partir de um Dockerfile, onde <code>&lt;path&gt;</code> \u00e9 o diret\u00f3rio que cont\u00e9m o Dockerfile.</li> <li><code>docker image ls</code>: Listar todas as imagens dispon\u00edveis em sua m\u00e1quina local.</li> <li><code>docker run -d -p &lt;host_port&gt;:&lt;container_port&gt; --name &lt;container_name&gt; &lt;image&gt;</code>: Executar um cont\u00eainer a partir de uma imagem, mapeando portas do host para portas do cont\u00eainer.</li> <li><code>docker container ls</code>: Listar todos os cont\u00eaineres em execu\u00e7\u00e3o.</li> <li><code>docker container stop &lt;container&gt;</code>: Parar um cont\u00eainer em execu\u00e7\u00e3o.</li> <li><code>docker container rm &lt;container&gt;</code>: Remover um cont\u00eainer parado.</li> <li><code>docker image rm &lt;image&gt;</code>: Remover uma imagem de sua m\u00e1quina local.</li> </ul>"},{"location":"docker/#persistencia-de-dados","title":"Persist\u00eancia de dados","text":"<p>Por padr\u00e3o, o armazenamento dentro de um cont\u00eainer Docker \u00e9 ef\u00eamero, o que significa que qualquer altera\u00e7\u00e3o ou modifica\u00e7\u00e3o de dados feita dentro de um cont\u00eainer s\u00f3 est\u00e1 dispon\u00edvel enquanto o cont\u00eainer estiver em execu\u00e7\u00e3o. Uma vez que o cont\u00eainer \u00e9 parado e removido, todos os dados associados a ele ser\u00e3o perdidos. Esse armazenamento tempor\u00e1rio ou de curta dura\u00e7\u00e3o \u00e9 chamado de \"sistema de arquivos ef\u00eamero do cont\u00eainer\".</p> <p>Em linhas gerais, quanto um cont\u00eainer inicia, ele usa os arquivos e a configura\u00e7\u00e3o fornecidos pela imagem. Cada cont\u00eainer \u00e9 capaz de criar, modificar e excluir arquivos, fazendo isso sem afetar nenhum outro cont\u00eainer. Quando o cont\u00eainer \u00e9 exclu\u00eddo, essas altera\u00e7\u00f5es de arquivo tamb\u00e9m s\u00e3o exclu\u00eddas.</p> <p>Embora essa natureza ef\u00eamera dos cont\u00eaineres seja \u00f3tima para desenvolvimento e testes, ela pode ser um desafio quando voc\u00ea deseja persistir dados entre reinicializa\u00e7\u00f5es de cont\u00eaineres. Por exemplo, se voc\u00ea reiniciar um cont\u00eainer de banco de dados, pode n\u00e3o querer come\u00e7ar com um banco de dados vazio. Portanto, como persistir arquivos?</p> <p>Existem duas abordagens principais para persistir dados em cont\u00eaineres Docker:</p> <ol> <li> <p>Bind mounts: Os bind mounts permitem que voc\u00ea monte um diret\u00f3rio do host dentro de um cont\u00eainer.</p> </li> <li> <p>Volumes: Os volumes s\u00e3o a maneira recomendada de persistir dados em cont\u00eaineres Docker. Eles s\u00e3o armazenados fora do sistema de arquivos do cont\u00eainer e podem ser compartilhados entre v\u00e1rios cont\u00eaineres.</p> </li> </ol>"},{"location":"docker/#bind-mounts","title":"Bind mounts","text":"<p>Os bind mounts, por sua vez, permitem que voc\u00ea monte um diret\u00f3rio do host dentro de um cont\u00eainer. Isso significa que qualquer altera\u00e7\u00e3o feita no diret\u00f3rio do host ser\u00e1 refletida no cont\u00eainer e vice-versa. Para usar um bind mount, voc\u00ea pode usar a op\u00e7\u00e3o <code>-v</code> com o caminho do diret\u00f3rio do host:</p> <pre><code>docker run -d -p 8001:80 -v /path/to/host/directory:/usr/share/nginx/html nginx\n</code></pre> <p>Isso montar\u00e1 o diret\u00f3rio <code>/path/to/host/directory</code> do host no diret\u00f3rio <code>/usr/share/nginx/html</code> dentro do cont\u00eainer Nginx. Qualquer arquivo criado ou modificado nesse diret\u00f3rio ser\u00e1 persistido no diret\u00f3rio do host, mesmo que o cont\u00eainer seja removido.</p> <p>\u00c9 importante notar que os bind mounts n\u00e3o s\u00e3o gerenciados pelo Docker e podem ser mais dif\u00edceis de gerenciar do que os volumes. Al\u00e9m disso, os bind mounts podem apresentar problemas de portabilidade, pois dependem do caminho do diret\u00f3rio no host.</p> <p>Bind mounts na pr\u00e1tica</p> <p>Vamos fazer um exemplo de modifica\u00e7\u00e3o no Nginx. Siga os seguintes passos:</p> <ul> <li> Vamos criar uma pasta para o nosso projeto, por exemplo <code>docker-nginx</code></li> <li> Abra esse diret\u00f3rio no Visual Studio Code ou no editor de sua prefer\u00eancia.</li> <li> Crie um sub-diret\u00f3rio com o nome <code>html</code> dentro de <code>docker-nginx</code>:</li> <li> Crie um arquivo <code>index.html</code> dentro do diret\u00f3rio <code>html</code> com o seguinte conte\u00fado:</li> </ul> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"pt-BR\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;Docker Nginx&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Bem-vindo ao Docker Nginx!&lt;/h1&gt;\n    &lt;p&gt;Este \u00e9 um exemplo de p\u00e1gina servida pelo Nginx em um cont\u00eainer Docker.&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <ul> <li> Agora, execute o seguinte comando no terminal:</li> </ul> <pre><code>docker run -p 8001:80 -v $(pwd)/html:/usr/share/nginx/html nginx # (1)\n</code></pre> <ul> <li> <p> Agora, abra o navegador e acesse <code>http://localhost:8001</code>. Voc\u00ea ver\u00e1 a p\u00e1gina HTML que voc\u00ea criou no diret\u00f3rio <code>html</code> do host.</p> </li> <li> <p> Agora, fa\u00e7a uma altera\u00e7\u00e3o no arquivo <code>index.html</code> e salve. Voc\u00ea ver\u00e1 que a p\u00e1gina no navegador ser\u00e1 atualizada automaticamente com as altera\u00e7\u00f5es feitas no arquivo <code>index.html</code> do host.</p> </li> </ul> <ol> <li> Isso iniciar\u00e1 um cont\u00eainer Nginx, mapeando a porta 80 do cont\u00eainer para a porta 8001 do host e montando o diret\u00f3rio <code>html</code> do host no diret\u00f3rio <code>/usr/share/nginx/html</code> dentro do cont\u00eainer. Lembre-se que este diret\u00f3rio \u00e9 onde o Nginx procura os arquivos HTML para servir.</li> </ol>"},{"location":"docker/#volumes","title":"Volumes","text":"<p>Como citado anteriormente, os volumes s\u00e3o gerenciados pelo Docker e podem ser facilmente criados, removidos e compartilhados. Para criar um volume, voc\u00ea pode usar o seguinte comando:</p> <pre><code>docker volume create &lt;volume_name&gt;\n</code></pre> <p>Para usar um volume ao executar um cont\u00eainer, voc\u00ea pode usar a op\u00e7\u00e3o <code>-v</code>:</p> <pre><code>docker run -d -p 8001:80 -v &lt;volume_name&gt;:/usr/share/nginx/html nginx\n</code></pre> <p>Isso montar\u00e1 o volume <code>&lt;volume_name&gt;</code> no diret\u00f3rio <code>/usr/share/nginx/html</code> dentro do cont\u00eainer Nginx. Qualquer arquivo criado ou modificado nesse diret\u00f3rio ser\u00e1 persistido no volume, mesmo que o cont\u00eainer seja removido.</p> <p>Para colocar em pr\u00e1tica, vamos usar o exemplo de um cont\u00eainer com um servidor de banco de dados PostgreSQL. Como comentado anteriormente, se voc\u00ea reiniciar um cont\u00eainer de banco de dados, pode n\u00e3o querer come\u00e7ar com um banco de dados vazio. Dessa forma, o uso de volumes pode ser uma boa solu\u00e7\u00e3o.</p> <p>Volumes na pr\u00e1tica</p> <p>Vamos fazer um exemplo de persist\u00eancia de dados com o PostgreSQL. Siga os seguintes passos:</p> <ul> <li> Primeiro vamos criar um volume com o nome <code>pgdata</code>:</li> </ul> <pre><code>docker volume create pgdata\n</code></pre> <ul> <li> Agora vamos executar um cont\u00eainer PostgreSQL, mapeando o volume <code>pgdata</code> para o diret\u00f3rio <code>/var/lib/postgresql/data</code> dentro do cont\u00eainer:</li> </ul> <p><pre><code>docker run -d \\\n    --name postgres \\\n    -e POSTGRES_USER=postgres \\\n    -e POSTGRES_PASSWORD=postgres \\\n    -p 5432:5432 \\\n    -v pgdata:/var/lib/postgresql/data \\\n    postgres # (1)\n</code></pre> - [x] Agora, voc\u00ea pode acessar o banco de dados PostgreSQL usando um cliente de banco de dados, como o DBeaver ou o pgAdmin, usando as seguintes credenciais:</p> <pre><code>Host: localhost\nPorta: 5432\nUsu\u00e1rio: postgres\nSenha: postgres\n</code></pre> <ul> <li> Todas as altera\u00e7\u00f5es que voc\u00ea fizer no banco de dados ser\u00e3o persistidas no volume <code>pgdata</code>, mesmo que o cont\u00eainer seja removido.</li> <li> Para parar o cont\u00eainer, voc\u00ea pode usar o seguinte comando:</li> </ul> <pre><code>docker container stop postgres\n</code></pre> <ol> <li>Note que estamos usando a imagem oficial do PostgreSQL e mapeando o volume <code>pgdata</code> para o diret\u00f3rio <code>/var/lib/postgresql/data</code> dentro do cont\u00eainer. Esse diret\u00f3rio \u00e9 onde o PostgreSQL armazena os dados do banco de dados. Isso garante que os dados persistam mesmo que o cont\u00eainer seja removido. Tamb\u00e9m estamos mapeando a porta 5432 do cont\u00eainer para a porta 5432 do host, permitindo que voc\u00ea acesse o banco de dados a partir do host.</li> </ol> <p>Os volumes s\u00e3o administrados pelo Docker e podem ser facilmente criados, removidos e compartilhados entre cont\u00eaineres. Voc\u00ea pode listar os volumes dispon\u00edveis em sua m\u00e1quina local usando o seguinte comando:</p> <pre><code>docker volume ls\n</code></pre> <p>Isso exibir\u00e1 uma tabela com informa\u00e7\u00f5es sobre os volumes dispon\u00edveis, incluindo o nome e o driver do volume.</p> <p>Uma informa\u00e7\u00e3o importante \u00e9 que os dados do volume n\u00e3o ficam armazenados dentro do cont\u00eainer, mas sim em um diret\u00f3rio espec\u00edfico no host. O Docker gerencia esse diret\u00f3rio e garante que os dados sejam persistidos mesmo que o cont\u00eainer seja removido. Isso significa que voc\u00ea pode remover um cont\u00eainer e ainda ter acesso aos dados armazenados no volume.</p> <p>Para visualizar o local dos dados do volume no host, voc\u00ea pode usar o seguinte comando:</p> <pre><code>docker volume inspect &lt;volume_name&gt;\n</code></pre> <p>Isso exibir\u00e1 informa\u00e7\u00f5es detalhadas sobre o volume, incluindo o caminho no host onde os dados est\u00e3o armazenados. O caminho pode variar dependendo do sistema operacional e da configura\u00e7\u00e3o do Docker.</p>"},{"location":"docker/#docker-compose","title":"Docker compose","text":"<p>O Docker Compose \u00e9 uma ferramenta que permite definir e executar aplicativos Docker compostos por v\u00e1rios cont\u00eaineres. Com o Docker Compose, voc\u00ea pode usar um arquivo YAML para configurar os servi\u00e7os, redes e volumes necess\u00e1rios para o seu aplicativo. Isso facilita a orquestra\u00e7\u00e3o de cont\u00eaineres e a cria\u00e7\u00e3o de ambientes de desenvolvimento e produ\u00e7\u00e3o consistentes.</p> <p>O formato YAML \u00e9 uma linguagem de serializa\u00e7\u00e3o de dados leg\u00edvel por humanos, que \u00e9 amplamente utilizada para configura\u00e7\u00e3o de aplicativos, em especial no contexto de DevOps e infraestrutura como c\u00f3digo. O arquivo de configura\u00e7\u00e3o do Docker Compose \u00e9 chamado <code>docker-compose.yml</code> e deve estar localizado no diret\u00f3rio raiz do seu projeto.</p> <p>O Docker Compose \u00e9 especialmente \u00fatil quando voc\u00ea tem um aplicativo que depende de v\u00e1rios servi\u00e7os, como um banco de dados, um servidor web e um servi\u00e7o de cache. Com o Docker Compose, voc\u00ea pode definir todos esses servi\u00e7os em um \u00fanico arquivo e iniciar todos eles com um \u00fanico comando.</p> <p>Todas as configura\u00e7\u00f5es que s\u00e3o realizadas na configura\u00e7\u00e3o de um <code>docker-compose</code> podem ser realizadas diretamente na linha de comando, mas o uso do <code>docker-compose</code> \u00e9 mais pr\u00e1tico e organizado. Anteriormente, vimos como executar um cont\u00eainer Ngnix com persist\u00eancia de dados usando <code>bind mounts</code>. Tamb\u00e9m vimos como executar um cont\u00eainer PostgreSQL com persist\u00eancia de dados usando volumes.</p> <p>Agora, vamos considerar o seguinte cen\u00e1rio: voc\u00ea executa um cont\u00eainer docker com o PostgreSQL e um outro cont\u00eainer com a ferramenta <code>PgAdmin</code> (1). Contudo, voc\u00ea n\u00e3o quer que o banco de dados PostgreSQL fique exposto na rede, mas sim que o <code>PgAdmin</code> tenha acesso a ele. Para isso, voc\u00ea deveria criar uma rede interna entre os dois cont\u00eaineres. Isso pode ser feito facilmente com o Docker Compose, e veremos como fazer isso a seguir.</p> <ol> <li>O <code>PgAdmin</code> \u00e9 uma ferramenta de gerenciamento e administra\u00e7\u00e3o de banco de dados PostgreSQL. Ele fornece uma interface gr\u00e1fica para interagir com o banco de dados, permitindo que voc\u00ea execute consultas SQL, visualize dados e gerencie objetos do banco de dados.</li> </ol> docker-compose.yml<pre><code>services:\n  db:\n    image: postgres\n    environment:\n      - POSTGRES_USER=postgres\n      - POSTGRES_PASSWORD=postgres\n      - POSTGRES_DB=sample_db\n    volumes:\n      - db-postgres-data:/var/lib/postgresql/data\n    networks:\n      - internal-network\n  pgadmin:\n    image: dpage/pgadmin4\n    ports:\n      - '5050:80'\n    environment:\n      - PGADMIN_DEFAULT_EMAIL=admin@admin.com\n      - PGADMIN_DEFAULT_PASSWORD=admin\n    networks:\n      - internal-network\n\nnetworks:\n  internal-network:\n    driver: bridge\n\nvolumes:\n  db-postgres-data:\n    driver: local\n</code></pre> <p>Note que o arquivo est\u00e1 dividido em tr\u00eas se\u00e7\u00f5es principais: <code>services</code>, <code>networks</code> e <code>volumes</code>. A se\u00e7\u00e3o <code>services</code> define os servi\u00e7os que ser\u00e3o executados, a se\u00e7\u00e3o <code>networks</code> define as redes que ser\u00e3o criadas e a se\u00e7\u00e3o <code>volumes</code> define os volumes que ser\u00e3o utilizados.</p> <p>Na se\u00e7\u00e3o <code>services</code>, temos dois servi\u00e7os: <code>db</code> e <code>pgadmin</code>.</p> <ul> <li>db - Esse servi\u00e7o usa a imagem oficial do PostgreSQL e define algumas vari\u00e1veis de ambiente para configurar o banco de dados. O banco de dados ser\u00e1 criado com o nome <code>sample_db</code>, e as credenciais de acesso ser\u00e3o definidas como <code>postgres</code> para o usu\u00e1rio e senha. Note que o volume <code>db-postgres-data</code> \u00e9 montado no diret\u00f3rio <code>/var/lib/postgresql/data</code> dentro do cont\u00eainer, garantindo que os dados do banco de dados sejam persistidos mesmo que o cont\u00eainer seja removido. O servi\u00e7o <code>db</code> tamb\u00e9m est\u00e1 conectado \u00e0 rede interna <code>internal-network</code>, o que significa que ele pode se comunicar com outros servi\u00e7os na mesma rede.</li> <li>pgadmin - Esse servi\u00e7o usa a imagem oficial do PgAdmin e exp\u00f5e a porta 80 do cont\u00eainer na porta 5050 do <code>host</code>. As vari\u00e1veis de ambiente <code>PGADMIN_DEFAULT_EMAIL</code> e <code>PGADMIN_DEFAULT_PASSWORD</code> s\u00e3o usadas para definir as credenciais de acesso ao PgAdmin. O servi\u00e7o <code>pgadmin</code> tamb\u00e9m est\u00e1 conectado \u00e0 rede interna <code>internal-network</code>, permitindo que ele se comunique com o servi\u00e7o <code>db</code>.</li> </ul> <p>Relembrando</p> <p>Os nomes dessas vari\u00e1veis de ambiente foram definidos na documenta\u00e7\u00e3o oficial do PgAdmin. Voc\u00ea pode consultar a documenta\u00e7\u00e3o oficial do PgAdmin para mais informa\u00e7\u00f5es sobre as vari\u00e1veis de ambiente dispon\u00edveis. Cada imagem possui as suas vari\u00e1veis de ambiente, e \u00e9 importante consultar a documenta\u00e7\u00e3o para entender como configur\u00e1-las corretamente.</p> <p>Note que, pela configura\u00e7\u00e3o de <code>networks</code>, os dois servi\u00e7os est\u00e3o conectados \u00e0 mesma rede interna chamada <code>internal-network</code>. Isso significa que eles podem se comunicar entre si, mas n\u00e3o estar\u00e3o acess\u00edveis diretamente a partir do host. O PgAdmin poder\u00e1 acessar o banco de dados PostgreSQL usando o nome do servi\u00e7o <code>db</code> como hostname. O pr\u00f3prio Docker ir\u00e1 resolver o nome do servi\u00e7o para o endere\u00e7o IP do cont\u00eainer correspondente na rede interna, e tamb\u00e9m gerenciar\u00e1 a atribui\u00e7\u00e3o de endere\u00e7os IP para os cont\u00eaineres na rede criada.</p> <p>Para iniciar os servi\u00e7os definidos no arquivo <code>docker-compose.yml</code>, voc\u00ea pode usar o seguinte comando:</p> <pre><code>docker compose up # (1) (2)\n</code></pre> <ol> <li>Voc\u00ea tamb\u00e9m pode usar a op\u00e7\u00e3o <code>-d</code> para executar os servi\u00e7os em segundo plano (modo \"detached\").</li> <li>Tamb\u00e9m voc\u00ea pode definir apenas um servi\u00e7o espec\u00edfico para iniciar. O comando <code>docker compose up db</code> iniciar\u00e1 apenas o servi\u00e7o <code>db</code>.</li> </ol> <p>Depois de iniciado os servi\u00e7os, voc\u00ea pode acessar o PgAdmin no seu navegador em <code>http://localhost:5050</code>. Use as credenciais definidas no arquivo <code>docker-compose.yml</code> para fazer login. Depois de autenticado, voc\u00ea pode adicionar uma nova conex\u00e3o ao banco de dados PostgreSQL usando o nome do servi\u00e7o <code>db</code> como hostname e as credenciais definidas no arquivo <code>docker-compose.yml</code>.</p> <p>Com isso, o seu cont\u00eainer <code>pgadmin</code> poder\u00e1 acessar o banco de dados PostgreSQL, que est\u00e1 em outro cont\u00eainer, e voc\u00ea poder\u00e1 gerenciar o banco de dados atrav\u00e9s da interface gr\u00e1fica do PgAdmin.</p>"},{"location":"docker/#comandos-do-docker-compose","title":"Comandos do Docker Compose","text":"<p>Abaixo est\u00e3o alguns comandos essenciais do Docker Compose que voc\u00ea usar\u00e1 com maior frequ\u00eancia:</p> Comando Descri\u00e7\u00e3o <code>docker compose up</code> Cria e inicia os servi\u00e7os definidos no arquivo <code>docker-compose.yml</code>. <code>docker compose down</code> Para e remove os servi\u00e7os definidos no arquivo <code>docker-compose.yml</code>. <code>docker compose ps</code> Lista os servi\u00e7os em execu\u00e7\u00e3o definidos no arquivo <code>docker-compose.yml</code>. <code>docker compose logs</code> Exibe os logs dos servi\u00e7os em execu\u00e7\u00e3o definidos no arquivo <code>docker-compose.yml</code>. <code>docker compose build</code> Constr\u00f3i as imagens dos servi\u00e7os definidos no arquivo <code>docker-compose.yml</code>. <code>docker compose exec &lt;service&gt; &lt;command&gt;</code> Executa um comando em um cont\u00eainer em execu\u00e7\u00e3o de um servi\u00e7o definido no arquivo <code>docker-compose.yml</code>. <code>docker compose run &lt;service&gt;</code> Executa um comando em um novo cont\u00eainer de um servi\u00e7o definido no arquivo <code>docker-compose.yml</code>. <code>docker compose config</code> Valida e exibe a configura\u00e7\u00e3o do arquivo <code>docker-compose.yml</code>. <code>docker compose pull</code> Faz o download das imagens dos servi\u00e7os definidos no arquivo <code>docker-compose.yml</code>. <code>docker compose rm</code> Remove os cont\u00eaineres parados dos servi\u00e7os definidos no arquivo <code>docker-compose.yml</code>. <code>docker compose restart</code> Reinicia os servi\u00e7os definidos no arquivo <code>docker-compose.yml</code>. <code>docker compose start</code> Inicia os servi\u00e7os definidos no arquivo <code>docker-compose.yml</code> que est\u00e3o parados. <code>docker compose stop</code> Para os servi\u00e7os definidos no arquivo <code>docker-compose.yml</code> que est\u00e3o em execu\u00e7\u00e3o. <code>docker compose version</code> Exibe a vers\u00e3o do Docker Compose instalada. <code>docker compose help</code> Exibe a ajuda para o Docker Compose. <code>docker compose -f &lt;file&gt;</code> Especifica um arquivo de configura\u00e7\u00e3o diferente do padr\u00e3o <code>docker-compose.yml</code>. <p>Existem muitos outros comandos e op\u00e7\u00f5es dispon\u00edveis no Docker Compose, mas esses s\u00e3o os mais comuns e \u00fateis para come\u00e7ar. Voc\u00ea pode consultar a documenta\u00e7\u00e3o oficial do Docker Compose para obter mais informa\u00e7\u00f5es sobre os comandos e as op\u00e7\u00f5es dispon\u00edveis.</p>"},{"location":"docker/#redes-docker","title":"Redes Docker","text":"<p>No exemplo que apresentamos, foi criada uma rede interna chamada <code>internal-network</code>, que permite que os cont\u00eaineres se comuniquem entre si. O Docker cria automaticamente uma rede bridge padr\u00e3o chamada <code>bridge</code> quando o Docker \u00e9 instalado. Essa rede \u00e9 usada para conectar cont\u00eaineres em execu\u00e7\u00e3o no mesmo host.</p> <p>Em geral, o docker permite a cria\u00e7\u00e3o de diversos tipos de redes (<code>drivers</code>). Aqui, falaremos de tr\u00eas:</p> <ul> <li>Bridge: A rede bridge padr\u00e3o \u00e9 criada automaticamente pelo Docker e \u00e9 usada para conectar cont\u00eaineres em execu\u00e7\u00e3o no mesmo host. Essa rede permite que os cont\u00eaineres se comuniquem entre si usando endere\u00e7os IP internos.</li> <li>Host: A rede host conecta o cont\u00eainer diretamente \u00e0 rede do host. Isso significa que o cont\u00eainer compartilha o mesmo espa\u00e7o de rede que o host, permitindo acesso direto \u00e0s interfaces de rede do host. Essa rede \u00e9 \u00fatil quando voc\u00ea precisa de desempenho m\u00e1ximo e n\u00e3o se importa com o isolamento do cont\u00eainer.</li> <li>Overlay: A rede overlay permite que voc\u00ea conecte cont\u00eaineres em diferentes hosts Docker. Essa rede \u00e9 \u00fatil para criar aplicativos distribu\u00eddos que precisam se comunicar entre diferentes hosts. O Docker Swarm usa redes overlay para conectar servi\u00e7os em diferentes n\u00f3s do cluster.</li> </ul> <p>Na maioria das vezes voc\u00ea usar\u00e1 a rede bridge padr\u00e3o, que permitem que os cont\u00eaineres se comuniquem entre si usando nomes de servi\u00e7o, o que facilita a configura\u00e7\u00e3o e o gerenciamento de aplicativos compostos por v\u00e1rios cont\u00eaineres.</p> <p>Para listar as redes dispon\u00edveis em sua m\u00e1quina local, voc\u00ea pode usar o seguinte comando:</p> <pre><code>docker network ls\n</code></pre> <p>Tamb\u00e9m \u00e9 poss\u00edvel inspecionar uma rede espec\u00edfica para obter mais informa\u00e7\u00f5es sobre ela, como os cont\u00eaineres conectados a ela e as configura\u00e7\u00f5es de rede. Para isso, voc\u00ea pode usar o seguinte comando:</p> <pre><code>docker network inspect &lt;network_name&gt;\n</code></pre>"},{"location":"iac/","title":"Infraestrutura como C\u00f3digo (IaC)","text":""},{"location":"iac/#o-que-e-infraestrutura-como-codigo-iac","title":"O que \u00e9 Infraestrutura como C\u00f3digo (IaC)?","text":"<p>A Infraestrutura como C\u00f3digo (Infrastructure as Code \u2013 IaC) \u00e9 uma pr\u00e1tica fundamental nas abordagens modernas de DevOps e engenharia de software. Ela permite que a infraestrutura de TI \u2014 servidores, redes, m\u00e1quinas virtuais, armazenamento e at\u00e9 servi\u00e7os de nuvem \u2014 seja gerenciada e provisionada por meio de arquivos de c\u00f3digo, de maneira automatizada, reproduz\u00edvel e version\u00e1vel. Essa abordagem transforma a infraestrutura em um ativo de software, permitindo que equipes tratem a infraestrutura com os mesmos princ\u00edpios e pr\u00e1ticas que aplicam ao desenvolvimento de software.</p>"},{"location":"iac/#origens-da-iac","title":"Origens da IaC","text":"<p>A pr\u00e1tica de Infraestrutura como C\u00f3digo (IaC) tem suas ra\u00edzes na automa\u00e7\u00e3o de TI e na virtualiza\u00e7\u00e3o. Com o advento de tecnologias de virtualiza\u00e7\u00e3o, como VMware e Hyper-V, as equipes de TI come\u00e7aram a automatizar o provisionamento de m\u00e1quinas virtuais. Essa automa\u00e7\u00e3o inicial evoluiu para a necessidade de gerenciar n\u00e3o apenas m\u00e1quinas virtuais, mas tamb\u00e9m redes, armazenamento e outros componentes de infraestrutura de forma program\u00e1tica.</p> <p>A populariza\u00e7\u00e3o de servi\u00e7os de nuvem, como Amazon Web Services (AWS) e Microsoft Azure, tamb\u00e9m impulsionou a ado\u00e7\u00e3o da IaC. Esses provedores de nuvem oferecem APIs e ferramentas que permitem que a infraestrutura seja definida e gerenciada por meio de c\u00f3digo, tornando a IaC uma pr\u00e1tica padr\u00e3o nas opera\u00e7\u00f5es em nuvem.</p> <p>Antes do surgimento da IaC, a configura\u00e7\u00e3o de servidores era feita manualmente (via SSH, scripts shell, edi\u00e7\u00f5es em tempo real de arquivos de configura\u00e7\u00e3o), o que era demorado, sujeito a erros e dif\u00edcil de auditar ou replicar. Mesmo com a virtualiza\u00e7\u00e3o, embora ferramentas como VMWare e VirtualBox possibilitaram a cria\u00e7\u00e3o de ambientes mais r\u00e1pidos, ainda havia a depend\u00eancia de intera\u00e7\u00e3o manual. Mais recentemente, com o avan\u00e7o do DevOps e da computa\u00e7\u00e3o em nuvem, tornou-se essencial criar ambientes automatizados e reproduz\u00edveis \u2014 da\u00ed a ado\u00e7\u00e3o do IaC.</p>"},{"location":"iac/#beneficios-da-iac","title":"Benef\u00edcios da IaC","text":"<p>O uso de Infraestrutura como C\u00f3digo (IaC) traz uma s\u00e9rie de benef\u00edcios significativos para as equipes de desenvolvimento e opera\u00e7\u00f5es:</p> <ol> <li> <p>Automa\u00e7\u00e3o: A IaC permite a automa\u00e7\u00e3o do provisionamento e gerenciamento da infraestrutura, reduzindo a necessidade de interven\u00e7\u00f5es manuais e minimizando erros.</p> </li> <li> <p>Reproduzibilidade: Com a IaC, \u00e9 poss\u00edvel reproduzir ambientes de forma consistente, garantindo que as mesmas configura\u00e7\u00f5es sejam aplicadas em diferentes ambientes (desenvolvimento, teste, produ\u00e7\u00e3o).</p> </li> <li> <p>Versionamento: Assim como o c\u00f3digo-fonte, a infraestrutura pode ser versionada, permitindo que equipes rastreiem altera\u00e7\u00f5es, revertam para vers\u00f5es anteriores e colaborem de forma mais eficaz.</p> </li> <li> <p>Escalabilidade: A IaC facilita a escalabilidade da infraestrutura, permitindo que recursos sejam provisionados ou desprovisionados rapidamente, conforme a demanda.</p> </li> <li> <p>Integra\u00e7\u00e3o Cont\u00ednua e Entrega Cont\u00ednua (CI/CD): A IaC \u00e9 uma parte essencial das pr\u00e1ticas de CI/CD, permitindo que a infraestrutura seja tratada como c\u00f3digo e integrada aos pipelines de entrega de software.</p> </li> <li> <p>Auditoria e Conformidade: Com a IaC, \u00e9 poss\u00edvel auditar as configura\u00e7\u00f5es da infraestrutura de forma mais eficaz, garantindo que as pol\u00edticas de conformidade sejam seguidas e facilitando a identifica\u00e7\u00e3o de desvios.</p> </li> <li> <p>Redu\u00e7\u00e3o de error humanos: A automa\u00e7\u00e3o e a padroniza\u00e7\u00e3o proporcionadas pela IaC reduzem significativamente a probabilidade de erros humanos, que s\u00e3o comuns em processos manuais de configura\u00e7\u00e3o.</p> </li> </ol>"},{"location":"iac/#limitacoes-da-iac","title":"Limita\u00e7\u00f5es da IaC","text":"<p>Apesar dos muitos benef\u00edcios, a Infraestrutura como C\u00f3digo (IaC) tamb\u00e9m apresenta algumas limita\u00e7\u00f5es e desafios:</p> <ol> <li> <p>Complexidade: A IaC pode introduzir complexidade adicional, especialmente em ambientes grandes e distribu\u00eddos, onde a gest\u00e3o de depend\u00eancias e configura\u00e7\u00f5es pode se tornar desafiadora.</p> </li> <li> <p>Curva de Aprendizado: Para equipes que n\u00e3o est\u00e3o familiarizadas com a IaC, pode haver uma curva de aprendizado significativa para entender as ferramentas e pr\u00e1ticas associadas.</p> </li> <li> <p>Depend\u00eancia de Ferramentas: A IaC geralmente depende de ferramentas espec\u00edficas, o que pode levar a um acoplamento indesejado entre a infraestrutura e as ferramentas utilizadas.</p> </li> <li> <p>Gerenciamento de Estado: Em algumas ferramentas de IaC, o gerenciamento do estado da infraestrutura pode ser complicado, especialmente em ambientes din\u00e2micos onde os recursos s\u00e3o frequentemente criados e destru\u00eddos.</p> </li> <li> <p>Seguran\u00e7a: A IaC pode introduzir riscos de seguran\u00e7a se n\u00e3o for gerenciada adequadamente, especialmente se as credenciais e segredos forem armazenados em c\u00f3digo ou reposit\u00f3rios de forma insegura.</p> </li> </ol>"},{"location":"iac/#classificacao-da-iac-quanto-a-abordagem-de-implementacao","title":"Classifica\u00e7\u00e3o da IaC quanto \u00e0 abordagem de implementa\u00e7\u00e3o","text":"<p>A Infraestrutura como C\u00f3digo (IaC) pode ser classificada em duas categorias principais:</p> <ol> <li> <p>Declarativa: Nesse modelo, o usu\u00e1rio descreve o estado desejado da infraestrutura, e a ferramenta de IaC se encarrega de criar ou modificar os recursos para alcan\u00e7ar esse estado. Exemplos de ferramentas incluem Terraform e AWS CloudFormation.</p> </li> <li> <p>Imperativa: Nesse modelo, o usu\u00e1rio especifica os passos necess\u00e1rios para alcan\u00e7ar o estado desejado da infraestrutura. A ferramenta executa esses passos em ordem. Exemplos de ferramentas incluem Ansible e Chef.</p> </li> </ol>"},{"location":"iac/#tipos-de-ferramentas-de-iac","title":"Tipos de ferramentas de IaC","text":"<p>As ferramentas de Infraestrutura como C\u00f3digo (IaC) podem ser divididas em duas categorias principais:</p> <ol> <li> <p>Ferramentas de Provisionamento: Essas ferramentas s\u00e3o usadas para criar e gerenciar recursos de infraestrutura, como m\u00e1quinas virtuais, redes e servi\u00e7os em nuvem. Elas permitem que os usu\u00e1rios definam a infraestrutura desejada em arquivos de configura\u00e7\u00e3o e automatizem o processo de provisionamento. Exemplos incluem Terraform, AWS CloudFormation e Pulumi.</p> </li> <li> <p>Ferramentas de Configura\u00e7\u00e3o: Essas ferramentas s\u00e3o usadas para configurar e gerenciar o software e as aplica\u00e7\u00f5es em execu\u00e7\u00e3o na infraestrutura provisionada. Elas permitem que os usu\u00e1rios definam o estado desejado do software e automatizem a configura\u00e7\u00e3o dos sistemas. Exemplos incluem Ansible, Chef e Puppet.</p> </li> <li> <p>Ferramentas de Orquestra\u00e7\u00e3o: Essas ferramentas s\u00e3o usadas para coordenar e gerenciar a execu\u00e7\u00e3o de v\u00e1rias tarefas e processos em um ambiente de infraestrutura. Elas ajudam a garantir que as depend\u00eancias sejam atendidas e que os recursos sejam provisionados e configurados na ordem correta. Exemplos incluem Kubernetes (para orquestra\u00e7\u00e3o de cont\u00eaineres) e Apache Mesos.</p> </li> <li> <p>Ferramentas de Empacotamento: Essas ferramentas s\u00e3o usadas para empacotar e distribuir a infraestrutura como c\u00f3digo, facilitando o compartilhamento e a reutiliza\u00e7\u00e3o de configura\u00e7\u00f5es. Elas permitem que os usu\u00e1rios criem pacotes de infraestrutura que podem ser facilmente implantados em diferentes ambientes. \u00c9 muito comum para a cria\u00e7\u00e3o de ambientes locais. Exemplos incluem Docker (para cont\u00eaineres) e Vagrant (para ambientes de desenvolvimento).</p> </li> </ol>"},{"location":"iac/#ferramentas-comuns-de-iac","title":"Ferramentas Comuns de IaC","text":"<p>Existem v\u00e1rias ferramentas populares que suportam a pr\u00e1tica de IaC, incluindo:</p> <ul> <li> <p>Terraform: Uma ferramenta de c\u00f3digo aberto que permite definir e provisionar infraestrutura em nuvem usando uma linguagem de configura\u00e7\u00e3o declarativa.</p> </li> <li> <p>AWS CloudFormation: Um servi\u00e7o da Amazon Web Services que permite criar e gerenciar recursos da AWS usando arquivos de modelo.</p> </li> <li> <p>Ansible: Uma ferramenta de automa\u00e7\u00e3o que pode ser usada para configurar e gerenciar infraestrutura de forma declarativa.</p> </li> <li> <p>Pulumi: Uma plataforma que permite definir a infraestrutura usando linguagens de programa\u00e7\u00e3o convencionais, como JavaScript, TypeScript e Python.</p> </li> </ul>"},{"location":"iac/#laboratorio-de-integracao-do-packer-vagrant-virtualbox","title":"Laborat\u00f3rio de integra\u00e7\u00e3o do Packer + Vagrant + VirtualBox","text":"<p>Vamos fazer um laborat\u00f3rio de integra\u00e7\u00e3o do Packer com o Vagrant e o VirtualBox. O objetivo \u00e9 criar uma imagem de m\u00e1quina virtual personalizada usando o Packer, que ser\u00e1 utilizada pelo Vagrant para provisionar ambientes de desenvolvimento consistentes.</p>"},{"location":"iac/#fundamentos-das-ferramentas","title":"Fundamentos das ferramentas","text":"<ul> <li>Packer: \u00c9 uma ferramenta de c\u00f3digo aberto para criar imagens de m\u00e1quina virtual idempotentes e reutiliz\u00e1veis. Ele permite que voc\u00ea defina a configura\u00e7\u00e3o da imagem em um arquivo JSON ou HCL, especificando os recursos e as etapas de provisionamento necess\u00e1rios. O Packer suporta v\u00e1rios provedores de virtualiza\u00e7\u00e3o, incluindo VirtualBox, AWS, Azure e outros. Foi criado pela HashiCorp, a mesma empresa por tr\u00e1s do Terraform.</li> <li>Vagrant: \u00c9 uma ferramenta de c\u00f3digo aberto para criar e gerenciar ambientes de desenvolvimento virtualizados. Ele permite que voc\u00ea defina a configura\u00e7\u00e3o do ambiente em um arquivo Vagrantfile, especificando o sistema operacional, as depend\u00eancias e as configura\u00e7\u00f5es necess\u00e1rias. O Vagrant \u00e9 amplamente utilizado para criar ambientes de desenvolvimento consistentes e reproduz\u00edveis, facilitando o trabalho em equipe e a colabora\u00e7\u00e3o entre desenvolvedores. Foi criado tamb\u00e9m pela HashiCorp.</li> <li>VirtualBox: \u00c9 um software de virtualiza\u00e7\u00e3o de c\u00f3digo aberto que permite criar e executar m\u00e1quinas virtuais em diferentes sistemas operacionais. Ele \u00e9 amplamente utilizado como provedor de virtualiza\u00e7\u00e3o para o Vagrant, permitindo que os desenvolvedores criem e gerenciem ambientes de desenvolvimento virtualizados de forma f\u00e1cil e eficiente. O VirtualBox suporta uma ampla variedade de sistemas operacionais convidados e \u00e9 compat\u00edvel com v\u00e1rias plataformas, incluindo Windows, macOS e Linux. Ele foi desenvolvido pela Oracle e \u00e9 uma das ferramentas de virtualiza\u00e7\u00e3o mais populares no mundo do desenvolvimento de software.</li> </ul>"},{"location":"iac/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<ol> <li>Packer: Certifique-se de ter o Packer instalado em sua m\u00e1quina. Voc\u00ea pode baixar a vers\u00e3o mais recente do Packer em packer.io.</li> <li>Vagrant: Instale o Vagrant em sua m\u00e1quina. Voc\u00ea pode encontrar as instru\u00e7\u00f5es de instala\u00e7\u00e3o em vagrantup.com.</li> <li>VirtualBox: Instale o VirtualBox, que \u00e9 o provedor de virtualiza\u00e7\u00e3o utilizado pelo Vagrant. Voc\u00ea pode baixar o VirtualBox em virtualbox.org.</li> </ol>"},{"location":"iac/#criando-uma-imagem-personalizada-com-o-packer","title":"Criando uma imagem personalizada com o Packer","text":"<ol> <li> <p>Crie um diret\u00f3rio para o projeto:</p> <p>O arquivo deve ser:</p> <pre><code>mkdir packer-vagrant-virtualbox\ncd packer-vagrant-virtualbox\n</code></pre> </li> <li> <p>Crie um arquivo de configura\u00e7\u00e3o do Packer</p> <p>Crie um arquivo chamado <code>packer.pkr.hcl</code> com o seguinte conte\u00fado:</p> <pre><code>packer {\n    required_plugins {\n        virtualbox = {\n            version = \"~&gt; 1\"\n            source  = \"github.com/hashicorp/virtualbox\"\n        }\n        vagrant = {\n            version = \"&gt;= 1.1.1\"\n            source = \"github.com/hashicorp/vagrant\"\n        }\n    }\n}\n</code></pre> <p>Nesse caso estamos utilizando o HCL (HashiCorp Configuration Language) para definir a configura\u00e7\u00e3o do Packer. O arquivo especifica os plugins necess\u00e1rios, como o VirtualBox e o Vagrant. Os plugins s\u00e3o respons\u00e1veis por fornecer suporte a diferentes provedores de virtualiza\u00e7\u00e3o e ferramentas de provisionamento. Mais informa\u00e7\u00f5es sobre o HCL podem ser encontradas na documenta\u00e7\u00e3o do Packer.</p> <p>Voc\u00ea precisar agora inicializar o projeto Packer e instalar o plugins registrados. Para isso, execute os seguintes comandos:</p> <pre><code>packer init .\npacker install plugin github.com/hashicorp/virtualbox\npacker install plugin github.com/hashicorp/vagrant\n</code></pre> </li> <li> <p>Crie um arquivo de configura\u00e7\u00e3o do Packer</p> <p>Crie um arquivo chamado <code>debian.json</code> com o seguinte conte\u00fado:</p> <pre><code>{\n  \"variables\": {\n    \"vm_name\": \"debian12\",\n    \"iso_url\": \"https://cdimage.debian.org/debian-cd/current/amd64/iso-cd/debian-12.11.0-amd64-netinst.iso\",\n    \"iso_checksum\": \"sha256:30ca12a15cae6a1033e03ad59eb7f66a6d5a258dcf27acd115c2bd42d22640e8\"\n  },\n  \"builders\": [\n    {\n      \"type\": \"virtualbox-iso\",\n      \"guest_os_type\": \"Debian_64\",\n      \"vm_name\": \"{{user `vm_name`}}\",\n      \"iso_url\": \"{{user `iso_url`}}\",\n      \"iso_checksum\": \"{{user `iso_checksum`}}\",\n      \"ssh_username\": \"vagrant\",\n      \"ssh_password\": \"vagrant\",\n      \"ssh_timeout\": \"20m\",\n      \"shutdown_command\": \"echo 'vagrant' | sudo -S shutdown -P now\",\n      \"disk_size\": 61440,\n      \"http_directory\": \"http\",\n      \"boot_wait\": \"5s\",\n      \"boot_command\": [\n        \"&lt;esc&gt;&lt;wait&gt;\",\n        \"auto url=http://{{ .HTTPIP }}:{{ .HTTPPort }}/preseed.cfg \",\n        \"debian-installer=en_US auto locale=pt_BR \",\n        \"kbd-chooser/method=us \",\n        \"hostname={{user `vm_name`}} \",\n        \"fb=false debconf/frontend=noninteractive \",\n        \"keyboard-configuration/layout=Brazilian \",\n        \"keyboard-configuration/variant=Brazilian&lt;enter&gt;\"\n      ],\n      \"vboxmanage\": [\n        [\"modifyvm\", \"{{.Name}}\", \"--memory\", \"2048\"],\n        [\"modifyvm\", \"{{.Name}}\", \"--cpus\", \"2\"],\n\n        [\"modifyvm\", \"{{.Name}}\", \"--nic1\", \"nat\"],\n        [\"modifyvm\", \"{{.Name}}\", \"--nictype1\", \"82540EM\"],\n        [\"modifyvm\", \"{{.Name}}\", \"--cableconnected1\", \"on\"]\n      ]\n    }\n  ],\n  \"provisioners\": [\n    {\n      \"type\": \"shell\",\n      \"inline\": [\n        \"echo 'Provisionando como vagrant...'\",\n        \"echo 'auto enp0s8' | sudo tee -a /etc/network/interfaces\",\n        \"echo 'iface enp0s8 inet dhcp' | sudo tee -a /etc/network/interfaces\",\n        \"mkdir -p /home/vagrant/.ssh\",\n        \"chmod 700 /home/vagrant/.ssh\",\n        \"curl -fsSL https://raw.githubusercontent.com/hashicorp/vagrant/main/keys/vagrant.pub -o /home/vagrant/.ssh/authorized_keys\",\n        \"cat /home/vagrant/.ssh/authorized_keys\",\n        \"chmod 600 /home/vagrant/.ssh/authorized_keys\",\n        \"chown -R vagrant:vagrant /home/vagrant/.ssh\"\n      ]\n    }\n  ],\n  \"post-processors\": [\n    {\n      \"type\": \"vagrant\",\n      \"output\": \"debian12.box\"\n    }\n  ]\n}\n</code></pre> <p>Nesse arquivo, definimos as vari\u00e1veis necess\u00e1rias, como o nome da m\u00e1quina virtual, a URL do ISO do Debian e o checksum do ISO. Em seguida, configuramos o construtor <code>virtualbox-iso</code>, que especifica as configura\u00e7\u00f5es da m\u00e1quina virtual, como o tipo de sistema operacional convidado, o nome da m\u00e1quina virtual, a URL do ISO e as configura\u00e7\u00f5es de rede. O comando de inicializa\u00e7\u00e3o \u00e9 configurado para automatizar a instala\u00e7\u00e3o do Debian usando um arquivo de pr\u00e9-configura\u00e7\u00e3o.</p> <p>Na chave <code>builder</code> especificamos o tipo de construtor como <code>virtualbox-iso</code>, que \u00e9 respons\u00e1vel por criar uma imagem de m\u00e1quina virtual usando o VirtualBox. As configura\u00e7\u00f5es incluem:</p> <ul> <li><code>guest_os_type</code>: Define o tipo de sistema operacional convidado, neste caso, Debian 64 bits.</li> <li><code>vm_name</code>: Define o nome da m\u00e1quina virtual. Essa informa\u00e7\u00e3o \u00e9 passada como uma vari\u00e1vel, permitindo que voc\u00ea altere facilmente o ISO sem modificar o arquivo principal.</li> <li><code>iso_url</code>: Especifica a URL do ISO do Debian que ser\u00e1 usado para criar a imagem. Essa informa\u00e7\u00e3o tamb\u00e9m \u00e9 uma vari\u00e1vel.</li> <li><code>iso_checksum</code>: Fornece o checksum do ISO para garantir a integridade do arquivo. Como as duas anteriores, \u00e9 uma vari\u00e1vel.</li> <li><code>ssh_username</code> e <code>ssh_password</code>: Definem as credenciais SSH para acessar a m\u00e1quina virtual durante o provisionamento.</li> <li><code>ssh_timeout</code>: Define o tempo limite para a conex\u00e3o SSH.</li> <li><code>shutdown_command</code>: Especifica o comando para desligar a m\u00e1quina virtual ap\u00f3s o provisionamento.</li> <li><code>disk_size</code>: Define o tamanho do disco da m\u00e1quina virtual em megabytes.</li> <li><code>http_directory</code>: Especifica o diret\u00f3rio onde o Packer procurar\u00e1 arquivos HTTP para provisionamento.</li> <li><code>boot_wait</code>: Define o tempo de espera antes de iniciar o processo de boot.</li> <li><code>boot_command</code>: Define os comandos de boot que ser\u00e3o enviados para a m\u00e1quina virtual durante o processo de inicializa\u00e7\u00e3o. Esses comandos s\u00e3o usados para automatizar a instala\u00e7\u00e3o do Debian usando um arquivo de pr\u00e9-configura\u00e7\u00e3o. Essas informa\u00e7\u00f5es s\u00e3o passadas como uma lista de strings, onde cada string representa um comando a ser enviado para a m\u00e1quina virtual no momento do boot.</li> <li><code>vboxmanage</code>: Permite modificar as configura\u00e7\u00f5es da m\u00e1quina virtual usando comandos do VirtualBox. Aqui, estamos configurando a mem\u00f3ria, o n\u00famero de CPUs e as configura\u00e7\u00f5es de rede. Nesse caso, estamos configurando a m\u00e1quina virtual para usar 2 GB de mem\u00f3ria, 2 CPUs e uma interface de rede NAT.</li> </ul> <p>O bloco <code>provisioners</code> define as etapas de provisionamento que ser\u00e3o executadas ap\u00f3s a cria\u00e7\u00e3o da imagem. Neste caso, estamos usando um provisionador do tipo <code>shell</code>, que executa comandos shell na m\u00e1quina virtual. Os comandos incluem a configura\u00e7\u00e3o da interface de rede e a adi\u00e7\u00e3o da chave SSH do Vagrant. Note que ele baixa a chave p\u00fablica do Vagrant diretamente do reposit\u00f3rio oficial, que ser\u00e1 usada para autentica\u00e7\u00e3o SSH no provisionamento.</p> <p>O bloco <code>post-processors</code> define as etapas que ser\u00e3o executadas ap\u00f3s o provisionamento. Neste caso, estamos usando um post-processor do tipo <code>vagrant</code>, que cria um arquivo <code>.box</code> que pode ser usado pelo Vagrant para criar m\u00e1quinas virtuais a partir da imagem criada pelo Packer.</p> </li> <li> <p>Crie um arquivo de pr\u00e9-configura\u00e7\u00e3o:</p> <p>Crie um diret\u00f3rio chamado <code>http</code> e dentro dele, crie um arquivo chamado <code>preseed.cfg</code> com o seguinte conte\u00fado:</p> <pre><code>d-i debian-installer/locale string pt_BR.UTF-8\n\nd-i console-setup/ask_detect boolean false\nd-i keyboard-configuration/xkb-keymap select br\nd-i keyboard-configuration/layout select Brazil\nd-i keyboard-configuration/variant select abnt2\nd-i keyboard-configuration/modelcode string abnt2\n\nd-i netcfg/choose_interface select enp0s3\nd-i netcfg/choose_interface_if_needed boolean false\nd-i netcfg/choose_interface priority critical\nd-i netcfg/get_hostname string debian12\nd-i netcfg/get_domain string localdomain\n\nd-i mirror/country string manual\nd-i mirror/http/hostname string deb.debian.org\nd-i mirror/http/directory string /debian\nd-i mirror/http/proxy string\n\nd-i accessibility-profile/choose-profile select none\n\nd-i clock-setup/utc boolean true\nd-i time/zone string America/Sao_Paulo\nd-i clock-setup/ntp boolean true\n\nd-i partman-auto/method string regular\nd-i partman-auto/choose_recipe select atomic\nd-i partman-partitioning/confirm_write_new_label boolean true\nd-i partman/choose_partition select finish\nd-i partman/confirm boolean true\nd-i partman/confirm_nooverwrite boolean true\n\nd-i passwd/user-fullname string Vagrant User\nd-i passwd/username string vagrant\nd-i passwd/user-password password vagrant\nd-i passwd/user-password-again password vagrant\nd-i user-setup/encrypt-home boolean false\nd-i user-setup/allow-password-weak boolean true\nd-i passwd/user-default-groups string sudo\n\nd-i passwd/root-login boolean false\nd-i passwd/root-password password root\nd-i passwd/root-password-again password root\n\nd-i grub-installer/only_debian boolean true\nd-i grub-installer/bootdev string /dev/sda\nd-i finish-install/reboot_in_progress note\nd-i preseed/late_command string in-target adduser vagrant sudo\nd-i preseed/late_command string in-target sh -c \"echo 'vagrant ALL=(ALL) NOPASSWD:ALL' &gt; /etc/sudoers.d/vagrant &amp;&amp; chmod 440 /etc/sudoers.d/vagrant\"\n\nd-i pkgsel/run_tasksel boolean false\nd-i pkgsel/include string openssh-server build-essential\nd-i pkgsel/include string sudo curl vim net-tools ssh lynx ansible\n\nd-i pkgsel/upgrade select full-upgrade\n</code></pre> </li> <li> <p>Crie o arquivo de imagem</p> <p>Execute o seguinte comando para criar a sua imagem:</p> <pre><code>packer build debian.json\n</code></pre> </li> <li> <p>Adicione a imagem criada ao Vagrant</p> <p>Ap\u00f3s a cria\u00e7\u00e3o da imagem, voc\u00ea pode adicionar a imagem ao Vagrant usando o seguinte comando:</p> <pre><code>vagrant box add debian12 debian12.box\n</code></pre> <p>Isso registrar\u00e1 a imagem <code>debian12.box</code> no Vagrant, permitindo que voc\u00ea crie m\u00e1quinas virtuais a partir dela.</p> </li> <li> <p>Crie o arquivo de configura\u00e7\u00e3o do Vagrant:</p> <p>Crie um arquivo chamado <code>Vagrantfile</code>, com seguinte conte\u00fado:</p> <pre><code>Vagrant.configure(\"2\") do |config|\n    config.vm.box = \"debian12\"\n\n    config.vm.network \"public_network\", bridge: \"enp2s0\"\n\n    config.vm.provider \"virtualbox\" do |vb|\n        vb.memory = \"2048\"\n        vb.cpus = 2\n    end\nend\n</code></pre> <p>Caso voc\u00ea queira, por exemplo, levantar tr\u00eas m\u00e1quinas virtuais, voc\u00ea pode modificar o arquivo <code>Vagrantfile</code> para incluir m\u00faltiplas m\u00e1quinas. Veja um exemplo:</p> <pre><code>Vagrant.configure(\"2\") do |config|\n  (1..3).each do |i|\n    config.vm.define \"debian#{i}\" do |machine|\n      machine.vm.box = \"debian12\"\n      machine.vm.network \"public_network\", bridge: \"enp2s0\"\n      machine.vm.provider \"virtualbox\" do |vb|\n        vb.memory = \"2048\"\n        vb.cpus = 2\n      end\n    end\n  end\nend\n</code></pre> <p>Nesse exemplo, estamos criando tr\u00eas m\u00e1quinas virtuais chamadas <code>debian1</code>, <code>debian2</code> e <code>debian3</code>, todas com as mesmas configura\u00e7\u00f5es de rede e recursos.</p> </li> <li> <p>Use o seu ambiente com o vagrant</p> <p>Para usar o ambiente criado execute:</p> <pre><code>vagrant up\n</code></pre> </li> </ol>"},{"location":"iac/#laboratorio-de-ansible","title":"Laborat\u00f3rio de Ansible","text":"<p>Ansible \u00e9 uma ferramenta de automa\u00e7\u00e3o de TI que permite gerenciar e configurar sistemas, implantar aplicativos e orquestrar tarefas complexas de forma simples e eficiente. Ele utiliza uma abordagem declarativa, onde o usu\u00e1rio define o estado desejado da infraestrutura ou dos sistemas, e o Ansible se encarrega de aplicar as mudan\u00e7as necess\u00e1rias para alcan\u00e7ar esse estado.</p> <p>Ansible \u00e9 amplamente utilizado em ambientes de DevOps e Infraestrutura como C\u00f3digo (IaC) devido \u00e0 sua simplicidade, flexibilidade e capacidade de automa\u00e7\u00e3o. Ele \u00e9 especialmente \u00fatil para gerenciar grandes quantidades de servidores e servi\u00e7os, permitindo que as equipes de TI automatizem tarefas repetitivas e se concentrem em atividades mais estrat\u00e9gicas.</p>"},{"location":"iac/#pre-requisitos_1","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar a trabalhar com Ansible, \u00e9 necess\u00e1rio ter um ambiente configurado. Aqui est\u00e3o os pr\u00e9-requisitos:</p> <ol> <li>Sistema Operacional: Ansible \u00e9 compat\u00edvel com sistemas baseados em Unix/Linux. Certifique-se de ter um sistema operacional adequado instalado, como Ubuntu, CentOS ou Debian.</li> <li>Python: Ansible requer Python 3.6 ou superior. Verifique se o Python est\u00e1 instalado no seu sistema executando o comando <code>python3 --version</code>.</li> <li>Acesso SSH: Ansible utiliza SSH para se conectar aos servidores remotos. Certifique-se de ter acesso SSH configurado para os servidores que deseja gerenciar.</li> <li>Instala\u00e7\u00e3o do Ansible: Voc\u00ea pode instalar o Ansible usando o gerenciador de pacotes do seu sistema.</li> </ol> <p>Note que voc\u00ea precise dos servidores que deseja gerenciar com Ansible. Para este laborat\u00f3rio, voc\u00ea pode usar m\u00e1quinas virtuais (que criamos no laborat\u00f3rio anterior) ou servidores na nuvem.</p> <p>Al\u00e9m disso, voc\u00ea deve gerar uma chave SSH para autentica\u00e7\u00e3o sem senha. Voc\u00ea pode fazer isso com o comando <code>ssh-keygen</code> e copiar a chave p\u00fablica para os servidores remotos usando <code>ssh-copy-id</code>.</p>"},{"location":"iac/#laboratorio-pratico","title":"Laborat\u00f3rio Pr\u00e1tico","text":"<p>Neste laborat\u00f3rio, vamos criar um playbook simples do Ansible para instalar e configurar um servidor web Nginx em uma m\u00e1quina virtual. O objetivo \u00e9 demonstrar como o Ansible pode ser usado para automatizar a configura\u00e7\u00e3o de servidores. Sugiro que voc\u00ea fa\u00e7a isso dentro de uma pasta chamada <code>ansible</code> dentro do diret\u00f3rio <code>devops</code>. Isso \u00e9 importante para dividir as configura\u00e7\u00f5es do Ansible de outras ferramentas e pr\u00e1ticas de DevOps, com o <code>Packer</code>, <code>Vagrant</code> e <code>Docker</code>.</p> <ol> <li> <p>Criar um arquivo de invent\u00e1rio</p> <p>Crie um arquivo chamado <code>hosts</code> na pasta <code>ansible</code> e adicione o seguinte conte\u00fado:</p> <pre><code>[webservers]\nwebserver1 ansible_host=192.168.56.101\nwebserver2 ansible_host=192.168.56.102\n\n[all:vars]\nansible_ssh_private_key_file=/caminho/para/chave/privada/ssh\nansible_user=vagrant\n</code></pre> <p>Substitua os endere\u00e7os IP pelos endere\u00e7os dos seus servidores. Esses IPs podem ser os endere\u00e7os das m\u00e1quinas virtuais criadas no laborat\u00f3rio anterior.</p> </li> <li> <p>Criar um playbook do Ansible</p> <p>Crie um arquivo chamado <code>install_nginx.yml</code> na pasta <code>ansible</code> e adicione o seguinte conte\u00fado:</p> <pre><code>---\n- name: Instalar e configurar Nginx\n  hosts: webservers\n  become: yes\n  tasks:\n    - name: Instalar o Nginx\n      apt:\n        name: nginx\n        state: present\n        update_cache: yes\n\n    - name: Garantir que o Nginx esteja rodando\n      service:\n        name: nginx\n        state: started\n</code></pre> <p>Voc\u00ea pode fazer v\u00e1rias outras configura\u00e7\u00f5es, como adicionar um arquivo de configura\u00e7\u00e3o personalizado ou copiar arquivos est\u00e1ticos para o servidor. Tamb\u00e9m \u00e9 poss\u00edvel adicionar outras tarefas, como instalar pacotes adicionais ou configurar o firewall.</p> </li> <li> <p>Executar o playbook do Ansible</p> <p>Para executar o playbook, abra um terminal na pasta <code>ansible</code> e execute o seguinte comando:</p> <pre><code>ansible-playbook -i hosts install_nginx.yml\n</code></pre> <p>Isso ir\u00e1 conectar-se aos servidores definidos no arquivo de invent\u00e1rio e executar as tarefas definidas no playbook.</p> </li> </ol>"},{"location":"iac/#conclusao","title":"Conclus\u00e3o","text":"<p>A Infraestrutura como C\u00f3digo (IaC) \u00e9 uma pr\u00e1tica essencial para equipes de DevOps que buscam aumentar a efici\u00eancia, reduzir erros e melhorar a colabora\u00e7\u00e3o. Ao tratar a infraestrutura como c\u00f3digo, as organiza\u00e7\u00f5es podem aproveitar os benef\u00edcios da automa\u00e7\u00e3o, reproduzibilidade e versionamento, tornando-se mais \u00e1geis e responsivas \u00e0s necessidades de neg\u00f3cios em constante mudan\u00e7a.</p> <p>Note que \u00e9 importante escolher a ferramenta de IaC certa com base nas necessidades espec\u00edficas da equipe e do projeto, considerando fatores como a complexidade da infraestrutura, a familiaridade da equipe com as ferramentas e os requisitos de integra\u00e7\u00e3o com outras pr\u00e1ticas de DevOps. Tamb\u00e9m, \u00e9 muito comum que as equipes utilizem uma combina\u00e7\u00e3o de ferramentas para atender a diferentes aspectos da IaC, como provisionamento, configura\u00e7\u00e3o e orquestra\u00e7\u00e3o.</p>"},{"location":"iac/lab-ansible/","title":"Lab ansible","text":""},{"location":"iac/lab-ansible/#laboratorio-de-ansible","title":"Laborat\u00f3rio de Ansible","text":"<p>Ansible \u00e9 uma ferramenta de automa\u00e7\u00e3o de TI que permite gerenciar e configurar sistemas, implantar aplicativos e orquestrar tarefas complexas de forma simples e eficiente. Ele utiliza uma abordagem declarativa, onde o usu\u00e1rio define o estado desejado da infraestrutura ou dos sistemas, e o Ansible se encarrega de aplicar as mudan\u00e7as necess\u00e1rias para alcan\u00e7ar esse estado.</p> <p>Ansible \u00e9 amplamente utilizado em ambientes de DevOps e Infraestrutura como C\u00f3digo (IaC) devido \u00e0 sua simplicidade, flexibilidade e capacidade de automa\u00e7\u00e3o. Ele \u00e9 especialmente \u00fatil para gerenciar grandes quantidades de servidores e servi\u00e7os, permitindo que as equipes de TI automatizem tarefas repetitivas e se concentrem em atividades mais estrat\u00e9gicas.</p>"},{"location":"iac/lab-ansible/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar a trabalhar com Ansible, \u00e9 necess\u00e1rio ter um ambiente configurado. Aqui est\u00e3o os pr\u00e9-requisitos:</p> <ol> <li>Sistema Operacional: Ansible \u00e9 compat\u00edvel com sistemas baseados em Unix/Linux. Certifique-se de ter um sistema operacional adequado instalado, como Ubuntu, CentOS ou Debian.</li> <li>Python: Ansible requer Python 3.6 ou superior. Verifique se o Python est\u00e1 instalado no seu sistema executando o comando <code>python3 --version</code>.</li> <li>Acesso SSH: Ansible utiliza SSH para se conectar aos servidores remotos. Certifique-se de ter acesso SSH configurado para os servidores que deseja gerenciar.</li> <li>Instala\u00e7\u00e3o do Ansible: Voc\u00ea pode instalar o Ansible usando o gerenciador de pacotes do seu sistema.</li> </ol> <p>Note que voc\u00ea precise dos servidores que deseja gerenciar com Ansible. Para este laborat\u00f3rio, voc\u00ea pode usar m\u00e1quinas virtuais (que criamos no laborat\u00f3rio anterior) ou servidores na nuvem.</p> <p>Al\u00e9m disso, voc\u00ea deve gerar uma chave SSH para autentica\u00e7\u00e3o sem senha. Voc\u00ea pode fazer isso com o comando <code>ssh-keygen</code> e copiar a chave p\u00fablica para os servidores remotos usando <code>ssh-copy-id</code>.</p>"},{"location":"iac/lab-ansible/#laboratorio-pratico","title":"Laborat\u00f3rio Pr\u00e1tico","text":"<p>Neste laborat\u00f3rio, vamos criar um playbook simples do Ansible para instalar e configurar um servidor web Nginx em uma m\u00e1quina virtual. O objetivo \u00e9 demonstrar como o Ansible pode ser usado para automatizar a configura\u00e7\u00e3o de servidores. Sugiro que voc\u00ea fa\u00e7a isso dentro de uma pasta chamada <code>ansible</code> dentro do diret\u00f3rio <code>devops</code>. Isso \u00e9 importante para dividir as configura\u00e7\u00f5es do Ansible de outras ferramentas e pr\u00e1ticas de DevOps, com o <code>Packer</code>, <code>Vagrant</code> e <code>Docker</code>.</p> <ol> <li> <p>Criar um arquivo de invent\u00e1rio</p> <p>Crie um arquivo chamado <code>hosts</code> na pasta <code>ansible</code> e adicione o seguinte conte\u00fado:</p> <pre><code>[webservers]\nwebserver1 ansible_host=192.168.56.101\nwebserver2 ansible_host=192.168.56.102\n\n[all:vars]\nansible_ssh_private_key_file=/caminho/para/chave/privada/ssh\nansible_user=vagrant\n</code></pre> <p>Substitua os endere\u00e7os IP pelos endere\u00e7os dos seus servidores. Esses IPs podem ser os endere\u00e7os das m\u00e1quinas virtuais criadas no laborat\u00f3rio anterior.</p> </li> <li> <p>Criar um playbook do Ansible</p> <p>Crie um arquivo chamado <code>install_nginx.yml</code> na pasta <code>ansible</code> e adicione o seguinte conte\u00fado:</p> <pre><code>---\n- name: Instalar e configurar Nginx\n  hosts: webservers\n  become: yes\n  tasks:\n    - name: Instalar o Nginx\n      apt:\n        name: nginx\n        state: present\n        update_cache: yes\n\n    - name: Garantir que o Nginx esteja rodando\n      service:\n        name: nginx\n        state: started\n</code></pre> <p>Voc\u00ea pode fazer v\u00e1rias outras configura\u00e7\u00f5es, como adicionar um arquivo de configura\u00e7\u00e3o personalizado ou copiar arquivos est\u00e1ticos para o servidor. Tamb\u00e9m \u00e9 poss\u00edvel adicionar outras tarefas, como instalar pacotes adicionais ou configurar o firewall.</p> </li> <li> <p>Executar o playbook do Ansible</p> <p>Para executar o playbook, abra um terminal na pasta <code>ansible</code> e execute o seguinte comando:</p> <pre><code>ansible-playbook -i hosts install_nginx.yml\n</code></pre> <p>Isso ir\u00e1 conectar-se aos servidores definidos no arquivo de invent\u00e1rio e executar as tarefas definidas no playbook.</p> </li> </ol>"},{"location":"iac/packer-vagrant-virtualbox/","title":"Packer vagrant virtualbox","text":""},{"location":"iac/packer-vagrant-virtualbox/#laboratorio-de-integracao-do-packer-vagrant-virtualbox","title":"Laborat\u00f3rio de integra\u00e7\u00e3o do Packer + Vagrant + VirtualBox","text":"<p>Vamos fazer um laborat\u00f3rio de integra\u00e7\u00e3o do Packer com o Vagrant e o VirtualBox. O objetivo \u00e9 criar uma imagem de m\u00e1quina virtual personalizada usando o Packer, que ser\u00e1 utilizada pelo Vagrant para provisionar ambientes de desenvolvimento consistentes.</p>"},{"location":"iac/packer-vagrant-virtualbox/#fundamentos-das-ferramentas","title":"Fundamentos das ferramentas","text":"<ul> <li>Packer: \u00c9 uma ferramenta de c\u00f3digo aberto para criar imagens de m\u00e1quina virtual idempotentes e reutiliz\u00e1veis. Ele permite que voc\u00ea defina a configura\u00e7\u00e3o da imagem em um arquivo JSON ou HCL, especificando os recursos e as etapas de provisionamento necess\u00e1rios. O Packer suporta v\u00e1rios provedores de virtualiza\u00e7\u00e3o, incluindo VirtualBox, AWS, Azure e outros. Foi criado pela HashiCorp, a mesma empresa por tr\u00e1s do Terraform.</li> <li>Vagrant: \u00c9 uma ferramenta de c\u00f3digo aberto para criar e gerenciar ambientes de desenvolvimento virtualizados. Ele permite que voc\u00ea defina a configura\u00e7\u00e3o do ambiente em um arquivo Vagrantfile, especificando o sistema operacional, as depend\u00eancias e as configura\u00e7\u00f5es necess\u00e1rias. O Vagrant \u00e9 amplamente utilizado para criar ambientes de desenvolvimento consistentes e reproduz\u00edveis, facilitando o trabalho em equipe e a colabora\u00e7\u00e3o entre desenvolvedores. Foi criado tamb\u00e9m pela HashiCorp.</li> <li>VirtualBox: \u00c9 um software de virtualiza\u00e7\u00e3o de c\u00f3digo aberto que permite criar e executar m\u00e1quinas virtuais em diferentes sistemas operacionais. Ele \u00e9 amplamente utilizado como provedor de virtualiza\u00e7\u00e3o para o Vagrant, permitindo que os desenvolvedores criem e gerenciem ambientes de desenvolvimento virtualizados de forma f\u00e1cil e eficiente. O VirtualBox suporta uma ampla variedade de sistemas operacionais convidados e \u00e9 compat\u00edvel com v\u00e1rias plataformas, incluindo Windows, macOS e Linux. Ele foi desenvolvido pela Oracle e \u00e9 uma das ferramentas de virtualiza\u00e7\u00e3o mais populares no mundo do desenvolvimento de software.</li> </ul>"},{"location":"iac/packer-vagrant-virtualbox/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<ol> <li>Packer: Certifique-se de ter o Packer instalado em sua m\u00e1quina. Voc\u00ea pode baixar a vers\u00e3o mais recente do Packer em packer.io.</li> <li>Vagrant: Instale o Vagrant em sua m\u00e1quina. Voc\u00ea pode encontrar as instru\u00e7\u00f5es de instala\u00e7\u00e3o em vagrantup.com.</li> <li>VirtualBox: Instale o VirtualBox, que \u00e9 o provedor de virtualiza\u00e7\u00e3o utilizado pelo Vagrant. Voc\u00ea pode baixar o VirtualBox em virtualbox.org.</li> </ol>"},{"location":"iac/packer-vagrant-virtualbox/#criando-uma-imagem-personalizada-com-o-packer","title":"Criando uma imagem personalizada com o Packer","text":"<ol> <li> <p>Crie um diret\u00f3rio para o projeto:</p> <p>O arquivo deve ser:</p> <pre><code>mkdir packer-vagrant-virtualbox\ncd packer-vagrant-virtualbox\n</code></pre> </li> <li> <p>Crie um arquivo de configura\u00e7\u00e3o do Packer</p> <p>Crie um arquivo chamado <code>packer.pkr.hcl</code> com o seguinte conte\u00fado:</p> <pre><code>packer {\n    required_plugins {\n        virtualbox = {\n            version = \"~&gt; 1\"\n            source  = \"github.com/hashicorp/virtualbox\"\n        }\n        vagrant = {\n            version = \"&gt;= 1.1.1\"\n            source = \"github.com/hashicorp/vagrant\"\n        }\n    }\n}\n</code></pre> <p>Nesse caso estamos utilizando o HCL (HashiCorp Configuration Language) para definir a configura\u00e7\u00e3o do Packer. O arquivo especifica os plugins necess\u00e1rios, como o VirtualBox e o Vagrant. Os plugins s\u00e3o respons\u00e1veis por fornecer suporte a diferentes provedores de virtualiza\u00e7\u00e3o e ferramentas de provisionamento. Mais informa\u00e7\u00f5es sobre o HCL podem ser encontradas na documenta\u00e7\u00e3o do Packer.</p> <p>Voc\u00ea precisar agora inicializar o projeto Packer e instalar o plugins registrados. Para isso, execute os seguintes comandos:</p> <pre><code>packer init .\npacker install plugin github.com/hashicorp/virtualbox\npacker install plugin github.com/hashicorp/vagrant\n</code></pre> </li> <li> <p>Crie um arquivo de configura\u00e7\u00e3o do Packer</p> <p>Crie um arquivo chamado <code>debian.json</code> com o seguinte conte\u00fado:</p> <pre><code>{\n  \"variables\": {\n    \"vm_name\": \"debian12\",\n    \"iso_url\": \"https://cdimage.debian.org/debian-cd/current/amd64/iso-cd/debian-12.11.0-amd64-netinst.iso\",\n    \"iso_checksum\": \"sha256:30ca12a15cae6a1033e03ad59eb7f66a6d5a258dcf27acd115c2bd42d22640e8\"\n  },\n  \"builders\": [\n    {\n      \"type\": \"virtualbox-iso\",\n      \"guest_os_type\": \"Debian_64\",\n      \"vm_name\": \"{{user `vm_name`}}\",\n      \"iso_url\": \"{{user `iso_url`}}\",\n      \"iso_checksum\": \"{{user `iso_checksum`}}\",\n      \"ssh_username\": \"vagrant\",\n      \"ssh_password\": \"vagrant\",\n      \"ssh_timeout\": \"20m\",\n      \"shutdown_command\": \"echo 'vagrant' | sudo -S shutdown -P now\",\n      \"disk_size\": 61440,\n      \"http_directory\": \"http\",\n      \"boot_wait\": \"5s\",\n      \"boot_command\": [\n        \"&lt;esc&gt;&lt;wait&gt;\",\n        \"auto url=http://{{ .HTTPIP }}:{{ .HTTPPort }}/preseed.cfg \",\n        \"debian-installer=en_US auto locale=pt_BR \",\n        \"kbd-chooser/method=us \",\n        \"hostname={{user `vm_name`}} \",\n        \"fb=false debconf/frontend=noninteractive \",\n        \"keyboard-configuration/layout=Brazilian \",\n        \"keyboard-configuration/variant=Brazilian&lt;enter&gt;\"\n      ],\n      \"vboxmanage\": [\n        [\"modifyvm\", \"{{.Name}}\", \"--memory\", \"2048\"],\n        [\"modifyvm\", \"{{.Name}}\", \"--cpus\", \"2\"],\n\n        [\"modifyvm\", \"{{.Name}}\", \"--nic1\", \"nat\"],\n        [\"modifyvm\", \"{{.Name}}\", \"--nictype1\", \"82540EM\"],\n        [\"modifyvm\", \"{{.Name}}\", \"--cableconnected1\", \"on\"]\n      ]\n    }\n  ],\n  \"provisioners\": [\n    {\n      \"type\": \"shell\",\n      \"inline\": [\n        \"echo 'Provisionando como vagrant...'\",\n        \"echo 'auto enp0s8' | sudo tee -a /etc/network/interfaces\",\n        \"echo 'iface enp0s8 inet dhcp' | sudo tee -a /etc/network/interfaces\",\n        \"mkdir -p /home/vagrant/.ssh\",\n        \"chmod 700 /home/vagrant/.ssh\",\n        \"curl -fsSL https://raw.githubusercontent.com/hashicorp/vagrant/main/keys/vagrant.pub -o /home/vagrant/.ssh/authorized_keys\",\n        \"cat /home/vagrant/.ssh/authorized_keys\",\n        \"chmod 600 /home/vagrant/.ssh/authorized_keys\",\n        \"chown -R vagrant:vagrant /home/vagrant/.ssh\"\n      ]\n    }\n  ],\n  \"post-processors\": [\n    {\n      \"type\": \"vagrant\",\n      \"output\": \"debian12.box\"\n    }\n  ]\n}\n</code></pre> <p>Nesse arquivo, definimos as vari\u00e1veis necess\u00e1rias, como o nome da m\u00e1quina virtual, a URL do ISO do Debian e o checksum do ISO. Em seguida, configuramos o construtor <code>virtualbox-iso</code>, que especifica as configura\u00e7\u00f5es da m\u00e1quina virtual, como o tipo de sistema operacional convidado, o nome da m\u00e1quina virtual, a URL do ISO e as configura\u00e7\u00f5es de rede. O comando de inicializa\u00e7\u00e3o \u00e9 configurado para automatizar a instala\u00e7\u00e3o do Debian usando um arquivo de pr\u00e9-configura\u00e7\u00e3o.</p> <p>Na chave <code>builder</code> especificamos o tipo de construtor como <code>virtualbox-iso</code>, que \u00e9 respons\u00e1vel por criar uma imagem de m\u00e1quina virtual usando o VirtualBox. As configura\u00e7\u00f5es incluem:</p> <ul> <li><code>guest_os_type</code>: Define o tipo de sistema operacional convidado, neste caso, Debian 64 bits.</li> <li><code>vm_name</code>: Define o nome da m\u00e1quina virtual. Essa informa\u00e7\u00e3o \u00e9 passada como uma vari\u00e1vel, permitindo que voc\u00ea altere facilmente o ISO sem modificar o arquivo principal.</li> <li><code>iso_url</code>: Especifica a URL do ISO do Debian que ser\u00e1 usado para criar a imagem. Essa informa\u00e7\u00e3o tamb\u00e9m \u00e9 uma vari\u00e1vel.</li> <li><code>iso_checksum</code>: Fornece o checksum do ISO para garantir a integridade do arquivo. Como as duas anteriores, \u00e9 uma vari\u00e1vel.</li> <li><code>ssh_username</code> e <code>ssh_password</code>: Definem as credenciais SSH para acessar a m\u00e1quina virtual durante o provisionamento.</li> <li><code>ssh_timeout</code>: Define o tempo limite para a conex\u00e3o SSH.</li> <li><code>shutdown_command</code>: Especifica o comando para desligar a m\u00e1quina virtual ap\u00f3s o provisionamento.</li> <li><code>disk_size</code>: Define o tamanho do disco da m\u00e1quina virtual em megabytes.</li> <li><code>http_directory</code>: Especifica o diret\u00f3rio onde o Packer procurar\u00e1 arquivos HTTP para provisionamento.</li> <li><code>boot_wait</code>: Define o tempo de espera antes de iniciar o processo de boot.</li> <li><code>boot_command</code>: Define os comandos de boot que ser\u00e3o enviados para a m\u00e1quina virtual durante o processo de inicializa\u00e7\u00e3o. Esses comandos s\u00e3o usados para automatizar a instala\u00e7\u00e3o do Debian usando um arquivo de pr\u00e9-configura\u00e7\u00e3o. Essas informa\u00e7\u00f5es s\u00e3o passadas como uma lista de strings, onde cada string representa um comando a ser enviado para a m\u00e1quina virtual no momento do boot.</li> <li><code>vboxmanage</code>: Permite modificar as configura\u00e7\u00f5es da m\u00e1quina virtual usando comandos do VirtualBox. Aqui, estamos configurando a mem\u00f3ria, o n\u00famero de CPUs e as configura\u00e7\u00f5es de rede. Nesse caso, estamos configurando a m\u00e1quina virtual para usar 2 GB de mem\u00f3ria, 2 CPUs e uma interface de rede NAT.</li> </ul> <p>O bloco <code>provisioners</code> define as etapas de provisionamento que ser\u00e3o executadas ap\u00f3s a cria\u00e7\u00e3o da imagem. Neste caso, estamos usando um provisionador do tipo <code>shell</code>, que executa comandos shell na m\u00e1quina virtual. Os comandos incluem a configura\u00e7\u00e3o da interface de rede e a adi\u00e7\u00e3o da chave SSH do Vagrant. Note que ele baixa a chave p\u00fablica do Vagrant diretamente do reposit\u00f3rio oficial, que ser\u00e1 usada para autentica\u00e7\u00e3o SSH no provisionamento.</p> <p>O bloco <code>post-processors</code> define as etapas que ser\u00e3o executadas ap\u00f3s o provisionamento. Neste caso, estamos usando um post-processor do tipo <code>vagrant</code>, que cria um arquivo <code>.box</code> que pode ser usado pelo Vagrant para criar m\u00e1quinas virtuais a partir da imagem criada pelo Packer.</p> </li> <li> <p>Crie um arquivo de pr\u00e9-configura\u00e7\u00e3o:</p> <p>Crie um diret\u00f3rio chamado <code>http</code> e dentro dele, crie um arquivo chamado <code>preseed.cfg</code> com o seguinte conte\u00fado:</p> <pre><code>d-i debian-installer/locale string pt_BR.UTF-8\n\nd-i console-setup/ask_detect boolean false\nd-i keyboard-configuration/xkb-keymap select br\nd-i keyboard-configuration/layout select Brazil\nd-i keyboard-configuration/variant select abnt2\nd-i keyboard-configuration/modelcode string abnt2\n\nd-i netcfg/choose_interface select enp0s3\nd-i netcfg/choose_interface_if_needed boolean false\nd-i netcfg/choose_interface priority critical\nd-i netcfg/get_hostname string debian12\nd-i netcfg/get_domain string localdomain\n\nd-i mirror/country string manual\nd-i mirror/http/hostname string deb.debian.org\nd-i mirror/http/directory string /debian\nd-i mirror/http/proxy string\n\nd-i accessibility-profile/choose-profile select none\n\nd-i clock-setup/utc boolean true\nd-i time/zone string America/Sao_Paulo\nd-i clock-setup/ntp boolean true\n\nd-i partman-auto/method string regular\nd-i partman-auto/choose_recipe select atomic\nd-i partman-partitioning/confirm_write_new_label boolean true\nd-i partman/choose_partition select finish\nd-i partman/confirm boolean true\nd-i partman/confirm_nooverwrite boolean true\n\nd-i passwd/user-fullname string Vagrant User\nd-i passwd/username string vagrant\nd-i passwd/user-password password vagrant\nd-i passwd/user-password-again password vagrant\nd-i user-setup/encrypt-home boolean false\nd-i user-setup/allow-password-weak boolean true\nd-i passwd/user-default-groups string sudo\n\nd-i passwd/root-login boolean false\nd-i passwd/root-password password root\nd-i passwd/root-password-again password root\n\nd-i grub-installer/only_debian boolean true\nd-i grub-installer/bootdev string /dev/sda\nd-i finish-install/reboot_in_progress note\nd-i preseed/late_command string in-target adduser vagrant sudo\nd-i preseed/late_command string in-target sh -c \"echo 'vagrant ALL=(ALL) NOPASSWD:ALL' &gt; /etc/sudoers.d/vagrant &amp;&amp; chmod 440 /etc/sudoers.d/vagrant\"\n\nd-i pkgsel/run_tasksel boolean false\nd-i pkgsel/include string openssh-server build-essential\nd-i pkgsel/include string sudo curl vim net-tools ssh lynx ansible\n\nd-i pkgsel/upgrade select full-upgrade\n</code></pre> </li> <li> <p>Crie o arquivo de imagem</p> <p>Execute o seguinte comando para criar a sua imagem:</p> <pre><code>packer build debian.json\n</code></pre> </li> <li> <p>Adicione a imagem criada ao Vagrant</p> <p>Ap\u00f3s a cria\u00e7\u00e3o da imagem, voc\u00ea pode adicionar a imagem ao Vagrant usando o seguinte comando:</p> <pre><code>vagrant box add debian12 debian12.box\n</code></pre> <p>Isso registrar\u00e1 a imagem <code>debian12.box</code> no Vagrant, permitindo que voc\u00ea crie m\u00e1quinas virtuais a partir dela.</p> </li> <li> <p>Crie o arquivo de configura\u00e7\u00e3o do Vagrant:</p> <p>Crie um arquivo chamado <code>Vagrantfile</code>, com seguinte conte\u00fado:</p> <pre><code>Vagrant.configure(\"2\") do |config|\n    config.vm.box = \"debian12\"\n\n    config.vm.network \"public_network\", bridge: \"enp2s0\"\n\n    config.vm.provider \"virtualbox\" do |vb|\n        vb.memory = \"2048\"\n        vb.cpus = 2\n    end\nend\n</code></pre> <p>Caso voc\u00ea queira, por exemplo, levantar tr\u00eas m\u00e1quinas virtuais, voc\u00ea pode modificar o arquivo <code>Vagrantfile</code> para incluir m\u00faltiplas m\u00e1quinas. Veja um exemplo:</p> <pre><code>Vagrant.configure(\"2\") do |config|\n  (1..3).each do |i|\n    config.vm.define \"debian#{i}\" do |machine|\n      machine.vm.box = \"debian12\"\n      machine.vm.network \"public_network\", bridge: \"enp2s0\"\n      machine.vm.provider \"virtualbox\" do |vb|\n        vb.memory = \"2048\"\n        vb.cpus = 2\n      end\n    end\n  end\nend\n</code></pre> <p>Nesse exemplo, estamos criando tr\u00eas m\u00e1quinas virtuais chamadas <code>debian1</code>, <code>debian2</code> e <code>debian3</code>, todas com as mesmas configura\u00e7\u00f5es de rede e recursos.</p> </li> <li> <p>Use o seu ambiente com o vagrant</p> <p>Para usar o ambiente criado execute:</p> <pre><code>vagrant up\n</code></pre> </li> </ol>"},{"location":"orquestracao/","title":"Orquestra\u00e7\u00e3o de cont\u00eaineres","text":"<p>A orquestra\u00e7\u00e3o de containers automatiza o gerenciamento de containers, desde o provisionamento at\u00e9 o escalonamento e monitoramento, permitindo que as organiza\u00e7\u00f5es implantem aplica\u00e7\u00f5es em grande escala de forma mais eficiente. A orquestra\u00e7\u00e3o \u00e9 especialmente \u00fatil em ambientes de microservi\u00e7os, onde aplica\u00e7\u00f5es s\u00e3o divididas em pequenos servi\u00e7os independentes que podem ser implantados e escalonados separadamente. Al\u00e9m disso, ela ajuda a manter a coes\u00e3o e a resili\u00eancia das aplica\u00e7\u00f5es, garantindo que os servi\u00e7os estejam sempre dispon\u00edveis e funcionando corretamente.</p> <p>Quando levantamos um container, usando o Docker por exemplo, estamos criando uma inst\u00e2ncia isolada de um aplicativo ou servi\u00e7o. No entanto, \u00e0 medida que o n\u00famero de containers aumenta, torna-se dif\u00edcil gerenci\u00e1-los manualmente. A orquestra\u00e7\u00e3o de containers resolve esse problema, permitindo que os desenvolvedores e operadores automatizem tarefas repetitivas e complexas.</p> <p>A orquestra\u00e7\u00e3o de containers \u00e9 uma abordagem que permite gerenciar e automatizar o ciclo de vida de containers em ambientes de produ\u00e7\u00e3o. Isso inclui tarefas como provisionamento, escalonamento, monitoramento e recupera\u00e7\u00e3o de falhas. Ferramentas de orquestra\u00e7\u00e3o ajudam a garantir que os containers estejam sempre dispon\u00edveis, escal\u00e1veis e funcionando corretamente.</p> <p>Algumas caracter\u00edsticas comuns de ferramentas de orquestra\u00e7\u00e3o de containers incluem:</p> <ul> <li>Gerenciamento de ciclo de vida: Automatiza o provisionamento, escalonamento e monitoramento de containers.</li> <li>Escalonamento autom\u00e1tico: Ajusta automaticamente o n\u00famero de containers em execu\u00e7\u00e3o com base na carga de trabalho.</li> <li>Balanceamento de carga: Distribui o tr\u00e1fego entre os containers para garantir desempenho e disponibilidade.</li> <li>Recupera\u00e7\u00e3o autom\u00e1tica: Reinicia containers com falha ou substitui containers n\u00e3o saud\u00e1veis.</li> <li>Gerenciamento de configura\u00e7\u00e3o: Permite a configura\u00e7\u00e3o centralizada de containers, facilitando a atualiza\u00e7\u00e3o e o gerenciamento de aplica\u00e7\u00f5es.</li> <li>Rede e armazenamento: Facilita a comunica\u00e7\u00e3o entre containers e o gerenciamento de volumes de armazenamento.</li> <li>Seguran\u00e7a: Fornece recursos de seguran\u00e7a, como autentica\u00e7\u00e3o, autoriza\u00e7\u00e3o e criptografia de dados.</li> <li>Monitoramento e registro: Coleta m\u00e9tricas e logs dos containers para an\u00e1lise e solu\u00e7\u00e3o de problemas.</li> <li>Integra\u00e7\u00e3o com CI/CD: Facilita a integra\u00e7\u00e3o com pipelines de entrega cont\u00ednua e implanta\u00e7\u00e3o cont\u00ednua.</li> <li>Multi-cloud e h\u00edbrido: Suporte para implanta\u00e7\u00f5es em ambientes de nuvem p\u00fablica, privada e h\u00edbrida.</li> <li>Flexibilidade: A capacidade de personalizar e estender a ferramenta para atender \u00e0s necessidades espec\u00edficas da organiza\u00e7\u00e3o.</li> <li>Gerenciamento de segredos: Permite armazenar e gerenciar segredos, como senhas e chaves de API, de forma segura.</li> </ul> <p>Nas nossas aulas, faremos uso da ferramenta \"kind\" para facilitar a cria\u00e7\u00e3o e gerenciamento de clusters Kubernetes locais. O Kind (Kubernetes IN Docker) \u00e9 uma ferramenta que permite executar clusters Kubernetes em containers Docker, tornando mais f\u00e1cil o desenvolvimento e teste de aplica\u00e7\u00f5es em ambientes Kubernetes. Ele \u00e9 especialmente \u00fatil para desenvolvedores que desejam experimentar o Kubernetes sem precisar configurar um cluster completo em uma m\u00e1quina f\u00edsica ou virtual. Por isso, \u00e9 amplamente utilizado em ambientes de desenvolvimento e teste, onde a cria\u00e7\u00e3o r\u00e1pida e f\u00e1cil de clusters Kubernetes \u00e9 essencial.</p>"},{"location":"orquestracao/#instalacao-do-kind-e-comandos-basicos","title":"Instala\u00e7\u00e3o do Kind e comandos b\u00e1sicos","text":"<p>Primeiramente, para instalar o Kind \u00e9 necess\u00e1rio ter o Docker instalado na m\u00e1quina. Para isso, caso voc\u00ea ainda n\u00e3o tenha o Docker, pode consultar a aula referente aos cont\u00eaineres.</p> <p>Com o Docker instalado, voc\u00ea pode instalar o Kind usando o comando abaixo, em um ambiente Linux:</p> <pre><code>curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.28.0/kind-linux-amd64\nchmod +x ./kind\nsudo mv ./kind /usr/local/bin/kind\n</code></pre> <p>Depois, voc\u00ea pode criar um cluster Kubernetes usando o Kind com o seguinte comando:</p> <pre><code>kind create cluster\n</code></pre> <p>Isso ir\u00e1 criar um cluster Kubernetes local em sua m\u00e1quina usando containers Docker. Voc\u00ea pode verificar se o cluster foi criado com sucesso executando o seguinte comando:</p> <pre><code>kubectl cluster-info --context kind-kind\n</code></pre> <p>Se tudo estiver funcionando corretamente, voc\u00ea ver\u00e1 informa\u00e7\u00f5es sobre o cluster Kubernetes em execu\u00e7\u00e3o. O comando <code>kubectl</code> \u00e9 a ferramenta de linha de comando do Kubernetes, que permite interagir com o cluster e gerenciar recursos. A instala\u00e7\u00e3o do <code>kubectl</code> \u00e9 feita automaticamente quando voc\u00ea instala o Kind, portanto, n\u00e3o \u00e9 necess\u00e1rio instal\u00e1-lo separadamente.</p> <p>Tamb\u00e9m, \u00e9 poss\u00edvel informar o nome do cluster com o seguinte comando:</p> <pre><code>kind create cluster --name devops\n</code></pre> <p>Nesse caso, foi criado um cluster chamado \"devops\". Agora, voc\u00ea pode listar os cluster com o seguinte comando:</p> <pre><code>kind get clusters\n</code></pre> <p>O comando acima ir\u00e1 listar todos os clusters criados com o Kind e, nosso exemplo, deve retornar o seguinte resultado:</p> <pre><code>kind\ndevops\n</code></pre> <p>O primeiro cluster criado com o Kind \u00e9 chamado \"kind\". O segundo cluster que criamos \u00e9 chamado \"devops\". Voc\u00ea pode usar esses nomes para gerenciar os clusters individualmente, como iniciar, parar ou excluir um cluster espec\u00edfico.</p> <p>Para excluir um cluster, voc\u00ea pode usar o seguinte comando:</p> <pre><code>kind delete cluster --name devops\n</code></pre> <p>Isso ir\u00e1 remover o cluster \"devops\" que criamos anteriormente. Se voc\u00ea quiser excluir o cluster padr\u00e3o chamado \"kind\", basta executar:</p> <pre><code>kind delete cluster\n</code></pre> <p>Isso ir\u00e1 remover o cluster \"kind\" que foi criado automaticamente quando voc\u00ea instalou o Kind. Lembre-se de que, ao excluir um cluster, todos os dados e configura\u00e7\u00f5es associados a ele ser\u00e3o perdidos. Portanto, certifique-se de fazer backup de qualquer dado importante antes de excluir um cluster.</p>"},{"location":"orquestracao/#criando-um-cluster-com-o-kind","title":"Criando um cluster com o Kind","text":"<p>Para as demais atividades com o kubernetes que desenvolveremos, sugiro que voc\u00ea crie um diret\u00f3rio vazio e armazene os arquivos de configura\u00e7\u00e3o do cluster nesse diret\u00f3rio. Dentro desse diret\u00f3rio, criaremos um arquivo chamado <code>kind.yaml</code> com a configura\u00e7\u00e3o do cluster. O conte\u00fado desse arquivo \u00e9 o seguinte:</p> ./kind.yaml<pre><code>kind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n  - role: control-plane\n  - role: worker\n  - role: worker\n  - role: worker\n</code></pre> <p>Nesse arquivo de configura\u00e7\u00e3o, estamos criando um cluster com um n\u00f3 de controle (control-plane) e tr\u00eas n\u00f3s de trabalho (worker). O n\u00f3 de controle \u00e9 respons\u00e1vel por gerenciar o cluster, enquanto os n\u00f3s de trabalho executam as aplica\u00e7\u00f5es e servi\u00e7os. Note que esse \u00e9 um arquivo declarativo, ou seja, ele descreve o estado desejado do cluster. O Kind ir\u00e1 criar o cluster com base nessa configura\u00e7\u00e3o. Vamos explicar as partes do arquivo:</p> <ul> <li><code>kind: Cluster</code>: Especifica que estamos criando um cluster Kubernetes.</li> <li><code>apiVersion: kind.x-k8s.io/v1alpha4</code>: Especifica a vers\u00e3o da API do Kind que estamos usando.</li> <li><code>nodes</code>: Define os n\u00f3s do cluster. Cada n\u00f3 pode ter um papel diferente, como control-plane ou worker.</li> </ul> <p>Para aplicar essa configura\u00e7\u00e3o e criar o cluster, execute o seguinte comando no terminal:</p> <pre><code>kind create cluster --config kind.yaml --name devops\n</code></pre> <p>Isso ir\u00e1 criar um cluster Kubernetes com a configura\u00e7\u00e3o especificada no arquivo <code>kind.yaml</code>. Ap\u00f3s a cria\u00e7\u00e3o do cluster, voc\u00ea pode verificar se ele est\u00e1 em execu\u00e7\u00e3o usando o comando:</p> <pre><code>kubectl cluster-info --context kind-devops\n</code></pre>"},{"location":"orquestracao/#criando-uma-aplicacao","title":"Criando uma aplica\u00e7\u00e3o","text":"<p>Vamos agora criar uma aplica\u00e7\u00e3o que ser\u00e1 utilizada em todo o percurso de estudo do kubernetes. Como ela \u00e9 uma aplica\u00e7\u00e3o apenas para fins de demonstra\u00e7\u00e3o, ser\u00e1 desenvolvida da forma mais simples poss\u00edvel. Para isso, faremos uso do framework FastApi, que \u00e9 um framework web para constru\u00e7\u00e3o de APIs em Python.</p> <p>Inicialmente, crie e acesse um diret\u00f3rio de nome <code>app</code>:</p> <pre><code>mkdir app\ncd app\n</code></pre> <p>Agora, crie um ambiente virtual <code>venv</code> e ative esse ambiente:</p> <pre><code>python -m venv .venv\nsource .venv/bin/activate\npip install fastapi uvicorn\n</code></pre> <p>Em seguida, crie um arquivo <code>main.py</code> com o seguinte conte\u00fado:</p> ./app/main.py<pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef read_root():\n    return {\"message\": \"Hello World!\"}\n\nif __name__ == '__main__':\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre> <p>J\u00e1 vamos gerar o arquivo <code>requirements.txt</code> com as depend\u00eancias necess\u00e1rias para a aplica\u00e7\u00e3o. Para isso, execute o seguinte comando:</p> <pre><code>pip freeze &gt; requirements.txt\n</code></pre> <p>Em seguida, para testarmos a aplica\u00e7\u00e3o, podemos executar o seguinte comando:</p> <pre><code>python main.py\n</code></pre> <p>Isso ir\u00e1 iniciar o servidor da aplica\u00e7\u00e3o FastAPI. Voc\u00ea pode acessar a aplica\u00e7\u00e3o no navegador ou usar uma ferramenta como o <code>curl</code> para fazer uma requisi\u00e7\u00e3o HTTP GET para o endpoint <code>/</code>, ou acessar http://localhost:8000. O servidor ir\u00e1 responder com a mensagem:</p> <pre><code>{ \"message\": \"Hello World!\" }\n</code></pre> <p>Com o projeto FastAPI j\u00e1 desenvolvido, podemos desativar o ambiente virtual e voltar para o diret\u00f3rio de trabalho:</p> <pre><code>deactivate\ncd ..\n</code></pre>"},{"location":"orquestracao/#criando-a-imagem-docker","title":"Criando a imagem Docker","text":"<p>Com a aplica\u00e7\u00e3o desenvolvida, vamos criar uma imagem docker para ser publicada e depois provisionada e implantada num cluster k8s. Para tal, crie um arquivo <code>Dockerfile</code> com o seguinte conte\u00fado:</p> ./Dockerfile<pre><code>FROM python:3.13-slim\nWORKDIR /app\nCOPY app/requirements.txt requirements.txt\nRUN pip install --no-cache-dir -r requirements.txt\nCOPY app/main.py main.py\nCMD [\"python\", \"main.py\"]\n</code></pre> <p>O arquivo declara uma imagem simples para a aplica\u00e7\u00e3o que foi desenvolvida. Abaixo, um detalhamento de cada linha:</p> <ul> <li><code>FROM python:3.13-slim</code>: Especifica a imagem base a ser utilizada, que \u00e9 uma vers\u00e3o leve do Python 3.13.</li> <li><code>WORKDIR /app</code>: Define o diret\u00f3rio de trabalho dentro do cont\u00eainer como <code>/app</code>.</li> <li><code>COPY app/requirements.txt requirements.txt</code>: Copia o arquivo <code>requirements.txt</code> para o diret\u00f3rio de trabalho no cont\u00eainer.</li> <li><code>RUN pip install --no-cache-dir -r requirements.txt</code>: Instala as depend\u00eancias da aplica\u00e7\u00e3o especificadas no <code>requirements.txt</code>.</li> <li><code>COPY app/main.py main.py</code>: Copia o arquivo <code>main.py</code> para o diret\u00f3rio de trabalho no cont\u00eainer.</li> <li><code>CMD [\"python\", \"main.py\"]</code>: Define o comando a ser executado quando o cont\u00eainer for iniciado, que \u00e9 rodar a aplica\u00e7\u00e3o FastAPI.</li> </ul> <p>Para testar, vamos construir a imagem. Aqui, usarei o meu nome de usu\u00e1rio do DockerHub (<code>eduardosilvasc</code>). Voc\u00ea deve usar o seu usu\u00e1rio para depois fazer a publica\u00e7\u00e3o da imagem:</p> <pre><code>docker build -t eduardosilvasc/hello-fastapi-k8s .\n</code></pre> <p>Para testar se a imagem foi criada corretamente, execute o seguinte comando:</p> <pre><code>docker run -p 8000:8000 eduardosilvasc/hello-fastapi-k8s\n</code></pre> <p>Com isso, o servidor da aplica\u00e7\u00e3o FastAPI estar\u00e1 rodando no cont\u00eainer e voc\u00ea poder\u00e1 acess\u00e1-lo em http://localhost:8000. A resposta deve ser a mesma que obtivemos anteriormente:</p> <pre><code>{ \"message\": \"Hello World!\" }\n</code></pre> <p>Agora, para publicar a imagem no DockerHub, execute o seguinte comando:</p> <pre><code>docker push eduardosilvasc/hello-fastapi-k8s\n</code></pre> <p>Claro que para isso, voc\u00ea deve estar logado no DockerHub. Caso n\u00e3o tenha feito isso, execute o seguinte comando:</p> <pre><code>docker login\n</code></pre> <p>Lembre que voc\u00ea precisar\u00e1 pegar as credenciais nas configura\u00e7\u00f5es do DockerHub.</p>"},{"location":"orquestracao/#criando-um-pod","title":"Criando um pod","text":"<p>Nessa etapa, vamos criar um pod que utiliza a imagem que criamos e registramos no reposit\u00f3rio de imagens do DockerHub. Para isso, crie um arquivo chamado <code>pod.yaml</code>, no diret\u00f3rio <code>k8s</code>, com o seguinte conte\u00fado:</p> ./k8s/pod.yaml<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-fastapi\nspec:\n  containers:\n    - name: hello-fastapi\n      image: eduardosilvasc/hello-fastapi-k8s\n      ports:\n        - containerPort: 8000\n</code></pre> <p>Com o arquivo acima, estamos declarando um pod Kubernetes chamado <code>hello-fastapi</code>, que executa um cont\u00eainer baseado na imagem <code>eduardosilvasc/hello-fastapi-k8s</code> e exp\u00f5e a porta 8000. Para criar o pod, execute o seguinte comando:</p> <pre><code>kubectl apply -f k8s/pod.yaml\n</code></pre> <p>Para verificar se o pod foi criado e est\u00e1 em execu\u00e7\u00e3o, use o comando:</p> <pre><code>kubectl get pods\n</code></pre> <p>Voc\u00ea deve ver o pod <code>hello-fastapi</code> na lista de pods em execu\u00e7\u00e3o. Para acessar a aplica\u00e7\u00e3o FastAPI que est\u00e1 rodando no pod, voc\u00ea pode usar o port-forwarding do Kubernetes:</p> <pre><code>kubectl port-forward pod/hello-fastapi --address 0.0.0.0 8000:8000\n</code></pre> <p>Agora, voc\u00ea pode acessar a aplica\u00e7\u00e3o em http://localhost:8000. A resposta deve ser a mesma que obtivemos anteriormente:</p> <pre><code>{ \"message\": \"Hello World!\" }\n</code></pre>"},{"location":"orquestracao/#criando-um-deployment","title":"Criando um Deployment","text":"<p>A cria\u00e7\u00e3o de um pod \u00e9 a parte essencial de um cluster k8s. Contudo, da forma que criamos esse recurso, o sistema n\u00e3o est\u00e1 preparado para lidar com falhas ou escalabilidade. Por exemplo, se o pod falhar ou for exclu\u00eddo, ele n\u00e3o ser\u00e1 reiniciado automaticamente. Para resolver isso, podemos usar um recurso chamado Deployment, que \u00e9 uma abstra\u00e7\u00e3o de n\u00edvel superior que gerencia a cria\u00e7\u00e3o e atualiza\u00e7\u00e3o de pods.</p> <p>Para isso, vamos criar um arquivo chamado <code>deployment.yaml</code>, no diret\u00f3rio <code>k8s</code>, com o seguinte conte\u00fado:</p> ./k8s/deployment.yaml<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-fastapi\nspec:\n    replicas: 3\n    selector:\n        matchLabels:\n        app: hello-fastapi\n    template:\n        metadata:\n        labels:\n            app: hello-fastapi\n        spec:\n        containers:\n        - name: hello-fastapi\n            image: eduardosilvasc/hello-fastapi-k8s\n            ports:\n            - containerPort: 8000\n</code></pre> <p>Na configura\u00e7\u00e3o acima do Deployment, estamos especificando que queremos 3 r\u00e9plicas do pod <code>hello-fastapi</code>. O Kubernetes ir\u00e1 garantir que sempre haja 3 pods em execu\u00e7\u00e3o. Se um pod falhar ou for exclu\u00eddo, o Kubernetes ir\u00e1 criar um novo pod automaticamente para substitu\u00ed-lo. Para criar o Deployment, execute o seguinte comando:</p> <pre><code>kubectl apply -f k8s/deployment.yaml\n</code></pre> <p>Para verificar se o Deployment foi criado e est\u00e1 em execu\u00e7\u00e3o, use o comando:</p> <pre><code>kubectl get deployments\n</code></pre> <p>Voc\u00ea deve ver o Deployment <code>hello-fastapi</code> na lista de deployments em execu\u00e7\u00e3o. Para verificar os pods criados pelo Deployment, use o comando:</p> <pre><code>kubectl get pods\n</code></pre> <p>Voc\u00ea deve ver 3 pods <code>hello-fastapi</code> em execu\u00e7\u00e3o. Para acessar a aplica\u00e7\u00e3o FastAPI que est\u00e1 rodando nos pods, voc\u00ea pode usar o port-forwarding do Kubernetes:</p> <pre><code>kubectl port-forward deployment/hello-fastapi --address 0.0.0.0 8000:8000\n</code></pre> <p>Agora, voc\u00ea pode acessar a aplica\u00e7\u00e3o em http://localhost:8000. A resposta deve ser a mesma que obtivemos anteriormente:</p> <pre><code>{ \"message\": \"Hello World!\" }\n</code></pre>"},{"location":"orquestracao/#criando-um-service","title":"Criando um Service","text":"<p>Para expor a aplica\u00e7\u00e3o FastAPI para o mundo externo, precisamos criar um Service. Um Service \u00e9 um recurso do Kubernetes que define como acessar os pods em execu\u00e7\u00e3o. Ele fornece um ponto de acesso est\u00e1vel para os pods, mesmo que os pods sejam criados ou exclu\u00eddos. Para isso, vamos criar um arquivo chamado <code>service.yaml</code>, no diret\u00f3rio <code>k8s</code>, com o seguinte conte\u00fado:</p> ./k8s/service.yaml<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: hello-fastapi-service\nspec:\n  selector:\n    app: hello-fastapi\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 8000\n</code></pre> <p>Nesse arquivo, estamos criando um Service chamado <code>hello-fastapi</code> que seleciona os pods com o r\u00f3tulo <code>app: hello-fastapi</code>. O Service ir\u00e1 expor a porta 80 e encaminhar o tr\u00e1fego para a porta 8000 dos pods. Para criar o Service, execute o seguinte comando:</p> <pre><code>kubectl apply -f k8s/service.yaml\n</code></pre> <p>Para verificar se o Service foi criado e est\u00e1 em execu\u00e7\u00e3o, use o comando:</p> <pre><code>kubectl get services\n</code></pre> <p>Voc\u00ea deve ver o Service <code>hello-fastapi</code> na lista de servi\u00e7os em execu\u00e7\u00e3o. Para acessar a aplica\u00e7\u00e3o FastAPI que est\u00e1 rodando nos pods, voc\u00ea pode usar o port-forwarding do Kubernetes:</p> <pre><code>kubectl port-forward service/hello-fastapi-service --address 0.0.0.0 8000:8000\n</code></pre> <p>Agora, voc\u00ea pode acessar a aplica\u00e7\u00e3o em http://localhost:8000. A resposta deve ser a mesma que obtivemos anteriormente:</p> <pre><code>{ \"message\": \"Hello World!\" }\n</code></pre>"}]}